diff --git a/CI/MOLAPFeatureTest/.settings/org.eclipse.jdt.core.prefs b/CI/MOLAPFeatureTest/.settings/org.eclipse.jdt.core.prefs
deleted file mode 100644
index d17b672..0000000
--- a/CI/MOLAPFeatureTest/.settings/org.eclipse.jdt.core.prefs
+++ /dev/null
@@ -1,12 +0,0 @@
-eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled
-org.eclipse.jdt.core.compiler.codegen.methodParameters=do not generate
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.7
-org.eclipse.jdt.core.compiler.codegen.unusedLocal=preserve
-org.eclipse.jdt.core.compiler.compliance=1.7
-org.eclipse.jdt.core.compiler.debug.lineNumber=generate
-org.eclipse.jdt.core.compiler.debug.localVariable=generate
-org.eclipse.jdt.core.compiler.debug.sourceFile=generate
-org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
-org.eclipse.jdt.core.compiler.problem.enumIdentifier=error
-org.eclipse.jdt.core.compiler.source=1.7
diff --git a/CI/MOLAPFeatureTest/src/main/scala/com/huawei/datasight/test/StartTest.scala b/CI/MOLAPFeatureTest/src/main/scala/com/huawei/datasight/test/StartTest.scala
index 29843f3..6d53881 100644
--- a/CI/MOLAPFeatureTest/src/main/scala/com/huawei/datasight/test/StartTest.scala
+++ b/CI/MOLAPFeatureTest/src/main/scala/com/huawei/datasight/test/StartTest.scala
@@ -66,70 +66,10 @@ object StartTest {
     val partitionColumn = prop.getProperty("olap.loadschema.PartitionerColumn","imei")
     
     val factPath:String=MessageFormat.format(prop.getProperty("olap.partitionData.fact.path"),basePath)
-   
-    println("referred variables :--- ")
-    
-    val createSQL = s"create cube " + cubeName+
-                 " dimensions(imei string,deviceInformationId integer,MAC string,deviceColor string,device_backColor string,modelId string,marketName string,AMSize string,ROMSize string,CUPAudit string,CPIClocked string,series string,productionDate timestamp,bomCode string,internalModels string, deliveryTime string, channelsId string, channelsName string , deliveryAreaId string, deliveryCountry string, deliveryProvince string, deliveryCity string,deliveryDistrict string, deliveryStreet string, oxSingleNumber string, ActiveCheckTime string, ActiveAreaId string, ActiveCountry string, ActiveProvince string, Activecity string, ActiveDistrict string, ActiveStreet string, ActiveOperatorId string, Active_releaseId string, Active_EMUIVersion string, Active_operaSysVersion string, Active_BacVerNumber string, Active_BacFlashVer string, Active_webUIVersion string, Active_webUITypeCarrVer string,Active_webTypeDataVerNumber string, Active_operatorsVersion string, Active_phonePADPartitionedVersions string, Latest_YEAR integer, Latest_MONTH integer, Latest_DAY integer, Latest_HOUR string, Latest_areaId string, Latest_country string, Latest_province string, Latest_city string, Latest_district string, Latest_street string, Latest_releaseId string, Latest_EMUIVersion string, Latest_operaSysVersion string, Latest_BacVerNumber string, Latest_BacFlashVer string, Latest_webUIVersion string, Latest_webUITypeCarrVer string, Latest_webTypeDataVerNumber string, Latest_operatorsVersion string, Latest_phonePADPartitionedVersions string, Latest_operatorId string, gamePointDescription string)"+ 
-                "measures(gamePointId numeric,contractNumber numeric) OPTIONS (PARTITIONER [CLASS = 'com.huawei.datasight.molap.partition.api.impl.SampleDataPartitionerImpl' columns= (" + 
-                partitionColumn+")"+ 
-                "PARTITION_COUNT="+partitionCount+"] )"
-
-    val loadSQl = "LOAD DATA FACT FROM '"+factPath+"' INTO Cube " + cubeName + " partitionData(DELIMITER ',' ,QUOTECHAR '\"', FILEHEADER 'imei,deviceInformationId,MAC,deviceColor,device_backColor,modelId,marketName,AMSize,ROMSize,CUPAudit,CPIClocked,series,productionDate,bomCode,internalModels,deliveryTime,channelsId,channelsName,deliveryAreaId,deliveryCountry,deliveryProvince,deliveryCity,deliveryDistrict,deliveryStreet,oxSingleNumber,contractNumber,ActiveCheckTime,ActiveAreaId,ActiveCountry,ActiveProvince,Activecity,ActiveDistrict,ActiveStreet,ActiveOperatorId,Active_releaseId,Active_EMUIVersion,Active_operaSysVersion,Active_BacVerNumber,Active_BacFlashVer,Active_webUIVersion,Active_webUITypeCarrVer,Active_webTypeDataVerNumber,Active_operatorsVersion,Active_phonePADPartitionedVersions,Latest_YEAR,Latest_MONTH,Latest_DAY,Latest_HOUR,Latest_areaId,Latest_country,Latest_province,Latest_city,Latest_district,Latest_street,Latest_releaseId,Latest_EMUIVersion,Latest_operaSysVersion,Latest_BacVerNumber,Latest_BacFlashVer,Latest_webUIVersion,Latest_webUITypeCarrVer,Latest_webTypeDataVerNumber,Latest_operatorsVersion,Latest_phonePADPartitionedVersions,Latest_operatorId,gamePointId,gamePointDescription')"
-    
-    if(prop.get("olap.loaddata").equals("true"))
-    {
-       // prepare for test 
-   
-       val olapKeys = prop.keySet.toList.map(_.toString).filter(_.startsWith("olapcontext."))
+    val olapKeys = prop.keySet.toList.map(_.toString).filter(_.startsWith("olapcontext."))
        olapKeys.foreach(x => hc.setConf(x.stripPrefix("olapcontext."), prop.getProperty(x)))
-//       val schemaPath:String=MessageFormat.format(prop.getProperty("spark.schema.path"),basePath)
-
-       
-       hc.sql("show cubes").show
-       try {
-         println(s"executing>>>>>> Drop cube ")
-           hc.sql("Drop cube " + cubeName).show
-           println(s"executed>>>>>> Drop cube ")
-       } catch {
-       case e: Exception => e.printStackTrace()
-        println(s"failed>>>>>> Drop cube ")
-       }
        
-       hc.sql("show cubes").show
-       
-       println(s"executing>>>>>> createSQL ")
-       hc.sql(createSQL).show;
-        println(s"executed>>>>>> createSQL ")
-        
-        println(s"executing>>>>>> loadSQl ")
-       hc.sql(loadSQl).show;
-         println(s"executed>>>>>> loadSQl")
-
-//       OlapContext.loadSchema(schemaPath, prop.getProperty("olap.loadschema.encrypted") equalsIgnoreCase "true",
-//       prop.getProperty("olap.loadschema.aggTablesGen") equalsIgnoreCase "true",
-//       Partitioner(prop.getProperty("olap.loadschema.Partitioner"), Seq(prop.getProperty("olap.loadschema.PartitionerColumn")).toArray, prop.getProperty("olap.loadschema.numberOfPartition").toInt, null))(hc)
-//  
-//       val partitionPath:String=MessageFormat.format(prop.getProperty("spark.partition.path"),basePath)
-//       val dimension:String=prop.getPropOrNull("spark.dimension.path")
-//       val dimensionPath:String=null
-//       if(null!=dimension)
-//       {
-//         val dimensionPath:String=MessageFormat.format(prop.getPropOrNull("spark.dimension.path"),basePath)  
-//       }
-//       
-//       
-//       if(prop.getProperty("olap.partitionData.partition").equalsIgnoreCase("true"))
-//       OlapContext.partitionData(prop.getProperty("spark.schema.name"), prop.getProperty("spark.cube.name"),factPath,partitionPath)(hc)
-//       
-//       OlapContext.loadData(prop.getProperty("spark.schema.name"), prop.getProperty("spark.cube.name"),partitionPath,dimensionPath)(hc)
-    }
-    
-//    hc.sql("""CREATE TABLE Carbon_Test USING org.apache.spark.sql.CarbonSource OPTIONS (cubename "Carbon_Test", storepath s"$basePath")   """).show()
-    
-     println(s"executing>>>>>> show cubes")
-     hc.sql("show cubes").show
-     println(s"executed>>>>>> show cubes")
+    println("referred variables :--- ")
     
     val sqlFilePath:String=MessageFormat.format(prop.getProperty("molap.test.sqlFile"),basePath)
     sqlFilePath.split(",").foreach(readFileAndExec(_, hc, pw,reportWriter))
@@ -149,12 +89,17 @@ object StartTest {
 	}
   def processCommand(cmd: String, hc: HiveContext, pw: java.io.PrintWriter,reportWriter: XmlReportWriter): Unit = {
     try {
-      println(s"executing>>>>>>$cmd")
-      val result=hc.sql(cmd)
-              result.show(100)
-              println(s"executed>>>>>>$cmd")
-      pw.write(s"$cmd  | Success \r\n")
-      reportWriter.writePASS("1", s"$cmd")
+     
+      if(!cmd.startsWith("#"))
+       {
+           println(s"executing>>>>>>$cmd")
+           val result=hc.sql(cmd)
+           result.show(100)
+           println(s"executed>>>>>>$cmd")
+           pw.write(s"$cmd  | Success \r\n")
+           reportWriter.writePASS("1", s"$cmd")  
+       }
+      
     } catch {
       case ex: Exception => {
         ex.printStackTrace()
diff --git a/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/autoagg/util/CommonUtil.java b/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/autoagg/util/CommonUtil.java
index ad3f917..bfd2bc9 100644
--- a/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/autoagg/util/CommonUtil.java
+++ b/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/autoagg/util/CommonUtil.java
@@ -22,8 +22,6 @@ import com.huawei.datasight.molap.datastats.model.LoadModel;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperations;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperationsImpl;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory.FileType;
@@ -53,21 +51,16 @@ public final class CommonUtil
 		List<String> listOfValidSlices = new ArrayList<String>(10);
 		DataInputStream dataInputStream = null;
 		Gson gsonObjectToRead = new Gson();
-		
-		AtomicFileOperations fileOperation = new AtomicFileOperationsImpl(loadMetaPath, FileFactory.getFileType(loadMetaPath));
-		
 		try
 		{
 			if (FileFactory.isFileExist(loadMetaPath,
 					FileFactory.getFileType(loadMetaPath)))
 			{
-			    
-			    dataInputStream = fileOperation.openForRead();
-			    
-				/*dataInputStream = FileFactory.getDataInputStream(
+
+				dataInputStream = FileFactory.getDataInputStream(
 						loadMetaPath,
 						FileFactory.getFileType(loadMetaPath));
-*/
+
 				BufferedReader buffReader = new BufferedReader(
 						new InputStreamReader(dataInputStream, "UTF-8"));
 
diff --git a/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/analysis/AggDataSuggestScanner.java b/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/analysis/AggDataSuggestScanner.java
index 927dac3..79ffafc 100644
--- a/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/analysis/AggDataSuggestScanner.java
+++ b/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/analysis/AggDataSuggestScanner.java
@@ -1,15 +1,10 @@
 package com.huawei.datasight.molap.datastats.analysis;
 
-import java.io.DataOutputStream;
-import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
 
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
 import com.huawei.unibi.molap.engine.columnar.keyvalue.AbstractColumnarScanResult;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 
@@ -34,7 +29,8 @@ public class AggDataSuggestScanner extends AbstractColumnarScanResult
 	public void setKeyBlock(
 			ColumnarKeyStoreDataHolder[] columnarKeyStoreDataHolder)
 	{
-		super.setKeyBlock(columnarKeyStoreDataHolder);
+		//need uncomment
+		//super.setKeyBlock(columnarKeyStoreDataHolder);
 		dataBlock = new byte[columnarKeyStoreDataHolder.length][];
 		dataBlockSize = new int[columnarKeyStoreDataHolder.length];
 		for (int i = 0; i < columnarKeyStoreDataHolder.length; i++)
@@ -117,10 +113,6 @@ public class AggDataSuggestScanner extends AbstractColumnarScanResult
 	{
 		return null;
 	}
-	public List<byte[]> getKeyArrayWithComplexTypes(Map<Integer, GenericQueryType> complexQueryDims)
-	{
-		return null;
-	}
 
 	@Override
 	public int getDimDataForAgg(int dimOrdinal)
@@ -130,13 +122,6 @@ public class AggDataSuggestScanner extends AbstractColumnarScanResult
 	}
 
 	@Override
-	public void getComplexDimDataForAgg(GenericQueryType complexType,
-			DataOutputStream dataOutputStream) throws IOException {
-		// TODO Auto-generated method stub
-		
-	}
-
-	@Override
 	public byte[] getKeyArray(ByteArrayWrapper key) {
 		// TODO Auto-generated method stub
 		return null;
diff --git a/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/load/FactDataNode.java b/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/load/FactDataNode.java
index 5b43237..cfed463 100644
--- a/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/load/FactDataNode.java
+++ b/Molap/Molap-Aggregation/src/main/java/com/huawei/datasight/molap/datastats/load/FactDataNode.java
@@ -35,7 +35,7 @@ public class FactDataNode
 		this.maxKeys = maxKeys;
 		
 		ColumnarKeyStoreInfo columnarStoreInfo = MolapUtil
-				.getColumnarKeyStoreInfo(leafNodeInfo, eachBlockSize);
+				.getColumnarKeyStoreInfo(leafNodeInfo, eachBlockSize,null);
 		keyStore = StoreFactory.createColumnarKeyStore(columnarStoreInfo,
 				fileHolder, isFileStore);
 
diff --git a/Molap/Molap-Core/.settings/org.eclipse.jdt.core.prefs b/Molap/Molap-Core/.settings/org.eclipse.jdt.core.prefs
index d95b340..574fe12 100644
--- a/Molap/Molap-Core/.settings/org.eclipse.jdt.core.prefs
+++ b/Molap/Molap-Core/.settings/org.eclipse.jdt.core.prefs
@@ -1,15 +1,4 @@
 eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled
-org.eclipse.jdt.core.compiler.codegen.methodParameters=do not generate
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.7
-org.eclipse.jdt.core.compiler.codegen.unusedLocal=preserve
-org.eclipse.jdt.core.compiler.compliance=1.7
-org.eclipse.jdt.core.compiler.debug.lineNumber=generate
-org.eclipse.jdt.core.compiler.debug.localVariable=generate
-org.eclipse.jdt.core.compiler.debug.sourceFile=generate
-org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
-org.eclipse.jdt.core.compiler.problem.enumIdentifier=error
-org.eclipse.jdt.core.compiler.source=1.7
 org.eclipse.jdt.core.formatter.align_type_members_on_columns=false
 org.eclipse.jdt.core.formatter.alignment_for_arguments_in_allocation_expression=16
 org.eclipse.jdt.core.formatter.alignment_for_arguments_in_annotation=0
diff --git a/Molap/Molap-Core/src/com/huawei/datasight/molap/core/load/LoadMetadataDetails.java b/Molap/Molap-Core/src/com/huawei/datasight/molap/core/load/LoadMetadataDetails.java
index 2a75f66..82c8fd7 100644
--- a/Molap/Molap-Core/src/com/huawei/datasight/molap/core/load/LoadMetadataDetails.java
+++ b/Molap/Molap-Core/src/com/huawei/datasight/molap/core/load/LoadMetadataDetails.java
@@ -15,11 +15,11 @@ public class LoadMetadataDetails implements Serializable {
 	private String loadStatus;
 	private String loadName;
 	private String partitionCount;
+//	private String deletionStatus;
 	private String deletionTimestamp;
     public final String  versionNumber= MolapVersion.getDataVersion();
     private String loadStartTime;
     
-    private String mergedLoadName;
     /**
      * visibility is used to determine whether to the load is visible or not.
      */
@@ -57,7 +57,23 @@ public class LoadMetadataDetails implements Serializable {
 		this.loadName = loadName;
 	}
 	
+	
+
 	/**
+	 * @return the deletionStatus
+	 *//*
+	public String getDeletionStatus() {
+		return deletionStatus;
+	}
+
+	*//**
+	 * @param deletionStatus the deletionStatus to set
+	 *//*
+	public void setDeletionStatus(String deletionStatus) {
+		this.deletionStatus = deletionStatus;
+	}
+*/
+    /**
      * @return the deletionTimestamp
      */
     public String getDeletionTimestamp()
@@ -135,21 +151,6 @@ public class LoadMetadataDetails implements Serializable {
     }
 
     /**
-     * @return the mergedLoadName
-     */
-    public String getMergedLoadName()
-    {
-        return mergedLoadName;
-    }
-
-    /**
-     * @param mergedLoadName the mergedLoadName to set
-     */
-    public void setMergedLoadName(String mergedLoadName)
-    {
-        this.mergedLoadName = mergedLoadName;
-    }
-    /**
      * @return the visibility
      */
     public String getVisibility()
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/constants/MolapCommonConstants.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/constants/MolapCommonConstants.java
index 6ca8adc..6c667fb 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/constants/MolapCommonConstants.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/constants/MolapCommonConstants.java
@@ -724,7 +724,7 @@ public final class MolapCommonConstants
      * GRAPH_ROWSET_SIZE_DEFAULT
      */
     public static final String GRAPH_ROWSET_SIZE_DEFAULT="500";
-       /**
+    /**
      * 
      * Comment for <code>TYPE_MYSQL</code>
      * 
@@ -1155,7 +1155,7 @@ public final class MolapCommonConstants
      * MOLAP_DATALOAD_VALID_CSVFILE_SIZE_DEFAULTVALUE
      */
     public static final String MOLAP_DATALOAD_VALID_NUMBAER_OF_CSVFILE_DEFAULTVALUE = "100";
-    
+       
     /**
      * MOLAP_IS_GROUPBY_IN_SORT_DEFAULTVALUE
      */
@@ -1460,10 +1460,6 @@ public final class MolapCommonConstants
     
     public static final String TIMESTAMP_TYPE = "TimestampType";
     
-    public static final String ARRAY_TYPE = "ArrayType";
-    
-    public static final String STRUCT_TYPE = "StructType";
-    
     public static final String BYTE_TYPE = "ByteType";
     
     public static final String SHORT_TYPE = "ShortType";
@@ -1482,10 +1478,6 @@ public final class MolapCommonConstants
     
     public static final String TIMESTAMP = "Timestamp";
     
-    public static final String ARRAY = "Array";
-    
-    public static final String STRUCT = "Struct";
-    
     public static final String INCLUDE = "include";
     
     public static final String FROM = "from";
@@ -1656,56 +1648,6 @@ public final class MolapCommonConstants
     public static final boolean  MOLAP_PREFETCH_IN_MERGE_VALUE = false;
     
     
-	
-	/**
-	 * TEMPWRITEFILEEXTENSION
-	 */
-    public static final String TEMPWRITEFILEEXTENSION = ".write";
-
-	 /**
-      * MERGE_THRESHOLD_VALUE
-      */
-     public static final String MERGE_THRESHOLD_VALUE = "molap.merge.threshold";
-
-     /**
-      * MERGE_THRESHOLD_DEFAULT_VAL
-      */
-     public static final String MERGE_THRESHOLD_DEFAULT_VAL = "10";
-
-     /**
-      * MERGE_FACTSIZE_THRESHOLD_VALUE
-      */
-    public static final String MERGE_FACTSIZE_THRESHOLD_VALUE = "molap.merge.factsize.threshold";
-
-    /**
-     * MERGE_FACTSIZE_THRESHOLD_DEFAULT_VAL
-     */
-    public static final String MERGE_FACTSIZE_THRESHOLD_DEFAULT_VAL = "10";
-    
-    /**
-     * MARKED_FOR_MERGE
-     */
-    public static final String MARKED_FOR_MERGE = "Marked For Merge";
-
-    /**
-     * TO_LOAD_MERGE_MAX_SIZE
-     */
-    public static final String TO_LOAD_MERGE_MAX_SIZE = "to.merge.load.max.size";
-
-    /**
-     * TO_LOAD_MERGE_MAX_SIZE_DEFAULT
-     */
-    public static final String TO_LOAD_MERGE_MAX_SIZE_DEFAULT = "1";
-    
-    /**
-     * ENABLE_LOAD_MERGE
-     */
-    public static final String ENABLE_LOAD_MERGE="molap.enable.load.merge";
-    
-    /**
-     * DEFAULT_ENABLE_LOAD_MERGE
-     */
-    public static final String DEFAULT_ENABLE_LOAD_MERGE="false";
 }
 
 
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/BlockIndexerStorageForInt.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/BlockIndexerStorageForInt.java
index 12d95f9..1a6af26 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/BlockIndexerStorageForInt.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/BlockIndexerStorageForInt.java
@@ -23,30 +23,20 @@ public class BlockIndexerStorageForInt implements IndexStorage<int[]>
 
     public BlockIndexerStorageForInt(byte[][] keyBlock)
     {
-        this(keyBlock, false, false, true);
+        this(keyBlock, false,true,false);
     }
-    
-    public BlockIndexerStorageForInt(byte[][] keyBlock, boolean compressData, boolean isSortRequired)
+
+    public BlockIndexerStorageForInt(byte[][] keyBlock, boolean compressData,boolean isHighCardinality,boolean isRowBlock)
     {
-        ColumnWithIntIndex[] columnWithIndexs = createColumnWithIndexArray(keyBlock,false);
-        if(isSortRequired)
-        {
-            Arrays.sort(columnWithIndexs);
-        }
-        compressMyOwnWay(extractDataAndReturnIndexes(columnWithIndexs, keyBlock));
-        if(compressData)
+        this.keyBlock=keyBlock;
+        //in case of row block sort is not required
+        if(isRowBlock)
         {
-            compressDataMyOwnWay(columnWithIndexs);
+            this.alreadySorted=true;
+            return;
         }
-    }
-    
-    public BlockIndexerStorageForInt(byte[][] keyBlock, boolean compressData, boolean isHighCardinality, boolean isSortRequired)
-    {
         ColumnWithIntIndex[] columnWithIndexs = createColumnWithIndexArray(keyBlock,isHighCardinality);
-        if(isSortRequired)
-        {
-            Arrays.sort(columnWithIndexs);
-        }
+        Arrays.sort(columnWithIndexs);
         compressMyOwnWay(extractDataAndReturnIndexes(columnWithIndexs, keyBlock));
         if(compressData)
         {
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreDataHolder.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreDataHolder.java
index e556a18..893ec31 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreDataHolder.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreDataHolder.java
@@ -2,20 +2,37 @@ package com.huawei.unibi.molap.datastorage.store.columnar;
 
 import java.nio.ByteBuffer;
 
+import com.huawei.unibi.molap.datastorage.store.KeyStoreDataHolder;
 
 
-public class ColumnarKeyStoreDataHolder
+
+public class ColumnarKeyStoreDataHolder implements KeyStoreDataHolder
 {
     private byte[] keyblockData;
     
     private ColumnarKeyStoreMetadata columnarKeyStoreMetadata;
     
+    private int rowStoreDimOrdinal;
+    
     public ColumnarKeyStoreDataHolder(final byte[] keyblockData,final ColumnarKeyStoreMetadata columnarKeyStoreMetadata)
     {
         this.keyblockData=keyblockData;
         this.columnarKeyStoreMetadata=columnarKeyStoreMetadata;
     }
     
+    /**
+     * In case of Row store, pass dimension index
+     * @param rowStoreData
+     * @param columnarKeyStoreMetadata
+     * @param blockIndex
+     */
+    public ColumnarKeyStoreDataHolder(byte[] rowStoreData, ColumnarKeyStoreMetadata columnarKeyStoreMetadata,
+            int blockIndex)
+    {
+       this(rowStoreData,columnarKeyStoreMetadata);
+       this.rowStoreDimOrdinal=blockIndex;
+    }
+
     public byte[] getKeyBlockData()
     {
         return keyblockData;
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreInfo.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreInfo.java
index b56c559..f87922b 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreInfo.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreInfo.java
@@ -1,6 +1,8 @@
 package com.huawei.unibi.molap.datastorage.store.columnar;
 
+import com.huawei.unibi.molap.datastorage.store.NodeKeyStore;
 import com.huawei.unibi.molap.keygenerator.mdkey.NumberCompressor;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 
 public class ColumnarKeyStoreInfo
@@ -27,6 +29,8 @@ public class ColumnarKeyStoreInfo
     
     private NumberCompressor[] keyBlockUnCompressor;
     
+    private HybridStoreModel hybridStoreMeta;
+    
     /**
      * dataIndexMap
      */
@@ -43,6 +47,17 @@ public class ColumnarKeyStoreInfo
      */
     private boolean[] aggKeyBlock;
     
+    
+    /**
+     * row based stores
+     */
+    private NodeKeyStore rowKeyStore;
+
+    /**
+     * dimension ordinal which is stored as row store
+     */
+    private int[] rowStoreOrdinals;
+    
     /**
      * @return the numberOfKeys
      */
@@ -260,4 +275,35 @@ public class ColumnarKeyStoreInfo
     {
         this.cardinality = cardinality;
     }
+
+    public void setRowKeyStore(NodeKeyStore rowKeyStore)
+    {
+       this.rowKeyStore = rowKeyStore;
+    }
+    
+    public NodeKeyStore getRowKeyStore()
+    {
+        return this.rowKeyStore;
+    }
+
+    public void setRowStoreOrdinals(int[] rowStoreOrdinals)
+    {
+       this.rowStoreOrdinals = rowStoreOrdinals;
+    }
+    
+    public int[] getRowStoreOrdinals()
+    {
+        return this.rowStoreOrdinals;
+    }
+
+    public HybridStoreModel getHybridStoreMeta()
+    {
+        return hybridStoreMeta;
+    }
+
+    public void setHybridStoreMeta(HybridStoreModel hybridStoreMeta)
+    {
+        this.hybridStoreMeta = hybridStoreMeta;
+    }
+    
 }
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreMetadata.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreMetadata.java
index 2820eb4..37ec0a5 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreMetadata.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/columnar/ColumnarKeyStoreMetadata.java
@@ -33,8 +33,8 @@ public class ColumnarKeyStoreMetadata
      */
     private Map<Integer, byte[]> mapOfColumnarKeyBlockData;
     
-
-
+    private boolean isRowStore;
+    
     public ColumnarKeyStoreMetadata(int eachRowSize)
     {
         this.eachRowSize=eachRowSize;
@@ -128,6 +128,16 @@ public class ColumnarKeyStoreMetadata
         return keyGenerator;
     }
 
+    public boolean isRowStore()
+    {
+        return isRowStore;
+    }
+
+    public void setRowStore(boolean isRowStore)
+    {
+        this.isRowStore = isRowStore;
+    }
+
     /**
      * 
      * @param isDirectSurrogateColumn
@@ -164,4 +174,8 @@ public class ColumnarKeyStoreMetadata
     {
         return mapOfColumnarKeyBlockData;
     }
+    public void setKeyGenerator(KeyGenerator keyGenerator)
+    {
+        this.keyGenerator=keyGenerator;
+    }
 }
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/dataholder/MolapWriteDataHolder.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/dataholder/MolapWriteDataHolder.java
index b87e446..d41b714 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/dataholder/MolapWriteDataHolder.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/dataholder/MolapWriteDataHolder.java
@@ -11,6 +11,8 @@
  */
 package com.huawei.unibi.molap.datastorage.store.dataholder;
 
+import com.huawei.unibi.molap.datastorage.store.NodeKeyStore;
+
 /**
  * Project Name NSE V3R8C10 
  * Module Name : MOLAP Data Processor
@@ -31,11 +33,6 @@ public class MolapWriteDataHolder
      * byteValues
      */
     private byte[][] byteValues;
-
-    /**
-     * byteValues
-     */
-    private byte[][][] columnByteValues;
     
     /**
      * size
@@ -46,7 +43,7 @@ public class MolapWriteDataHolder
      * totalSize
      */
     private int totalSize;
-    
+
     /**
      * Method to initialise double array
      * @param size
@@ -72,7 +69,6 @@ public class MolapWriteDataHolder
         }
         
         byteValues= new byte[size][];
-        columnByteValues= new byte[size][][];
     }
     /**
      * set double value by index
@@ -97,21 +93,6 @@ public class MolapWriteDataHolder
         if(null != value)
         totalSize+=value.length;
     }
-
-    /**
-     * set byte array value by index
-     * @param index
-     * @param value
-     */
-    public void setWritableByteArrayValueByIndex(int index, int mdKeyIndex, Object[] columnData)
-    {
-        int l=0;
-        columnByteValues[index] = new byte[columnData.length - (mdKeyIndex+1)][];
-        for(int i=mdKeyIndex+1;i<columnData.length;i++)
-        {
-            columnByteValues[index][l++]=(byte[])columnData[i];
-        }
-    }
     
     /**
      * Get Writable Double Values
@@ -155,20 +136,10 @@ public class MolapWriteDataHolder
         return byteValues;
     }
     
-    public byte[][][] getColumnByteArrayValues()
-    {
-        if(size<columnByteValues.length)
-        {
-            byte[][][] temp = new byte[size][][];
-            System.arraycopy(columnByteValues, 0, temp, 0, size);
-            columnByteValues=temp;
-        }
-        return columnByteValues;
-    }
-    
     public void reset()
     {
         size=0;
         totalSize=0;
     }
+   
 }
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/AtomicFileOperations.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/AtomicFileOperations.java
deleted file mode 100644
index 205cc70..0000000
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/AtomicFileOperations.java
+++ /dev/null
@@ -1,37 +0,0 @@
-/**
- * 
- */
-package com.huawei.unibi.molap.datastorage.store.fileperations;
-
-import java.io.DataInputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-
-/**
- * @author R00903928
- *
- */
-public interface AtomicFileOperations
-{
-
-    /**
-     * 
-     * @return
-     * @throws IOException
-     */
-    DataInputStream openForRead() throws IOException;
-    
-    /**
-     * @throws IOException 
-     * 
-     */
-    void close() throws IOException;
-
-    /**
-     * 
-     * @param operation
-     * @return
-     * @throws IOException
-     */
-    DataOutputStream openForWrite(FileWriteOperation operation) throws IOException;
-}
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/AtomicFileOperationsImpl.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/AtomicFileOperationsImpl.java
deleted file mode 100644
index eab0d05..0000000
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/AtomicFileOperationsImpl.java
+++ /dev/null
@@ -1,103 +0,0 @@
-/**
- * 
- */
-package com.huawei.unibi.molap.datastorage.store.fileperations;
-
-import java.io.DataInputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-
-import com.huawei.unibi.molap.constants.MolapCommonConstants;
-import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
-import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
-import com.huawei.unibi.molap.datastorage.store.impl.FileFactory.FileType;
-import com.huawei.unibi.molap.util.MolapUtil;
-
-/**
- * @author R00903928
- *
- */
-public class AtomicFileOperationsImpl implements AtomicFileOperations
-{
-    
-    private String filePath;
-    
-    private FileType fileType;
-    
-    private String tempWriteFilePath;
-    
-    private DataOutputStream dataOutStream;
-    
-    /**
-     * 
-     * @param filePath
-     * @param fileType
-     */
-    public AtomicFileOperationsImpl(String filePath , FileType fileType)
-    {
-        this.filePath = filePath;
-        
-        this.fileType = fileType;
-    }
-    
-
-    /**
-     * 
-     * @return DataInputStream
-     * @throws IOException
-     */
-    @Override
-    public DataInputStream openForRead() throws IOException
-    {
-        return FileFactory.getDataInputStream(filePath, fileType);
-    }
-
-    /**
-     * 
-     * @param operation
-     * @return DataOutputStream
-     * @throws IOException
-     */
-    @Override
-    public DataOutputStream openForWrite(FileWriteOperation operation) throws IOException
-    {
-
-        filePath = filePath.replace("\\", "/");
-
-        tempWriteFilePath = filePath + MolapCommonConstants.TEMPWRITEFILEEXTENSION;
-
-        if(FileFactory.isFileExist(tempWriteFilePath, fileType))
-        {
-            FileFactory.getMolapFile(tempWriteFilePath, fileType).delete();
-        }
-
-        FileFactory.createNewFile(tempWriteFilePath, fileType);
-
-        dataOutStream =  FileFactory.getDataOutputStream(tempWriteFilePath, fileType);
-        
-        return dataOutStream;
-
-    }
-
-    /* (non-Javadoc)
-     * @see com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperations#close()
-     */
-    @Override
-    public void close() throws IOException
-    {
-     
-        if(null != dataOutStream)
-        {
-            dataOutStream.close();
-
-            MolapFile tempFile = FileFactory.getMolapFile(tempWriteFilePath, fileType);
-
-            if(!tempFile.renameForce(filePath))
-            {
-                throw new IOException("temporary file renaming failed");
-            }
-        }
-                
-    }
-
-}
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/FileWriteOperation.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/FileWriteOperation.java
deleted file mode 100644
index dc21768..0000000
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/fileperations/FileWriteOperation.java
+++ /dev/null
@@ -1,13 +0,0 @@
-/**
- * 
- */
-package com.huawei.unibi.molap.datastorage.store.fileperations;
-
-/**
- * @author R00903928
- *
- */
-public enum FileWriteOperation {
-    
-    APPEND,OVERWRITE
-}
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/impl/key/columnar/compressed/CompressedColumnarFileKeyStore.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/impl/key/columnar/compressed/CompressedColumnarFileKeyStore.java
index b0ee32d..42865e1 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/impl/key/columnar/compressed/CompressedColumnarFileKeyStore.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/datastorage/store/impl/key/columnar/compressed/CompressedColumnarFileKeyStore.java
@@ -101,6 +101,10 @@ public class CompressedColumnarFileKeyStore extends AbstractColumnarKeyStore
             columnarKeyStoreMetadata.setDataIndex(dataIndex);
             columnarKeyStoreMetadata.setColumnReverseIndex(columnKeyBlockReverseIndexes);
             columnarKeyStoreMetadata.setUnCompressed(isUnCompressed);
+            if(columnarStoreInfo.getHybridStoreMeta().isHybridStore() && blockIndex[i]==0)
+            {
+                columnarKeyStoreMetadata.setRowStore(true);
+            }
             columnarKeyStoreDataHolders[i] = new ColumnarKeyStoreDataHolder(
                     columnarKeyBlockData,columnarKeyStoreMetadata);
             }
@@ -199,6 +203,10 @@ public class CompressedColumnarFileKeyStore extends AbstractColumnarKeyStore
         columnarKeyStoreMetadata.setDataIndex(dataIndex);
         columnarKeyStoreMetadata.setColumnReverseIndex(columnKeyBlockReverseIndex);
         columnarKeyStoreMetadata.setUnCompressed(isUnCompressed);
+        if(columnarStoreInfo.getHybridStoreMeta().isHybridStore() && blockIndex==0)
+        {
+            columnarKeyStoreMetadata.setRowStore(true);
+        }
         ColumnarKeyStoreDataHolder columnarKeyStoreDataHolders = new ColumnarKeyStoreDataHolder(columnarKeyBlockData,
                 columnarKeyStoreMetadata);
         return columnarKeyStoreDataHolders;
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/KeyGenerator.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/KeyGenerator.java
index 0f053f9..ad0c3c5 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/KeyGenerator.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/KeyGenerator.java
@@ -99,8 +99,4 @@ public interface KeyGenerator extends Serializable, Comparator<byte[]>
      * @return
      */
     int getDimCount();
-    
-    void setStartAndEndKeySizeWithOnlyPrimitives(int startAndEndKeySizeWithPrimitives);
-    
-    int getStartAndEndKeySizeWithOnlyPrimitives();
 }
\ No newline at end of file
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/columnar/impl/MultiDimKeyVarLengthVariableSplitGenerator.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/columnar/impl/MultiDimKeyVarLengthVariableSplitGenerator.java
new file mode 100644
index 0000000..4c720b1
--- /dev/null
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/columnar/impl/MultiDimKeyVarLengthVariableSplitGenerator.java
@@ -0,0 +1,250 @@
+package com.huawei.unibi.molap.keygenerator.columnar.impl;
+
+import java.util.ArrayList;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
+import java.util.TreeSet;
+
+import com.huawei.unibi.molap.constants.MolapCommonConstants;
+import com.huawei.unibi.molap.keygenerator.KeyGenException;
+import com.huawei.unibi.molap.keygenerator.columnar.ColumnarSplitter;
+import com.huawei.unibi.molap.keygenerator.mdkey.MultiDimKeyVarLengthGenerator;
+
+public class MultiDimKeyVarLengthVariableSplitGenerator extends MultiDimKeyVarLengthGenerator implements ColumnarSplitter
+{
+
+    /**
+     * 
+     */
+    private static final long serialVersionUID = 1L;
+    
+    private int[] dimensionsToSplit;
+    
+    private int[] blockKeySize;
+    
+    public MultiDimKeyVarLengthVariableSplitGenerator(int[] lens,int[] dimSplit)
+    {
+        super(lens);
+        this.dimensionsToSplit =dimSplit;
+        initialise();
+
+    }
+
+    private void initialise()
+    {
+        int s = 0;
+        List<Set<Integer>> splitList = new ArrayList<Set<Integer>>(MolapCommonConstants.CONSTANT_SIZE_TEN);
+        Set<Integer> split = new TreeSet<Integer>();
+        splitList.add(split);
+        int dimSplitIndx=0;
+      
+        for(int i = 0;i < byteRangesForKeys.length;i++)
+        {
+            if(s == dimensionsToSplit[dimSplitIndx]) {
+                s = 0;
+                split = new TreeSet<Integer>();
+                splitList.add(split);
+                dimSplitIndx++;
+            }
+            for(int j = 0;j < byteRangesForKeys[i].length;j++)
+            {
+                for(int j2 = byteRangesForKeys[i][0];j2 <= byteRangesForKeys[i][1];j2++)
+                {
+                    split.add(j2);
+                }
+            }
+            s++;
+            
+        }
+        List<Integer>[] splits = new List[splitList.size()];
+        int i = 0;
+        for(Set<Integer> splitLocal : splitList)
+        {
+            List<Integer> range = new ArrayList<Integer>(MolapCommonConstants.CONSTANT_SIZE_TEN);
+            for(Integer index : splitLocal)
+            {
+                range.add(index);
+            }
+            splits[i++] = range;
+        }
+        for(int j = 1;j < splits.length;j++)
+        {
+            if(splits[j-1].get(splits[j-1].size()-1) == splits[j].get(0))
+            {
+                splits[j].remove(0);
+            }
+        }
+        int[][] splitDimArray = new int[splits.length][];
+        for(int j = 0;j < splits.length;j++)
+        {
+            int[] a = convertToArray(splits[j]);
+            splitDimArray[j] = new int[]{a[0], a[a.length-1]};
+        }
+
+        int[][] dimBlockArray = new int[byteRangesForKeys.length][];
+        Set<Integer>[] dimBlockSet = new Set[dimBlockArray.length];
+        for(int k = 0;k < byteRangesForKeys.length;k++)
+        {
+            int[] dimRange = byteRangesForKeys[k];
+            Set<Integer> dimBlockPosSet = new TreeSet<Integer>(); 
+            dimBlockSet[k] = dimBlockPosSet;
+            for(int j = 0;j < splitDimArray.length;j++)
+            {
+                if(dimRange[0] >= splitDimArray[j][0] && dimRange[0] <= splitDimArray[j][1]) {
+                    dimBlockPosSet.add(j);
+                }
+                if(dimRange[1] >= splitDimArray[j][0] && dimRange[1] <= splitDimArray[j][1]) {
+                    dimBlockPosSet.add(j);
+                }
+            }
+            
+        }
+
+        for(int j = 0;j < dimBlockSet.length;j++)
+        {
+            dimBlockArray[j] = convertToArray(dimBlockSet[j]);
+        }
+        
+        int[][] splitDimArrayLocalIndexes = new int [splitDimArray.length][];
+        for(int j = 0;j < splitDimArrayLocalIndexes.length;j++)
+        {
+            splitDimArrayLocalIndexes[j] = new int[]{0, splitDimArray[j][1]-splitDimArray[j][0]};
+        }
+        
+        int[][][] byteRangesForDims = new int[byteRangesForKeys.length][][];
+        for(int j = 0;j < byteRangesForKeys.length;j++)
+        {
+            if(dimBlockArray[j].length > 1)
+            {
+                int[] bArray1 = splitDimArrayLocalIndexes[dimBlockArray[j][0]];
+                byteRangesForDims[j]=new int[2][2];
+                byteRangesForDims[j][0] = new int[] {bArray1[bArray1.length-1], bArray1[bArray1.length-1]};
+                byteRangesForDims[j][1] = new int[] {0, (byteRangesForKeys[j][byteRangesForKeys[j].length-1]-byteRangesForKeys[j][0])-1};
+            }
+            else
+            {
+                byteRangesForDims[j]=new int[1][1];
+                int[] bArray1 = splitDimArray[dimBlockArray[j][0]];
+                byteRangesForDims[j][0] = new int[] {byteRangesForKeys[j][0]-bArray1[0], byteRangesForKeys[j][1]-bArray1[0]};
+            }
+        }
+        blockKeySize = new int[splitDimArray.length];
+        
+        for(int j = 0;j < blockKeySize.length;j++)
+        {
+            blockKeySize[j]=splitDimArray[j][1]-splitDimArray[j][0]+1;
+        }
+        
+    }
+    
+    private int[] convertToArray(List<Integer> list)
+    {
+        int[] ints = new int[list.size()];
+        for(int i = 0;i < ints.length;i++)
+        {
+            ints[i] = list.get(i);
+        }
+        return ints;
+    }
+
+    private int[] convertToArray(Set<Integer> set)
+    {
+        int[] ints = new int[set.size()];
+        int i = 0;
+        for(Iterator iterator = set.iterator();iterator.hasNext();)
+        {
+            ints[i++] = (Integer)iterator.next();
+        }
+        return ints;
+    }
+
+    @Override
+    public byte[][] splitKey(byte[] key)
+    {
+        byte[][] split = new byte[blockKeySize.length][];
+        int copyIndex=0;
+        for(int i = 0;i < split.length;i++)
+        {
+            split[i] = new byte[blockKeySize[i]];
+            System.arraycopy(key, copyIndex, split[i], 0, split[i].length);
+            copyIndex+=blockKeySize[i];
+        }
+        return split;
+    }
+
+    @Override
+    public byte[][] generateAndSplitKey(long[] keys) throws KeyGenException
+    {
+        return splitKey(generateKey(keys));
+    }
+
+    @Override
+    public byte[][] generateAndSplitKey(int[] keys) throws KeyGenException
+    {
+        return splitKey(generateKey(keys));
+    }
+
+    @Override
+    public long[] getKeyArray(byte[][] key)
+    {
+        byte[] fullKey = new byte[getKeySizeInBytes()];
+        int copyIndex=0;
+        for(int i = 0;i < key.length;i++)
+        {
+            System.arraycopy(key[i], 0, fullKey, copyIndex, key[i].length);
+            copyIndex+=key[i].length;
+        }
+        return getKeyArray(fullKey);
+    }
+
+    @Override
+    public byte[] getKeyByteArray(byte[][] key)
+    {
+        byte[] fullKey = new byte[getKeySizeInBytes()];
+        int copyIndex=0;
+        for(int i = 0;i < key.length;i++)
+        {
+            System.arraycopy(key[i], 0, fullKey, copyIndex, key[i].length);
+            copyIndex+=key[i].length;
+        }
+        return fullKey;
+    }
+
+    @Override
+    public byte[] getKeyByteArray(byte[][] key, int[] columnIndexes)
+    {
+        return null;
+    }
+
+    @Override
+    public long[] getKeyArray(byte[][] key, int[] columnIndexes)
+    {
+        return null;
+    }
+    
+    public int[] getBlockKeySize()
+    {
+        return blockKeySize;
+    }
+    @Override
+    public int getKeySizeByBlock(int[] blockIndexes)
+    {
+        /*int size=0;
+        for(int i = 0;i < blockIndexes.length;i++)
+        {
+            size+=blockKeySize[blockIndexes[i]];
+        }
+        return size;*/
+        int size=0;
+        for(int i = 0;i < blockIndexes.length;i++)
+        {
+            if(blockIndexes[i] < blockKeySize.length)
+            {
+                size += blockKeySize[blockIndexes[i]];
+            }
+        }
+        return size;
+    }
+
+}
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/factory/KeyGeneratorFactory.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/factory/KeyGeneratorFactory.java
index 693e0a4..9ea72c1 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/factory/KeyGeneratorFactory.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/factory/KeyGeneratorFactory.java
@@ -53,5 +53,33 @@ public final class KeyGeneratorFactory
         }
         return new MultiDimKeyVarLengthGenerator(incrementedCardinality);
     }
+    /**
+     * @param dimesion
+     * @return
+     */
+    public static KeyGenerator getKeyGenerator(int []dimesion,boolean isFullyFilled)
+    {
+        int[] incrementedCardinality = null;
+        if(!isFullyFilled)
+        {
+            incrementedCardinality = MolapUtil
+                    .getIncrementedCardinality(dimesion);
+        }
+        else
+        {
+            incrementedCardinality = MolapUtil
+                    .getIncrementedCardinalityFullyFilled(dimesion);
+        }
+        return new MultiDimKeyVarLengthGenerator(incrementedCardinality);
+    }
+    
+    public static KeyGenerator getKeyGenerator(int[] dimCardinality,int[][] splits)
+    {
+        int[] dimsBitLens = MolapUtil.getDimensionBitLength(dimCardinality, splits);
+        
+        return new MultiDimKeyVarLengthGenerator(dimsBitLens);
+    }
+
+   
 }
 
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/AbstractKeyGenerator.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/AbstractKeyGenerator.java
index 04b3a53..ff21a67 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/AbstractKeyGenerator.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/AbstractKeyGenerator.java
@@ -84,5 +84,4 @@ public abstract class AbstractKeyGenerator implements KeyGenerator
         // TODO Auto-generated method stub
         return 0;
     }
-   
 }
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/MultiDimKeyVarLengthGenerator.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/MultiDimKeyVarLengthGenerator.java
index 1dfc295..1d1dc0a 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/MultiDimKeyVarLengthGenerator.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/keygenerator/mdkey/MultiDimKeyVarLengthGenerator.java
@@ -25,8 +25,6 @@ public class MultiDimKeyVarLengthGenerator extends AbstractKeyGenerator
      * bits.
      */
     private Bits bits;
-    
-    private int startAndEndKeySizeWithPrimitives;
 
     /**
      * 
@@ -148,18 +146,6 @@ public class MultiDimKeyVarLengthGenerator extends AbstractKeyGenerator
         return bits.getKeyArray(key, maskedByteRanges);
     }
 
-    @Override
-    public void setStartAndEndKeySizeWithOnlyPrimitives(int startAndEndKeySizeWithPrimitives)
-    {
-        this.startAndEndKeySizeWithPrimitives = startAndEndKeySizeWithPrimitives;
-    }
-
-    @Override
-    public int getStartAndEndKeySizeWithOnlyPrimitives()
-    {
-        return startAndEndKeySizeWithPrimitives;
-    }
-
     /**
      * @param args
      * @throws MalformedURLException
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/LeafNodeInfoColumnar.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/LeafNodeInfoColumnar.java
index 46fec14..10a319d 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/LeafNodeInfoColumnar.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/LeafNodeInfoColumnar.java
@@ -93,6 +93,7 @@ public class LeafNodeInfoColumnar
      */
     private byte[][] columnMinMaxData;
     
+    
     /**
      * getFileName().
      * @return String.
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/MolapMetadata.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/MolapMetadata.java
index 88bb6b7..8bde7e2 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/MolapMetadata.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/MolapMetadata.java
@@ -69,8 +69,6 @@ public final class MolapMetadata
     
     private final Lock writeLock = lock.writeLock();
 
-    public String parent;
-
     /**
      * create the instance of MolapMetadata.
      * @return MolapMetadata.
@@ -242,9 +240,9 @@ public final class MolapMetadata
         Map<String, String> levelsToColMap = loadMetaToCube(table, locCube, schema);
 
         List<Measure> measures = locCube.getMeasures(table);
-        prepareComplexDimensions(locCube.getDimensions(table));
-        HashMap<String, Measure> measuresMap = new HashMap<String, MolapMetadata.Measure>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
-        
+        HashMap<String, Measure> measuresMap = new HashMap<String, MolapMetadata.Measure>(
+                MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
+
         for(Measure measure : measures)
         {
             measuresMap.put("[Measures].[" + measure.getName() + ']', measure);
@@ -457,37 +455,7 @@ public final class MolapMetadata
         metaAggTableCols.add(aggTable.factcount.column);
         }
     }
-    
-    
-    private void prepareComplexDimensions(List<Dimension> currentDimTables)
-    {
-        Map<String, ArrayList<Dimension>> complexDimensions = new HashMap<String, ArrayList<Dimension>>();
-        for(int i = 0;i < currentDimTables.size();i++)
-        {
-            ArrayList<Dimension> dimensions = complexDimensions.get(currentDimTables.get(i).getHierName());
-            if(dimensions != null)
-            {
-                dimensions.add(currentDimTables.get(i));
-            }
-            else
-            {
-                dimensions = new ArrayList<Dimension>();
-                dimensions.add(currentDimTables.get(i));
-            }
-            complexDimensions.put(currentDimTables.get(i).getHierName(), dimensions);
-        }
-        
-        for (Map.Entry<String, ArrayList<Dimension>> entry : complexDimensions.entrySet())
-        {
-            int[] blockIndexsForEachComplexType = new int[entry.getValue().size()];
-            for(int i=0;i<entry.getValue().size();i++)
-            {
-                blockIndexsForEachComplexType[i] = entry.getValue().get(i).getDataBlockIndex();
-            }
-            entry.getValue().get(0).setAllApplicableDataBlockIndexs(blockIndexsForEachComplexType);
-        }
-    }
-    
+
     /**
      * Process all the dimensions and fact table.
      * @param table
@@ -525,7 +493,6 @@ public final class MolapMetadata
         int keyOrdinal;
         // index for normalizedList
         int indexNormalized = 0;
-        int blockIndex = 0;
         List<MolapMetadata.Dimension> normalizedDimList = new ArrayList<MolapMetadata.Dimension>(MolapCommonConstants.CONSTANT_SIZE_TEN);
         for(MondrianLevelHolder levHolder : levelList)
         {
@@ -550,13 +517,12 @@ public final class MolapMetadata
             //dimension.setNoOfbits((byte)Long.toBinaryString(lev.levelCardinality).length());
 //            dimension.setNoOfbits(lev.levelCardinality);
             dimension.setDataType(makeSQLDataTye(lev.type));
-            dimension.setParentName(lev.parentname);
             dimension.setOrdinalCol(false);
             dimension.setTableName(levHolder.molapTableName);
             dimension.setHierName(levHolder.molapHierName);
             dimension.setActualTableName(levHolder.actualTableName);
             dimension.setDimName(levHolder.molapDimName);
-            dimension.setDataBlockIndex(blockIndex++);
+            dimension.setColumnar(levHolder.rolapLevel.columnar);
             boolean hasNameColumn = hasNameColumn(lev);
             
             dimension.setNameColumnIndex(getNameColumnIndexInSchemaOrder(levHolder, levelList));
@@ -1547,57 +1513,29 @@ public final class MolapMetadata
         private boolean isQueryForDistinctCount;
         
         /**
-         * queryOrder
+         * store type
+         * true: columnar
+         * false: row
          */
-        protected int queryOrder;
+        private boolean isColumnar=true;
         
         /**
-         * parentName
-         */
-        private String parentName; 
-
-        private boolean highCardinalityDim;
-
-        /**
-         * dataBlockIndexs
-         */
-        private int dataBlockIndexs; 
-
-        /**
-         * dataBlockIndexs
+         * queryOrder
          */
-        private int[] allApplicableDataBlockIndexs; 
+        protected int queryOrder;
         
-        public void setAllApplicableDataBlockIndexs(int[] allApplicableDataBlockIndexs)
-        {
-            this.allApplicableDataBlockIndexs = allApplicableDataBlockIndexs;
-        }
         
-        public int[] getAllApplicableDataBlockIndexs()
-        {
-            return allApplicableDataBlockIndexs;
-        }
 
-        public int getDataBlockIndex()
-        {
-            return dataBlockIndexs;
-        }
-
-        public void setDataBlockIndex(int dataBlockIndexs)
-        {
-            this.dataBlockIndexs = dataBlockIndexs;
-        }
-
-        public String getParentName()
+        private boolean highCardinalityDim;
+        public boolean isColumnar()
         {
-            return parentName;
+            return isColumnar;
         }
 
-        public void setParentName(String parentName)
+        public void setColumnar(boolean isColumnar)
         {
-            this.parentName = parentName;
+            this.isColumnar = isColumnar;
         }
-
         /**
          * @return
          */
@@ -1724,7 +1662,6 @@ public final class MolapMetadata
             Dimension copy = new Dimension();
             copy.dataType = this.dataType;
             copy.colName = this.colName;
-            copy.parentName = this.parentName;
             copy.levelType = this.levelType;
             copy.name = this.name;
             copy.keyOrdinal = this.keyOrdinal;
@@ -1748,6 +1685,7 @@ public final class MolapMetadata
             copy.actualTableName=this.actualTableName;
             copy.isQueryForDistinctCount=this.isQueryForDistinctCount;
             copy.queryOrder=queryOrder;
+            copy.isColumnar=isColumnar;
             return copy;
         }
 
@@ -2204,11 +2142,7 @@ public final class MolapMetadata
             this.queryOrder = queryOrder;
         }
 
-        public void getParent()
-        {
-            // TODO Auto-generated method stub
-            
-        }
+
     }
 //CHECKSTYLE:OFF    Approval No:Approval-257
     /**
@@ -2239,11 +2173,6 @@ public final class MolapMetadata
         private Map<String, List<Dimension>> hierarchiesMapping = new LinkedHashMap<String, List<Dimension>>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
 
         /**
-         * complexTypeMapping
-         */
-//        private Map<String, HashMap<Integer, ComplexColumnMetadata>> complexTypesMap = new HashMap<String, HashMap<Integer, ComplexColumnMetadata>>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
-
-        /**
          * TableName, columns list [Meta data i.e. from original database]
          */
         private Map<String, Set<String>> metaTables = new HashMap<String, Set<String>>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
@@ -2418,21 +2347,6 @@ public final class MolapMetadata
             return null;
         }
 
-        public List<Dimension> getChildren(String dimName) {
-            List<Dimension> retList = new ArrayList<Dimension>();
-            for(List<Dimension> list : dimensions.values())
-            {
-                for(Dimension dimension : list)
-                {
-                    if(null != dimension.getParentName() && 
-                            dimension.getParentName().equalsIgnoreCase(dimName)){
-                        retList.add(dimension);
-                    }
-                }
-            }
-            return retList;
-        }
-        
         /**
          * Find Dimension by column name
          */
@@ -2834,8 +2748,6 @@ public final class MolapMetadata
         TYPESMAPPING.put("Date", SqlStatement.Type.OBJECT);
         TYPESMAPPING.put("Time", SqlStatement.Type.OBJECT);
         TYPESMAPPING.put("Timestamp", SqlStatement.Type.TIMESTAMP);
-        TYPESMAPPING.put("Array", SqlStatement.Type.ARRAY);
-        TYPESMAPPING.put("Struct", SqlStatement.Type.STRUCT);
     }//CHECKSTYLE:ON
 //CHECKSTYLE:OFF    Approval No:Approval-374
     /**
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/SliceMetaData.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/SliceMetaData.java
index 4aa0b61..330f17b 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/SliceMetaData.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/metadata/SliceMetaData.java
@@ -27,18 +27,6 @@ public class SliceMetaData implements Serializable
      */
     private String[] dimensions;
     
-    private String complexTypeString;
-    
-    public String getComplexTypeString()
-    {
-        return complexTypeString;
-    }
-
-    public void setComplexTypeString(String complexTypeString)
-    {
-        this.complexTypeString = complexTypeString;
-    }
-
     /**
      *actualDimensions 
      */
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/MolapDef.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/MolapDef.java
index b0f49f6..3e855e5 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/MolapDef.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/MolapDef.java
@@ -312,6 +312,7 @@ Cube getCube(String cubeName) {
         public String description;  // optional attribute
         public String foreignKey;  // optional attribute
         public Boolean highCardinality;  // attribute default: false
+        public Boolean columnar=true;
 
         /**
          * Contains values of user-defined properties.
@@ -1343,7 +1344,6 @@ public boolean isEnabled() {
                 org.eigenbase.xom.NodeDef[] _tempArray;
                 approxRowCount = (String)_parser.getAttribute("approxRowCount", "String", null, null, false);
                 name = (String)_parser.getAttribute("name", "String", null, null, false);
-                parentname = (String)_parser.getAttribute("parentname", "String", null, null, false);
                 visible = (Boolean)_parser.getAttribute("visible", "Boolean", "true", null, false);
                 columnIndex = (Integer)_parser.getAttribute("columnIndex", "Integer", "-1", null, false);
                 keyOrdinal = (Integer)_parser.getAttribute("keyOrdinal", "Integer", "-1", null, false);
@@ -1359,6 +1359,7 @@ public boolean isEnabled() {
                 type = (String)_parser.getAttribute("type", "String", "String", _type_values, false);
                 internalType = (String)_parser.getAttribute("internalType", "String", null, _internalType_values, false);
                 uniqueMembers = (Boolean)_parser.getAttribute("uniqueMembers", "Boolean", "false", null, false);
+                columnar = (Boolean)_parser.getAttribute("columnar", "Boolean", "true", null, false);
                 levelType = (String)_parser.getAttribute("levelType", "String", "Regular", _levelType_values, false);
                 hideMemberIf = (String)_parser.getAttribute("hideMemberIf", "String", "Never", _hideMemberIf_values, false);
                 formatter = (String)_parser.getAttribute("formatter", "String", null, null, false);
@@ -1385,7 +1386,6 @@ public boolean isEnabled() {
 
         public String approxRowCount;  // optional attribute
         public String name;  // optional attribute
-        public String parentname; // optional attribute
         public Boolean visible;  // attribute default: true
         public Integer columnIndex;  // attribute default: -1
         public Integer keyOrdinal;  // attribute default: -1
@@ -1399,12 +1399,13 @@ public boolean isEnabled() {
         public String parentColumn;  // optional attribute
         public String nullParentValue;  // optional attribute
         /** Allowable values for {@link #type}. */
-        public static final String[] _type_values = {"String", "Numeric", "Integer", "Boolean", "Date", "Time", "Timestamp", "Array", "Struct"};
+        public static final String[] _type_values = {"String", "Numeric", "Integer", "Boolean", "Date", "Time", "Timestamp"};
         public String type;  // attribute default: String
         /** Allowable values for {@link #internalType}. */
         public static final String[] _internalType_values = {"int", "long", "Object", "String"};
         public String internalType;  // optional attribute
         public Boolean uniqueMembers;  // attribute default: false
+        public Boolean columnar=true;
         /** Allowable values for {@link #levelType}. */
         public static final String[] _levelType_values = {"Regular", "TimeYears", "TimeHalfYears", "TimeHalfYear", "TimeQuarters", "TimeMonths", "TimeWeeks", "TimeDays", "TimeHours", "TimeMinutes", "TimeSeconds", "TimeUndefined"};
         public String levelType;  // attribute default: Regular
@@ -1461,7 +1462,6 @@ public boolean isEnabled() {
             _out.println(getName());
             displayAttribute(_out, "approxRowCount", approxRowCount, _indent+1);
             displayAttribute(_out, "name", name, _indent+1);
-            displayAttribute(_out, "parentname", parentname, _indent+1);
             displayAttribute(_out, "visible", visible, _indent+1);
             displayAttribute(_out, "columnIndex", columnIndex, _indent+1);
             displayAttribute(_out, "keyOrdinal", keyOrdinal, _indent+1);
@@ -1477,6 +1477,7 @@ public boolean isEnabled() {
             displayAttribute(_out, "type", type, _indent+1);
             displayAttribute(_out, "internalType", internalType, _indent+1);
             displayAttribute(_out, "uniqueMembers", uniqueMembers, _indent+1);
+            displayAttribute(_out,"columnar",columnar,_indent+1);
             displayAttribute(_out, "levelType", levelType, _indent+1);
             displayAttribute(_out, "hideMemberIf", hideMemberIf, _indent+1);
             displayAttribute(_out, "formatter", formatter, _indent+1);
@@ -1499,7 +1500,6 @@ public boolean isEnabled() {
             _out.beginTag("Level", new org.eigenbase.xom.XMLAttrVector()
                 .add("approxRowCount", approxRowCount)
                 .add("name", name)
-                .add("parentname", parentname)
                 .add("visible", visible)
                 .add("columnIndex", columnIndex)
                 .add("keyOrdinal", keyOrdinal)
@@ -1515,6 +1515,7 @@ public boolean isEnabled() {
                 .add("type", type)
                 .add("internalType", internalType)
                 .add("uniqueMembers", uniqueMembers)
+                .add("columnar",columnar)
                 .add("levelType", levelType)
                 .add("hideMemberIf", hideMemberIf)
                 .add("formatter", formatter)
@@ -1539,7 +1540,6 @@ public boolean isEnabled() {
             Level _cother = (Level)_other;
             boolean _diff = displayAttributeDiff("approxRowCount", approxRowCount, _cother.approxRowCount, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("name", name, _cother.name, _out, _indent+1);
-            _diff = _diff && displayAttributeDiff("parentname", parentname, _cother.parentname, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("visible", visible, _cother.visible, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("columnIndex", columnIndex, _cother.columnIndex, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("keyOrdinal", keyOrdinal, _cother.keyOrdinal, _out, _indent+1);
@@ -1555,6 +1555,7 @@ public boolean isEnabled() {
             _diff = _diff && displayAttributeDiff("type", type, _cother.type, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("internalType", internalType, _cother.internalType, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("uniqueMembers", uniqueMembers, _cother.uniqueMembers, _out, _indent+1);
+            _diff = _diff && displayAttributeDiff("columnar", columnar, _cother.columnar, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("levelType", levelType, _cother.levelType, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("hideMemberIf", hideMemberIf, _cother.hideMemberIf, _out, _indent+1);
             _diff = _diff && displayAttributeDiff("formatter", formatter, _cother.formatter, _out, _indent+1);
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/SqlStatement.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/SqlStatement.java
index e79964b..474df2e 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/SqlStatement.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/olap/SqlStatement.java
@@ -9,8 +9,6 @@ public class SqlStatement
         INT,
         LONG,
         STRING,
-        BOOLEAN,
-        ARRAY,
-        STRUCT
+        BOOLEAN
     }
 }
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapMergerUtil.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapMergerUtil.java
deleted file mode 100644
index 4ca382c..0000000
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapMergerUtil.java
+++ /dev/null
@@ -1,157 +0,0 @@
-/**
- * 
- */
-package com.huawei.unibi.molap.util;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.lang.Math;
-
-import org.pentaho.di.core.exception.KettleException;
-
-import com.huawei.iweb.platform.logging.LogService;
-import com.huawei.iweb.platform.logging.LogServiceFactory;
-import com.huawei.unibi.molap.constants.MolapCommonConstants;
-import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
-import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
-import com.huawei.unibi.molap.datastorage.store.impl.FileFactory.FileType;
-
-/**
- * @author R00903928
- * Util class for merge activities of 2 loads.
- */
-public class MolapMergerUtil
-{
-
-    /**
-     * Attribute for Molap LOGGER
-     */
-    private static final LogService LOGGER = LogServiceFactory.getLogService(MolapMergerUtil.class.getName());
-
-    /**
-     * 
-     * @param storeLocation
-     * @param tableName
-     * @param fileType
-     * @param loadsToBeMerged
-     * @return
-     */
-    public static List<MolapSliceAndFiles> getSliceAndFilesList(String storeLocation, String tableName,
-            FileType fileType, List<String> loadsToBeMerged)
-    {
-        try
-        {
-            if(!FileFactory.isFileExist(storeLocation, fileType))
-            {
-                return new ArrayList<MolapSliceAndFiles>(0);
-            }
-        }
-        catch(IOException e)
-        {
-            LOGGER.error(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG, "Error occurred :: " + e.getMessage());
-        }
-        MolapFile file = FileFactory.getMolapFile(storeLocation, fileType);
-
-        MolapFile[] listFiles = MolapUtil.listFiles(file);
-        if(null == listFiles || listFiles.length < 0)
-        {
-            return new ArrayList<MolapSliceAndFiles>(0);
-        }
-        Arrays.sort(listFiles, new MolapFileFolderComparator());
-        listFiles = getMergeFilesList(loadsToBeMerged, listFiles);
-
-        return MolapUtil.getSliceAndFilesList(tableName, listFiles, fileType);
-    }
-
-    /**
-     * 
-     * @param loadsToBeMerged
-     * @param listFiles
-     * @return
-     */
-    private static MolapFile[] getMergeFilesList(List<String> loadsToBeMerged, MolapFile[] listFiles)
-    {
-        MolapFile[] molapFile = new MolapFile[loadsToBeMerged.size()];
-        int i = 0;
-        for(MolapFile listFile : listFiles)
-        {
-            String loadName = listFile.getName();
-            for(String load : loadsToBeMerged)
-            {
-                if((MolapCommonConstants.LOAD_FOLDER + load).equalsIgnoreCase(loadName))
-                {
-                    molapFile[i++] = listFile;
-                }
-            }
-        }
-        return molapFile;
-    }
-
-    /**
-     * 
-     * @param sliceLocation
-     * @param tableName
-     * @param destinationLocation
-     */
-    public static int[] mergeLevelMetadata(String[] sliceLocation, String tableName, String destinationLocation)
-    {
-        int[][] cardinalityOfLoads = new int[sliceLocation.length][];
-        int i = 0;
-        for(String loadFolderLoacation : sliceLocation)
-        {
-            try
-            {
-                cardinalityOfLoads[i++] = MolapUtil.getCardinalityFromLevelMetadataFile(loadFolderLoacation + '/'
-                        + MolapCommonConstants.LEVEL_METADATA_FILE + tableName + ".metadata");
-            }
-            catch(MolapUtilException e)
-            {
-                LOGGER.error(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG, "Error occurred :: " + e.getMessage());
-            }
-        }
-        int[] MaxCardinality = new int[cardinalityOfLoads[0].length];
-
-        for(int k = 0;k < cardinalityOfLoads[0].length;k++)
-        {
-            MaxCardinality[k] = Math.max(cardinalityOfLoads[0][k], cardinalityOfLoads[1][k]);
-        }
-
-        try
-        {
-            MolapUtil.writeLevelCardinalityFile(destinationLocation, tableName, MaxCardinality);
-        }
-        catch(KettleException e)
-        {
-            LOGGER.error(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG, "Error occurred :: " + e.getMessage());
-        }
-
-        return MaxCardinality;
-    }
-
-    /**
-     * 
-     * @param path
-     * @param tableName
-     * @return
-     */
-    public static int[] getCardinalityFromLevelMetadata(String path, String tableName)
-    {
-        int[] localCardinality = null;
-        try
-        {
-            localCardinality = MolapUtil.getCardinalityFromLevelMetadataFile(path + '/'
-                    + MolapCommonConstants.LEVEL_METADATA_FILE + tableName + ".metadata");
-        }
-        catch(MolapUtilException e)
-        {
-            LOGGER.error(
-                    MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG ,
-                    "Error occurred :: " + e.getMessage());
-        }
-
-        return localCardinality;
-    }
-
-}
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java
index 410ebc8..6995ced 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java
@@ -1,7 +1,6 @@
 package com.huawei.unibi.molap.util;
 
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 
 public class MolapSliceAndFiles
 {
@@ -15,8 +14,6 @@ public class MolapSliceAndFiles
      */
     private MolapFile[] sliceFactFilesList;
     
-    private KeyGenerator keyGen;
-    
     /**
      * This method will be used get the slice fact files 
      * 
@@ -61,21 +58,5 @@ public class MolapSliceAndFiles
         this.path = path;
     }
 
-    /**
-     * @return the keyGen
-     */
-    public KeyGenerator getKeyGen()
-    {
-        return keyGen;
-    }
-
-    /**
-     * @param keyGen the keyGen to set
-     */
-    public void setKeyGen(KeyGenerator keyGen)
-    {
-        this.keyGen = keyGen;
-    }
-
    
 }
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapUtil.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapUtil.java
index 24dd8a8..b693740 100644
--- a/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapUtil.java
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/util/MolapUtil.java
@@ -33,7 +33,9 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Comparator;
+import java.util.HashMap;
 import java.util.List;
+import java.util.Map;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
@@ -51,8 +53,6 @@ import com.huawei.unibi.molap.datastorage.store.FileHolder;
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreInfo;
 import com.huawei.unibi.molap.datastorage.store.columnar.UnBlockIndexer;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperations;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperationsImpl;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFileFilter;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
@@ -61,6 +61,7 @@ import com.huawei.unibi.molap.keygenerator.mdkey.NumberCompressor;
 import com.huawei.unibi.molap.metadata.LeafNodeInfo;
 import com.huawei.unibi.molap.metadata.LeafNodeInfoColumnar;
 import com.huawei.unibi.molap.metadata.SliceMetaData;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 
 
@@ -716,6 +717,46 @@ public final class MolapUtil
         return newDimsC;
     }
 
+    public static int getIncrementedCardinality(int dimCardinality)
+    {
+        // get the cardinality incr factor
+        final int incrValue = Integer.parseInt(MolapProperties.getInstance().getProperty(
+                MolapCommonConstants.CARDINALITY_INCREMENT_VALUE,
+                MolapCommonConstants.CARDINALITY_INCREMENT_VALUE_DEFAULT_VAL));
+
+        int perIncr = 0;
+        int remainder = 0;
+        int newDimsC = 0;
+
+        // get the incr
+        perIncr = (dimCardinality * incrValue) / CONST_HUNDRED;
+
+        // if per incr is more than one the add to cardinality
+        if(perIncr > 0)
+        {
+            newDimsC = dimCardinality + perIncr;
+        }
+        else
+        {
+            // else add one
+            newDimsC = dimCardinality + 1;
+        }
+        // check whether its in boundary condition
+        remainder = newDimsC % CONST_EIGHT;
+        if(remainder == CONST_SEVEN)
+        {
+            // then incr cardinality by 1
+            newDimsC = dimCardinality + 1;
+        }
+        newDimsC = Long.toBinaryString(newDimsC).length();
+        // get the log bits of cardinality
+
+        return newDimsC;
+    }
+   
+    
+    
+    
   /*  public static void main(String[] s)
     {
         int[]a={7,6,15,27};
@@ -735,27 +776,63 @@ public final class MolapUtil
         // get the log bits of cardinality 
         for(int i = 0;i < dimCardinality.length;i++)
         {
-            if(dimCardinality[i] == 0)
+            newDimsC[i] =getBitLengthFullyFilled(dimCardinality[i]);
+        }
+        return newDimsC;
+    }
+    
+    private static int getBitLengthFullyFilled(int dimlens)
+    {
+        int bitsLength=Long.toBinaryString(dimlens).length();
+        int div=bitsLength/8;
+        int mod=bitsLength%8;
+        if(mod>0)
+        {
+            return 8 * (div + 1);
+        }
+        else
+        {
+            return bitsLength;
+        }
+    }
+    
+    /**
+     * This method will return bit length required for each dimension based on splits
+     * @param dimension
+     * @param dimPartitioner : this will partition few dimension to be stored at row level. If it is row level than data is store in bits 
+     * @return
+     */
+    public static int[] getDimensionBitLength(int[] dimCardinality, int[][] dimPartitioner)
+    {
+        int[] newdims=new int[dimCardinality.length];
+        int dimCounter=0;
+        for(int i=0;i<dimPartitioner.length;i++)
+        {
+            if(dimPartitioner[i].length==1)
             {
-                //Array or struct type may have higher value 
-                newDimsC[i]=64;
+                //for columnar store
+                newdims[dimCounter]=getBitLengthFullyFilled(dimCardinality[dimCounter]);
+                dimCounter++;
             }
             else
             {
-                int bitsLength=Long.toBinaryString(dimCardinality[i]).length();
-                int div=bitsLength/8;
-                int mod=bitsLength%8;
-                if(mod>0)
+                // for row store
+                int totalSize=0;
+                for(int j=0;j<dimPartitioner[i].length;j++)
                 {
-                    newDimsC[i] = 8 * (div + 1);
+                    newdims[dimCounter]=MolapUtil.getIncrementedCardinality(dimCardinality[dimCounter]);
+                    totalSize+=newdims[dimCounter];
+                    dimCounter++;
                 }
-                else
+                //need to check if its required
+                int mod=totalSize%8;
+                if(mod>0)
                 {
-                    newDimsC[i]=bitsLength;
+                    newdims[dimCounter-1]=newdims[dimCounter-1]+(8-mod);
                 }
             }
         }
-        return newDimsC;
+        return newdims;
     }
     
     /**
@@ -1271,9 +1348,11 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         }
         info.setColumnMinMaxData(columnMinMaxData);
         
+        
         info.setKeyLengths(keyLengths);
         info.setKeyOffSets(keyOffset);
         info.setIsSortedKeyColumn(isAlreadySorted);
+        
         buffer.get(startKey);
         //
         buffer.get(endKey);
@@ -1596,7 +1675,7 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         return UnBlockIndexer.uncompressIndex(indexData, indexMap);
     }
     
-    public static ColumnarKeyStoreInfo getColumnarKeyStoreInfo(LeafNodeInfoColumnar leafNodeInfo, int[] eachBlockSize)
+    public static ColumnarKeyStoreInfo getColumnarKeyStoreInfo(LeafNodeInfoColumnar leafNodeInfo, int[] eachBlockSize,HybridStoreModel hybridStoreMeta)
     {
         ColumnarKeyStoreInfo columnarKeyStoreInfo = new ColumnarKeyStoreInfo();
         columnarKeyStoreInfo.setFilePath(leafNodeInfo.getFileName());
@@ -1613,6 +1692,8 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         columnarKeyStoreInfo.setAggKeyBlock(leafNodeInfo.getAggKeyBlock());
         columnarKeyStoreInfo.setDataIndexMapLength(leafNodeInfo.getDataIndexMapLength());
         columnarKeyStoreInfo.setDataIndexMapOffsets(leafNodeInfo.getDataIndexMapOffsets());
+        columnarKeyStoreInfo.setHybridStoreMeta(hybridStoreMeta);
+        //columnarKeyStoreInfo.setRowStoreOrdinals(leafNodeInfo.getRowStoreOrdinals());
         return columnarKeyStoreInfo;
     }
     
@@ -1880,7 +1961,7 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         return array;
     }
     
-    /*public static List<MolapSliceAndFiles> getSlicesToMergeFromHDFS(String storeLocation,String tableName, FileType fileType, String metadataPath, List<LoadMetadataDetails> mergedLoadDetails)
+    public static List<MolapSliceAndFiles> getSlicesFromHDFS(String storeLocation,String tableName, FileType fileType)
     {
         try
         {
@@ -1915,22 +1996,9 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
             return new ArrayList<MolapSliceAndFiles>(0);
         }
         Arrays.sort(listFiles,new MolapFileFolderComparator());
-        
-        LoadMetadataDetails[] loadDetails = readLoadMetadata(metadataPath);
-        
-        if(loadDetails.length == 0)
-        {
-            LOGGER.error(
-                    MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG ,
-                    "load metadata details doesnt exist." );
-            return new ArrayList<MolapSliceAndFiles>(0);
-        }
-        listFiles = getMergeFilesList(loadDetails,listFiles,mergedLoadDetails);
-        
-        
         return getSliceAndFilesList(
-                tableName, listFiles,fileType,loadDetails);
-    }*/
+                tableName, listFiles,fileType);
+    }
     public static String[] getSlices(String storeLocation,String tableName, FileType fileType)
     {
         try
@@ -1974,7 +2042,7 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         return slices;
     }
     
-    /*public static List<MolapSliceAndFiles> getSlicesFromLocal(String storeLocation,String tableName)
+    public static List<MolapSliceAndFiles> getSlicesFromLocal(String storeLocation,String tableName)
     {
         try
         {
@@ -1999,7 +2067,7 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         Arrays.sort(listFiles,new MolapFileFolderComparator());
         return getSliceAndFilesList(
                 tableName, listFiles,FileType.LOCAL);
-    }*/
+    }
 
     /**
      * @param file
@@ -2023,19 +2091,11 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         return listFiles;
     }
     
-    public static List<MolapSliceAndFiles> getSliceAndFilesList(String tableName,
+    private static List<MolapSliceAndFiles> getSliceAndFilesList(String tableName,
             MolapFile[] listFiles, FileType fileType)
     {
-        
-        //listFiles  = getLoadFolderToBeMerged(listFiles);
-        
         List<MolapSliceAndFiles> sliceFactFilesList = new ArrayList<MolapSliceAndFiles>(
                 listFiles.length);
-        if(listFiles.length == 0)
-        {
-            return sliceFactFilesList;
-        }
-        
 
         MolapSliceAndFiles sliceAndFiles = null;
         MolapFile[] sortedPathForFiles = null;
@@ -2116,28 +2176,8 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
     {
         MolapFile file = FileFactory.getMolapFile(sliceLocation, fileType);
         MolapFile[] files = null;
-        MolapFile[] updatedFactFiles = null;
         if(file.isDirectory())
         {
-            updatedFactFiles =  file.listFiles(new MolapFileFilter()
-            {
-                
-                @Override
-                public boolean accept(MolapFile pathname)
-                {
-                    return ((!pathname.isDirectory())
-                            && (pathname.getName().startsWith(tableName)) && pathname
-                            .getName().endsWith(
-                                    MolapCommonConstants.FACT_UPDATE_EXTENSION));
-                }
-            });
-            
-            if(updatedFactFiles.length != 0)
-            {
-                return updatedFactFiles;
-                
-            }
-            
             files = file.listFiles(new MolapFileFilter()
             {
                 public boolean accept(MolapFile pathname)
@@ -2282,17 +2322,14 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
                 + MolapCommonConstants.LOADMETADATA_FILENAME + MolapCommonConstants.MOLAP_METADATA_EXTENSION;
         LoadMetadataDetails[] listOfLoadFolderDetailsArray;
 
-        AtomicFileOperations fileOperation = new AtomicFileOperationsImpl(metadataFileName, FileFactory.getFileType(metadataFileName));
-        
         try
         {
             if(!FileFactory.isFileExist(metadataFileName, FileFactory.getFileType(metadataFileName)))
             {
                 return new LoadMetadataDetails[0];
             }
-            dataInputStream = fileOperation.openForRead();
-            /*dataInputStream = FileFactory.getDataInputStream(metadataFileName,
-                    FileFactory.getFileType(metadataFileName));*/
+            dataInputStream = FileFactory.getDataInputStream(metadataFileName,
+                    FileFactory.getFileType(metadataFileName));
             inStream = new InputStreamReader(dataInputStream, MolapCommonConstants.MOLAP_DEFAULT_STREAM_ENCODEFORMAT);
             buffReader = new BufferedReader(inStream);
             listOfLoadFolderDetailsArray = gsonObjectToRead.fromJson(buffReader, LoadMetadataDetails[].class);
@@ -2479,18 +2516,6 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         }
     }
     
-    public static String escapeComplexDelimiterChar(String parseStr)
-    {
-        switch(parseStr)
-        {
-            case "$":
-                return "\\$";
-            case ":":
-                return "\\:";
-            default:
-                return parseStr;
-        }
-    }
     /**
      * Append HDFS Base Url for show create & load data sql
      * 
@@ -2609,5 +2634,148 @@ private static List<LeafNodeInfo> getLeafNodeDetails(List<LeafNodeInfo> listOfNo
         }
         return basePath;
     }
+
+     /**
+     *  
+     * @param dimCardinality : dimension cardinality
+     * @param dimensionStoreType : dimension store type: true->columnar, false->row
+     * @param highCardDimOrdinals 
+     * @param columnarStoreColumns->columns for columnar store
+     * @param rowStoreColumns -> columns for row store
+     * @return
+     */
+    public static HybridStoreModel getHybridStoreMeta(int[] dimCardinality,boolean[] dimensionStoreType, List<Integer> highCardDimOrdinals)
+    {
+        //get dimension store type
+        HybridStoreModel hybridStoreMeta=new HybridStoreModel();
+      
+        List<Integer> columnarStoreOrdinalsList = new ArrayList<Integer>(dimensionStoreType.length);
+        List<Integer> columnarDimcardinalityList =new ArrayList<Integer>(dimensionStoreType.length);
+        List<Integer> rowStoreOrdinalsList = new ArrayList<Integer>(dimensionStoreType.length);
+        List<Integer> rowDimCardinalityList= new ArrayList<Integer>(dimensionStoreType.length);
+        boolean isHybridStore=false;
+        for (int i = 0; i < dimensionStoreType.length; i++)
+        {
+            if (dimensionStoreType[i])
+            {
+                columnarStoreOrdinalsList.add(i);
+                columnarDimcardinalityList.add(dimCardinality[i]);
+                
+            }
+            else
+            {
+                rowStoreOrdinalsList.add(i);
+                rowDimCardinalityList.add(dimCardinality[i]);
+               
+            }
+        }
+        if(rowStoreOrdinalsList.size()>0)
+        {
+            isHybridStore=true;
+        }
+        int[] columnarStoreOrdinal=convertToIntArray(columnarStoreOrdinalsList);
+        int[] columnarDimcardinality = convertToIntArray(columnarDimcardinalityList);
+        
+        int[] rowStoreOrdinal=convertToIntArray(rowStoreOrdinalsList);
+        int[] rowDimCardinality=convertToIntArray(rowDimCardinalityList);
+        
+        Map<Integer,Integer> dimOrdinalMDKeymapping=new HashMap<Integer,Integer>();
+        Map<Integer,Integer> dimOrdinalStoreIndexMapping=new HashMap<Integer,Integer>();
+        int dimCount=0;
+        int storeIndex=0;
+        for(int i=0;i<rowStoreOrdinal.length;i++)
+        {
+            //dimOrdinalMDKeymapping.put(dimCount++, rowStoreOrdinal[i]);
+            dimOrdinalMDKeymapping.put(rowStoreOrdinal[i],dimCount++);
+            //row stores will be stored at 0th inex
+            dimOrdinalStoreIndexMapping.put(rowStoreOrdinal[i], storeIndex);
+        }
+        storeIndex++;
+        for(int i=0;i<columnarStoreOrdinal.length;i++)
+        {
+            //dimOrdinalMDKeymapping.put(dimCount++,columnarStoreOrdinal[i] );
+            dimOrdinalMDKeymapping.put(columnarStoreOrdinal[i],dimCount++);
+            dimOrdinalStoreIndexMapping.put(columnarStoreOrdinal[i], storeIndex++);
+        }
+       
+        //updating with highcardinality dimension store detail
+        if(null!=highCardDimOrdinals)
+        {
+            for(Integer highCardDimOrdinal:highCardDimOrdinals)
+            {
+                dimOrdinalStoreIndexMapping.put(highCardDimOrdinal, storeIndex++);
+            }    
+        }
+        
+        
+        //This split is used while splitting mdkey's into columns
+        //1,1,1,3 -> it means first 3 dimension will be alone and next 3 dimension will be in single column
+        
+        //here in index +1 means total no of split will be all dimension,part of columnar store, and one column which
+        //will have all dimension in single column as row
+        int[] mdKeyPartioner=null;
+        int[][] dimensionPartitioner=null;
+        // no of dimension stored as column.. this inculdes one complete set of row store
+        int noOfColumnsStore=columnarStoreOrdinal.length;
+        if(isHybridStore)
+        {
+            noOfColumnsStore++;
+            mdKeyPartioner=new int[columnarStoreOrdinal.length+1];
+            dimensionPartitioner=new int[columnarDimcardinality.length+1][];
+            
+            //row
+            mdKeyPartioner[0]=rowDimCardinality.length;
+            dimensionPartitioner[0]=new int[rowDimCardinality.length];
+            for(int i=0;i<rowDimCardinality.length;i++)
+            {
+                dimensionPartitioner[0][i]=rowDimCardinality[i];
+               
+            }
+            //columnar
+            //dimensionPartitioner[1]=new int[columnarDimcardinality.length];
+            for(int i=0;i<columnarDimcardinality.length;i++)
+            {
+                dimensionPartitioner[i+1]=new int[]{columnarDimcardinality[i]};
+                mdKeyPartioner[i+1]=1;
+            }
+        }
+        else
+        {
+            mdKeyPartioner=new int[columnarStoreOrdinal.length];
+            dimensionPartitioner=new int[columnarDimcardinality.length][];
+            //columnar
+            dimensionPartitioner[0]=new int[columnarDimcardinality.length];
+            for(int i=0;i<columnarDimcardinality.length;i++)
+            {
+                dimensionPartitioner[i]=new int[]{columnarDimcardinality[i]};
+                mdKeyPartioner[i]=1;
+            }
+        }
+        
+       
+        hybridStoreMeta.setNoOfColumnStore(noOfColumnsStore);
+        hybridStoreMeta.setDimOrdinalMDKeyMapping(dimOrdinalMDKeymapping);
+        hybridStoreMeta.setColumnStoreOrdinals(columnarStoreOrdinal);
+        hybridStoreMeta.setRowStoreOrdinals(rowStoreOrdinal);
+        hybridStoreMeta.setDimensionPartitioner(dimensionPartitioner);
+        hybridStoreMeta.setColumnSplit(mdKeyPartioner);
+        hybridStoreMeta.setDimOrdinalStoreIndexMapping(dimOrdinalStoreIndexMapping);
+        //this is no
+        
+        
+        //get Key generator for each columnar and row store
+        int[] completeCardinality=new int[rowDimCardinality.length+columnarDimcardinality.length];
+        System.arraycopy(rowDimCardinality, 0, completeCardinality, 0, rowDimCardinality.length);
+        System.arraycopy(columnarDimcardinality, 0, completeCardinality,rowDimCardinality.length, columnarDimcardinality.length);
+        
+        hybridStoreMeta.setHybridCardinality(completeCardinality);
+       
+        hybridStoreMeta.setHybridStore(isHybridStore);
+        
+         
+        
+        return hybridStoreMeta;
+    }
+    
 }
 
diff --git a/Molap/Molap-Core/src/com/huawei/unibi/molap/vo/HybridStoreModel.java b/Molap/Molap-Core/src/com/huawei/unibi/molap/vo/HybridStoreModel.java
new file mode 100644
index 0000000..7bb501d
--- /dev/null
+++ b/Molap/Molap-Core/src/com/huawei/unibi/molap/vo/HybridStoreModel.java
@@ -0,0 +1,155 @@
+package com.huawei.unibi.molap.vo;
+
+import java.util.Map;
+
+
+public class HybridStoreModel
+{
+
+    /**
+     * This array will have columns ordinal which are part of columnar store
+     */
+    private int[] columnStoreOrdinals;
+    
+    /**
+     * This array will have columns ordinal which are part of row store
+     */
+    private int[] rowStoreOrdinals;
+    
+
+    /**
+     * 
+     */
+    private int[] hybridCardinality;
+    
+    
+    /**
+     * This has detail of dimension which has to be stored as column based or row based
+     * e.g {{1,1}
+     *      {2,1}
+     *      {3,1}
+     *      {4,5,6}
+     * it means first 3 dimension will be part of columnar store and next 3 dimension 
+     * will be part of row store
+     */
+    private int[][] dimensionPartitioner;
+    
+    
+    private int[] columnSplit;
+
+    /**
+     * It states whether store is hybrid store ie. data stored is both row and columnar
+     */
+    private boolean isHybridStore;
+    
+
+    /**
+     * This will have mapping for dimension ordinal and its index in generated md keyArray
+     * 
+     */
+    private Map<Integer, Integer> dimOrdinalMDKeymapping;
+    
+    
+    /**
+     * this will have dimension ordinal and its index in fact store
+     */
+    private Map<Integer, Integer> dimOrdinalStoreIndexMapping;
+
+    
+    private int noOfColumnsStore;
+    
+
+    public int[] getColumnStoreOrdinals()
+    {
+        return columnStoreOrdinals;
+    }
+
+    public void setColumnStoreOrdinals(int[] columnStoreOrdinals)
+    {
+        this.columnStoreOrdinals = columnStoreOrdinals;
+    }
+
+    public int[] getRowStoreOrdinals()
+    {
+        return rowStoreOrdinals;
+    }
+
+    public void setRowStoreOrdinals(int[] rowStoreOrdinals)
+    {
+        this.rowStoreOrdinals = rowStoreOrdinals;
+    }
+
+    public int[] getHybridCardinality()
+    {
+        return hybridCardinality;
+    }
+
+    public void setHybridCardinality(int[] hybridCardinality)
+    {
+        this.hybridCardinality = hybridCardinality;
+    }
+
+    public int[][] getDimensionPartitioner()
+    {
+        return dimensionPartitioner;
+    }
+
+    public void setDimensionPartitioner(int[][] dimensionPartitioner)
+    {
+        this.dimensionPartitioner = dimensionPartitioner;
+    }
+
+    public int[] getColumnSplit()
+    {
+        return columnSplit;
+    }
+
+    public void setColumnSplit(int[] split)
+    {
+        this.columnSplit = split;
+    }
+
+    public boolean isHybridStore()
+    {
+        return this.isHybridStore;
+    }
+
+    public void setHybridStore(boolean isHybridStore)
+    {
+        this.isHybridStore = isHybridStore;
+    }
+
+ 
+    public void setDimOrdinalMDKeyMapping(Map<Integer, Integer> dimOrdinalMDKeymapping)
+    {
+        this.dimOrdinalMDKeymapping=dimOrdinalMDKeymapping;
+        
+    }
+
+    public int getMdKeyOrdinal(int ordinal)
+    {
+       return this.dimOrdinalMDKeymapping.get(ordinal);
+        
+    }
+
+    public void setDimOrdinalStoreIndexMapping(Map<Integer, Integer> dimOrdinalStoreIndexMapping)
+    {
+       this.dimOrdinalStoreIndexMapping=dimOrdinalStoreIndexMapping;
+        
+    }
+    
+    public int getStoreIndex(int dimOrdinal)
+    {
+        return this.dimOrdinalStoreIndexMapping.get(dimOrdinal);
+    }
+
+    public void setNoOfColumnStore(int noOfColumnsStore)
+    {
+        this.noOfColumnsStore=noOfColumnsStore;
+    }
+    public int getNoOfColumnStore()
+    {
+        return this.noOfColumnsStore;
+    }
+    
+}
diff --git a/Molap/Molap-Data-Processor/.settings/org.eclipse.jdt.core.prefs b/Molap/Molap-Data-Processor/.settings/org.eclipse.jdt.core.prefs
deleted file mode 100644
index 7341ab1..0000000
--- a/Molap/Molap-Data-Processor/.settings/org.eclipse.jdt.core.prefs
+++ /dev/null
@@ -1,11 +0,0 @@
-eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.7
-org.eclipse.jdt.core.compiler.codegen.unusedLocal=preserve
-org.eclipse.jdt.core.compiler.compliance=1.7
-org.eclipse.jdt.core.compiler.debug.lineNumber=generate
-org.eclipse.jdt.core.compiler.debug.localVariable=generate
-org.eclipse.jdt.core.compiler.debug.sourceFile=generate
-org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
-org.eclipse.jdt.core.compiler.problem.enumIdentifier=error
-org.eclipse.jdt.core.compiler.source=1.7
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/ArrayDataType.java b/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/ArrayDataType.java
deleted file mode 100644
index bcd0870..0000000
--- a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/ArrayDataType.java
+++ /dev/null
@@ -1,204 +0,0 @@
-package com.huawei.datasight.molap.datatypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.pentaho.di.core.exception.KettleException;
-
-import com.huawei.unibi.molap.keygenerator.KeyGenException;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.surrogatekeysgenerator.csvbased.MolapCSVBasedDimSurrogateKeyGen;
-
-public class ArrayDataType implements GenericDataType {
-	
-	private GenericDataType children;
-	
-	private String name;
-	
-	private String parentname;
-	
-	private int outputArrayIndex;
-	
-	private int dataCounter;
-	
-	@Override
-	public void addChildren(GenericDataType children) {
-		if(this.getName().equals(children.getParentname()))
-		{
-			this.children = children;
-		}
-		else
-		{
-			this.children.addChildren(children);
-		}
-	}
-	public ArrayDataType(String name, String parentname)
-	{
-		this.name = name;
-		this.parentname = parentname;
-	}
-	
-	@Override
-	public void setName(String name) {
-		this.name = name;
-	}
-	
-	@Override
-	public String getName() {
-		return name;
-	}
-	
-	@Override
-	public void setParentname(String parentname) {
-		this.parentname = parentname;
-		
-	}
-
-	@Override
-	public String getParentname() {
-		return parentname;
-	}
-	
-	@Override
-	public void getAllPrimitiveChildren(List<GenericDataType> primitiveChild) {
-		if (children instanceof PrimitiveDataType) 
-		{
-			primitiveChild.add(children);
-		}
-		else
-		{
-			children.getAllPrimitiveChildren(primitiveChild);
-		}
-	}
-	
-	
-	@Override
-	public int getSurrogateIndex() {
-		return 0;
-	}
-
-	@Override
-	public void setSurrogateIndex(int surrIndex) {
-		
-	}
-	@Override
-	public void parseStringAndWriteByteArray(String tableName, String inputString,
-			String[] delimiter, int delimiterIndex,
-			DataOutputStream dataOutputStream,
-			MolapCSVBasedDimSurrogateKeyGen surrogateKeyGen)
-			throws KettleException, IOException {
-		
-		if(inputString == null || inputString.equals("null"))
-		{
-			//Indicates null array
-			dataOutputStream.writeInt(0);
-		}
-		else
-		{
-			String[] splitInput = inputString.split(delimiter[delimiterIndex]);
-			dataOutputStream.writeInt(splitInput.length);
-			delimiterIndex = (delimiter.length - 1) == delimiterIndex ? delimiterIndex : delimiterIndex + 1;
-			for(String eachInput: splitInput)
-			{
-				children.parseStringAndWriteByteArray(tableName, eachInput, delimiter, delimiterIndex, dataOutputStream, surrogateKeyGen);
-			}
-		}
-	}
-	
-	@Override
-	public void parseAndBitPack(ByteBuffer byteArrayInput, DataOutputStream dataOutputStream, KeyGenerator[] generator) throws IOException, KeyGenException
-	{
-		int dataLength = byteArrayInput.getInt();
-		
-		dataOutputStream.writeInt(dataLength);
-		if(children instanceof PrimitiveDataType)
-		{
-			dataOutputStream.writeInt(generator[children.getSurrogateIndex()].getKeySizeInBytes());
-		}
-		for(int i=0;i<dataLength;i++)
-		{
-			children.parseAndBitPack(byteArrayInput, dataOutputStream, generator);
-		}
-		
-	}
-	@Override
-	public int getColsCount() {
-		return children.getColsCount() + 1;
-	}
-	
-	@Override
-	public void setOutputArrayIndex(int outputArrayIndex) {
-		this.outputArrayIndex = outputArrayIndex;
-		children.setOutputArrayIndex(outputArrayIndex + 1);
-	}
-	
-	@Override
-	public int getMaxOutputArrayIndex()
-	{
-		int currentMax = outputArrayIndex;
-		int childMax = children.getMaxOutputArrayIndex();
-		if(childMax > currentMax)
-		{
-			currentMax = childMax;
-		}
-		return currentMax;
-	}
-	
-	@Override
-	public void getColumnarDataForComplexType(
-			List<ArrayList<byte[]>> columnsArray, ByteBuffer inputArray) {
-		ByteBuffer b = ByteBuffer.allocate(8);
-		int dataLength = inputArray.getInt();
-		b.putInt(dataLength);
-		if(dataLength == 0)
-		{
-			b.putInt(0);
-		}
-		else
-		{
-			b.putInt(children.getDataCounter());
-		}
-		columnsArray.get(this.outputArrayIndex).add(b.array());
-
-		if(children instanceof PrimitiveDataType)
-		{
-			((PrimitiveDataType) children).setKeySize(inputArray.getInt());
-		}
-		for(int i=0;i<dataLength;i++)
-		{
-			children.getColumnarDataForComplexType(columnsArray, inputArray);
-		}
-		this.dataCounter++;
-	}
-	
-	@Override
-	public int getDataCounter()
-	{
-		return this.dataCounter;
-	}
-	
-	@Override
-	public void fillAggKeyBlock(List<Boolean> aggKeyBlockWithComplex, boolean[] aggKeyBlock)
-	{
-		aggKeyBlockWithComplex.add(false);
-		children.fillAggKeyBlock(aggKeyBlockWithComplex,aggKeyBlock);
-	}
-	
-	@Override
-	public void fillBlockKeySize(List<Integer> blockKeySizeWithComplex, int[] primitiveBlockKeySize)
-	{
-		blockKeySizeWithComplex.add(8);
-		children.fillBlockKeySize(blockKeySizeWithComplex, primitiveBlockKeySize);
-	}
-	
-	@Override
-	public void fillCardinalityAfterDataLoad(List<Integer> dimCardWithComplex, int[] maxSurrogateKeyArray)
-	{
-		dimCardWithComplex.add(0);
-		children.fillCardinalityAfterDataLoad(dimCardWithComplex, maxSurrogateKeyArray);
-	}
-	
-}
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/GenericDataType.java b/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/GenericDataType.java
deleted file mode 100644
index b3ab7d7..0000000
--- a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/GenericDataType.java
+++ /dev/null
@@ -1,54 +0,0 @@
-package com.huawei.datasight.molap.datatypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.pentaho.di.core.exception.KettleException;
-
-import com.huawei.unibi.molap.keygenerator.KeyGenException;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.surrogatekeysgenerator.csvbased.MolapCSVBasedDimSurrogateKeyGen;
-
-public interface GenericDataType {
-	
-	void setName(String name);
-	
-	String getName();
-
-	void setParentname(String parentname);
-	
-	String getParentname();
-	
-	void addChildren(GenericDataType children);
-	
-	void getAllPrimitiveChildren(List<GenericDataType> primitiveChild);
-	
-	void parseStringAndWriteByteArray(String tableName, String inputString, String[] delimiter, 
-			int delimiterIndex,	DataOutputStream dataOutputStream, 
-			MolapCSVBasedDimSurrogateKeyGen surrogateKeyGen) throws KettleException, IOException;
-	
-	int getSurrogateIndex();
-	
-	void setSurrogateIndex(int surrIndex);
-	
-	void parseAndBitPack(ByteBuffer byteArrayInput, DataOutputStream dataOutputStream, KeyGenerator[] generator) throws IOException, KeyGenException;
-	
-	int getColsCount();
-	
-	void setOutputArrayIndex(int outputArrayIndex);
-	
-	int getMaxOutputArrayIndex();
-	
-	void getColumnarDataForComplexType(List<ArrayList<byte[]>> columnsArray, ByteBuffer inputArray);
-	
-	int getDataCounter();
-	
-	void fillAggKeyBlock(List<Boolean> aggKeyBlockWithComplex, boolean[] aggKeyBlock);
-	
-	void fillBlockKeySize(List<Integer> blockKeySizeWithComplex, int[] primitiveBlockKeySize);
-	
-	void fillCardinalityAfterDataLoad(List<Integer> dimCardWithComplex, int[] maxSurrogateKeyArray);
-}
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/PrimitiveDataType.java b/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/PrimitiveDataType.java
deleted file mode 100644
index d67c143..0000000
--- a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/PrimitiveDataType.java
+++ /dev/null
@@ -1,145 +0,0 @@
-package com.huawei.datasight.molap.datatypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.pentaho.di.core.exception.KettleException;
-
-import com.huawei.unibi.molap.keygenerator.KeyGenException;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.surrogatekeysgenerator.csvbased.MolapCSVBasedDimSurrogateKeyGen;
-
-public class PrimitiveDataType implements GenericDataType {
-
-	private int index;
-	
-	private String name;
-	private String parentname;
-	
-	private int keySize;
-	
-	private int outputArrayIndex;
-	
-	private int dataCounter;
-	
-	public PrimitiveDataType(String name, String parentname)
-	{
-		this.name = name;
-		this.parentname = parentname;
-	}
-	
-	@Override
-	public void addChildren(GenericDataType children) {
-
-	}
-
-	@Override
-	public void setName(String name) {
-		this.name = name;
-	}
-	
-	@Override
-	public String getName() {
-		return name;
-	}
-
-	@Override
-	public void setParentname(String parentname) {
-		this.parentname = parentname;
-		
-	}
-
-	@Override
-	public String getParentname() {
-		return parentname;
-	}
-	
-	@Override
-	public void getAllPrimitiveChildren(List<GenericDataType> primitiveChild) {
-
-	}
-
-	@Override
-	public int getSurrogateIndex() {
-		return index;
-	}
-
-	@Override
-	public void setSurrogateIndex(int surrIndex) {
-		index = surrIndex;
-	}
-
-	@Override
-	public void parseStringAndWriteByteArray(String tableName, String inputString,
-			String[] delimiter, int delimiterIndex,
-			DataOutputStream dataOutputStream,
-			MolapCSVBasedDimSurrogateKeyGen surrogateKeyGen) throws KettleException, IOException {
-		dataOutputStream.writeInt(surrogateKeyGen.generateSurrogateKeys(inputString,
-				tableName+"_"+name, index, new Object[0]));
-	}
-	
-	@Override
-	public void parseAndBitPack(ByteBuffer byteArrayInput, DataOutputStream dataOutputStream, KeyGenerator[] generator) throws IOException, KeyGenException
-	{
-		int data = byteArrayInput.getInt();
-		dataOutputStream.write(generator[index].generateKey(new int[]{data}));
-	}
-
-	@Override
-	public int getColsCount() {
-		return 1;
-	}
-
-	@Override
-	public void setOutputArrayIndex(int outputArrayIndex) {
-		this.outputArrayIndex = outputArrayIndex;
-	}
-	
-	@Override
-	public int getMaxOutputArrayIndex()
-	{
-		return outputArrayIndex;
-	}
-	
-
-	@Override
-	public void getColumnarDataForComplexType(
-			List<ArrayList<byte[]>> columnsArray, ByteBuffer inputArray) {
-		byte[] key = new byte[keySize];
-		inputArray.get(key);
-		columnsArray.get(outputArrayIndex).add(key);
-		dataCounter++;
-	}
-	
-	@Override
-	public int getDataCounter()
-	{
-		return this.dataCounter;
-	}
-	
-	public void setKeySize(int keySize)
-	{
-		this.keySize = keySize;
-	}
-	
-	@Override
-	public void fillAggKeyBlock(List<Boolean> aggKeyBlockWithComplex, boolean[] aggKeyBlock)
-	{
-		aggKeyBlockWithComplex.add(aggKeyBlock[index]);
-	}
-
-	@Override
-	public void fillBlockKeySize(List<Integer> blockKeySizeWithComplex, int[] primitiveBlockKeySize)
-	{
-		blockKeySizeWithComplex.add(primitiveBlockKeySize[index]);
-	}
-	
-	@Override
-	public void fillCardinalityAfterDataLoad(List<Integer> dimCardWithComplex, int[] maxSurrogateKeyArray)
-	{
-		dimCardWithComplex.add(maxSurrogateKeyArray[index]);
-	}
-}
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/StructDataType.java b/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/StructDataType.java
deleted file mode 100644
index 8129130..0000000
--- a/Molap/Molap-Data-Processor/src/com/huawei/datasight/molap/datatypes/StructDataType.java
+++ /dev/null
@@ -1,234 +0,0 @@
-package com.huawei.datasight.molap.datatypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.pentaho.di.core.exception.KettleException;
-
-import com.huawei.unibi.molap.keygenerator.KeyGenException;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.surrogatekeysgenerator.csvbased.MolapCSVBasedDimSurrogateKeyGen;
-
-public class StructDataType implements GenericDataType {
-	
-	private List<GenericDataType> children = new ArrayList<GenericDataType>();
-	private String name;
-	private String parentname;
-	private int outputArrayIndex;
-	private int dataCounter;
-	
-	@Override
-	public void addChildren(GenericDataType newChild) {
-		if(this.getName().equals(newChild.getParentname()))
-		{
-			this.children.add(newChild);
-		}
-		else
-		{
-			for(GenericDataType child : this.children)
-			{
-				child.addChildren(newChild);
-			}
-		}
-		
-	}
-	
-	public StructDataType(String name, String parentname)
-	{
-		this.name = name;
-		this.parentname = parentname;
-	}
-	
-	@Override
-	public void setName(String name) {
-		this.name = name;
-	}
-	
-	@Override
-	public String getName() {
-		return name;
-	}
-	
-	@Override
-	public void setParentname(String parentname) {
-		this.parentname = parentname;
-		
-	}
-
-	@Override
-	public String getParentname() {
-		return parentname;
-	}
-	
-	@Override
-	public void getAllPrimitiveChildren(List<GenericDataType> primitiveChild) {
-		for(int i=0;i<children.size();i++)
-		{
-			GenericDataType child = children.get(i);
-			if (child instanceof PrimitiveDataType) 
-			{
-				primitiveChild.add(child);
-			}
-			else
-			{
-				child.getAllPrimitiveChildren(primitiveChild);
-			}
-		}
-	}
-	
-	@Override
-	public int getSurrogateIndex() {
-		return 0;
-	}
-
-	@Override
-	public void setSurrogateIndex(int surrIndex) {
-		
-	}
-
-	@Override
-	public void parseStringAndWriteByteArray(String tableName, String inputString,
-			String[] delimiter, int delimiterIndex,
-			DataOutputStream dataOutputStream,
-			MolapCSVBasedDimSurrogateKeyGen surrogateKeyGen)
-			throws KettleException, IOException {
-		if(inputString == null || inputString.equals("null"))
-		{
-			//Indicates null array
-			dataOutputStream.writeInt(0);
-		}
-		else
-		{
-			String[] splitInput = inputString.split(delimiter[delimiterIndex]);
-			dataOutputStream.writeInt(children.size());
-			delimiterIndex = (delimiter.length - 1) == delimiterIndex ? delimiterIndex : delimiterIndex + 1;
-			for(int i=0;i<children.size();i++)
-			{
-				children.get(i).parseStringAndWriteByteArray(tableName, splitInput[i], delimiter, delimiterIndex, dataOutputStream, surrogateKeyGen);
-			}
-		}
-	}
-	
-	@Override
-	public void parseAndBitPack(ByteBuffer byteArrayInput, DataOutputStream dataOutputStream, KeyGenerator[] generator) throws IOException, KeyGenException
-	{
-		int childElement = byteArrayInput.getInt();
-		dataOutputStream.writeInt(childElement);
-		for(int i=0;i<childElement;i++)
-		{
-			if(children.get(i) instanceof PrimitiveDataType)
-			{
-				dataOutputStream.writeInt(generator[children.get(i).getSurrogateIndex()].getKeySizeInBytes());
-			}
-			children.get(i).parseAndBitPack(byteArrayInput, dataOutputStream, generator);
-		}
-	}
-	
-	@Override
-	public int getColsCount() {
-		int colsCount = 1;
-		for(int i=0;i<children.size();i++)
-		{
-			colsCount += children.get(i).getColsCount();
-		}
-		return colsCount;
-	}
-	
-	@Override
-	public void setOutputArrayIndex(int outputArrayIndex) {
-		this.outputArrayIndex = outputArrayIndex++;
-		for(int i=0;i<children.size();i++)
-		{
-			if(children.get(i) instanceof PrimitiveDataType)
-			{
-				children.get(i).setOutputArrayIndex(outputArrayIndex++);
-			}
-			else
-			{
-				children.get(i).setOutputArrayIndex(outputArrayIndex++);
-				outputArrayIndex = getMaxOutputArrayIndex() + 1;
-			}
-		}
-	}
-	
-	@Override
-	public int getMaxOutputArrayIndex()
-	{
-		int currentMax = outputArrayIndex;
-		for(int i=0;i<children.size();i++)
-		{
-			int childMax = children.get(i).getMaxOutputArrayIndex();
-			if(childMax > currentMax)
-			{
-				currentMax = childMax;
-			}
-		}
-		return currentMax;
-	}
-	@Override
-	public void getColumnarDataForComplexType(
-			List<ArrayList<byte[]>> columnsArray, ByteBuffer inputArray) {
-		
-		ByteBuffer b = ByteBuffer.allocate(8);
-		int childElement = inputArray.getInt();
-		b.putInt(childElement);
-		if(childElement == 0)
-		{
-			b.putInt(0);
-		}
-		else
-		{
-			b.putInt(children.get(0).getDataCounter());
-		}
-		columnsArray.get(this.outputArrayIndex).add(b.array());
-
-		for(int i=0;i<childElement;i++)
-		{
-			if(children.get(i) instanceof PrimitiveDataType)
-			{
-				((PrimitiveDataType) children.get(i)).setKeySize(inputArray.getInt());
-			}
-			children.get(i).getColumnarDataForComplexType(columnsArray, inputArray);
-		}
-		this.dataCounter++;
-	}
-	
-	@Override
-	public int getDataCounter()
-	{
-		return this.dataCounter;
-	}
-	
-	@Override
-	public void fillAggKeyBlock(List<Boolean> aggKeyBlockWithComplex, boolean[] aggKeyBlock)
-	{
-		aggKeyBlockWithComplex.add(false);
-		for(int i=0;i<children.size();i++)
-		{
-			children.get(i).fillAggKeyBlock(aggKeyBlockWithComplex,aggKeyBlock);
-		}
-	}
-	
-	@Override
-	public void fillBlockKeySize(List<Integer> blockKeySizeWithComplex, int[] primitiveBlockKeySize)
-	{
-		blockKeySizeWithComplex.add(8);
-		for(int i=0;i<children.size();i++)
-		{
-			children.get(i).fillBlockKeySize(blockKeySizeWithComplex, primitiveBlockKeySize);
-		}
-	}
-	
-	@Override
-	public void fillCardinalityAfterDataLoad(List<Integer> dimCardWithComplex, int[] maxSurrogateKeyArray)
-	{
-		dimCardWithComplex.add(0);
-		for(int i=0;i<children.size();i++)
-		{
-			children.get(i).fillCardinalityAfterDataLoad(dimCardWithComplex, maxSurrogateKeyArray);
-		}
-	}
-}
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/api/dataloader/SchemaInfo.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/api/dataloader/SchemaInfo.java
index a7c9028..b2c3cb2 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/api/dataloader/SchemaInfo.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/api/dataloader/SchemaInfo.java
@@ -76,26 +76,6 @@ public class SchemaInfo
      * isBackgroundMergingRequest
      */
     private boolean isBackgroundMergingRequest;
-    
-    private String complexDelimiterLevel1;
-
-    private String complexDelimiterLevel2;
-
-    public String getComplexDelimiterLevel1() {
-		return complexDelimiterLevel1;
-	}
-
-	public void setComplexDelimiterLevel1(String complexDelimiterLevel1) {
-		this.complexDelimiterLevel1 = complexDelimiterLevel1;
-	}
-
-	public String getComplexDelimiterLevel2() {
-		return complexDelimiterLevel2;
-	}
-
-	public void setComplexDelimiterLevel2(String complexDelimiterLevel2) {
-		this.complexDelimiterLevel2 = complexDelimiterLevel2;
-	}
 
     /**
      * 
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/csvload/GraphExecutionUtil.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/csvload/GraphExecutionUtil.java
index d6a6c73..f92284e 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/csvload/GraphExecutionUtil.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/csvload/GraphExecutionUtil.java
@@ -486,7 +486,7 @@ public final class GraphExecutionUtil
 
                         for(Level level : levels)
                         {
-                            if (level.visible && null == level.parentname)
+                            if (level.visible)
                             {
                                 columnNames.add(level.column.trim());
                             }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/DataRetentionHandler.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/DataRetentionHandler.java
index fdc8be5..1011aed 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/DataRetentionHandler.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/DataRetentionHandler.java
@@ -189,11 +189,6 @@ public class DataRetentionHandler
 
                 applyRetentionDetailsBasedOnRetentionMember();
 
-            // skip deleted and merged load folders.
-            if(!isLoadValid(listOfLoadMetadataDetails,molapFile.getName()))
-            {
-                continue;
-            }
                 /*
                  * if(retentionSurrogateKey==-1) { throw new
                  * MolapDataProcessorException("Invalid Date Member..."); }
@@ -241,40 +236,6 @@ public class DataRetentionHandler
 		return status;
 	}
 
-	 /**
-    * 
-    * @param loadMetadataDetails2
-    * @param name
-    * @return
-    */
-    private boolean isLoadValid(
-            List<LoadMetadataDetails> loadMetadataDetails2, String name)
-    {
-        String loadName = name.substring(name.indexOf(MolapCommonConstants.LOAD_FOLDER)+MolapCommonConstants.LOAD_FOLDER.length(), name.length());
-        
-        for(LoadMetadataDetails loads : loadMetadataDetails2)
-        {
-            if(loads.getLoadName().equalsIgnoreCase(loadName))
-            {
-                if(null != loads.getMergedLoadName())
-                {
-                    return false;
-                }
-                else if(loads.getLoadStatus().equalsIgnoreCase(MolapCommonConstants.MARKED_FOR_DELETE))
-                {
-                    return false;
-                }
-                return true;
-            }
-            else if( null != loads.getMergedLoadName() && loads.getMergedLoadName().equalsIgnoreCase(loadName) && !loads.getLoadStatus().equalsIgnoreCase(MolapCommonConstants.MARKED_FOR_DELETE))
-            {
-                return true;
-            }
-        }
-        
-        
-        return false;
-    }
     private void applyRetentionDetailsBasedOnRetentionMember()
     {
         measureLength = sliceMetadata.getMeasures().length;
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/MolapDataRetentionUtil.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/MolapDataRetentionUtil.java
index 502287f..ced3b22 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/MolapDataRetentionUtil.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/dataprocessor/dataretention/MolapDataRetentionUtil.java
@@ -5,15 +5,13 @@ import java.io.IOException;
 import java.nio.charset.Charset;
 import java.text.ParseException;
 import java.text.SimpleDateFormat;
-import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Date;
-import java.util.List;
+//import java.util.HashMap;
 import java.util.Map;
 
 import org.apache.commons.codec.binary.Base64;
 
-import com.huawei.datasight.molap.core.load.LoadMetadataDetails;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
@@ -253,65 +251,4 @@ public final class MolapDataRetentionUtil
         });
         return listFiles;
     }
-
-    /**
-     * 
-     * @param loadFiles
-     * @param loadMetadataDetails
-     * @return
-     */
-    public static MolapFile[] excludeUnwantedLoads(MolapFile[] loadFiles,
-            List<LoadMetadataDetails> loadMetadataDetails)
-    {
-        List<MolapFile> validLoads = new ArrayList<MolapFile>();
-        
-        List<String> validLoadsForRetention =  getValidLoadsForRetention(loadMetadataDetails);
-        
-        for(MolapFile loadFolder : loadFiles)
-        {
-            String loadName = loadFolder.getName().substring(loadFolder.getName().indexOf(MolapCommonConstants.LOAD_FOLDER)+MolapCommonConstants.LOAD_FOLDER.length(),loadFolder.getName().length() );
-            
-            if(validLoadsForRetention.contains(loadName))
-            {
-                validLoads.add(loadFolder);
-            }
-            
-        }
-        
-        
-        
-        
-        return validLoads.toArray(new MolapFile[validLoads.size()]);
-    }
-
-    /**
-     * 
-     * @param loadMetadataDetails
-     * @return
-     */
-    private static List<String> getValidLoadsForRetention(
-            List<LoadMetadataDetails> loadMetadataDetails)
-    {
-        List<String> validLoadNameForRetention = new ArrayList<String>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
-        
-        for(LoadMetadataDetails loadDetail : loadMetadataDetails )
-        {
-            //load should not be deleted and load should not be merged.
-            if(!loadDetail.getLoadStatus().equalsIgnoreCase(MolapCommonConstants.MARKED_FOR_DELETE))
-            {
-                if(null == loadDetail.getMergedLoadName())
-                {
-                    validLoadNameForRetention.add(loadDetail.getLoadName());
-                }
-                else
-                {
-                    validLoadNameForRetention.add(loadDetail.getMergedLoadName());
-                }
-                   
-            }
-            
-        }
-        
-        return validLoadNameForRetention;
-    }
 }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/columnar/MolapColumnarLeafNodeIterator.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/columnar/MolapColumnarLeafNodeIterator.java
index f1a3bdd..5189adc 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/columnar/MolapColumnarLeafNodeIterator.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/columnar/MolapColumnarLeafNodeIterator.java
@@ -215,7 +215,7 @@ public class MolapColumnarLeafNodeIterator implements
     private void getNewLeafData()
     {
         LeafNodeInfoColumnar leafNodeInfo = leafNodeInfoList.get(currentCount++);
-        keyStore = StoreFactory.createColumnarKeyStore(MolapUtil.getColumnarKeyStoreInfo(leafNodeInfo, blockKeySize), fileHolder,true);
+        keyStore = StoreFactory.createColumnarKeyStore(MolapUtil.getColumnarKeyStoreInfo(leafNodeInfo, blockKeySize,null), fileHolder,true);
         this.dataStore = StoreFactory.createDataStore(true, compressionModel, leafNodeInfo.getMeasureOffset(),
                 leafNodeInfo.getMeasureLength(), leafNodeInfo.getFileName(), fileHolder).getBackData(null, fileHolder);
         this.entryCount=leafNodeInfo.getNumberOfKeys();
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/step/MolapFactReaderStep.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/step/MolapFactReaderStep.java
index 8baa8b1..1e9398b 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/step/MolapFactReaderStep.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/factreader/step/MolapFactReaderStep.java
@@ -37,6 +37,7 @@ import org.pentaho.di.trans.step.StepMeta;
 import org.pentaho.di.trans.step.StepMetaInterface;
 
 
+
 //import com.huawei.datasight.molap.core.load.LoadMetadataDetails;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
@@ -63,6 +64,7 @@ import com.huawei.unibi.molap.iterator.MolapIterator;
 import com.huawei.unibi.molap.keygenerator.KeyGenException;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthEquiSplitGenerator;
+import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthVariableSplitGenerator;
 import com.huawei.unibi.molap.keygenerator.factory.KeyGeneratorFactory;
 import com.huawei.unibi.molap.metadata.MolapMetadata;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Cube;
@@ -547,10 +549,16 @@ public class MolapFactReaderStep extends BaseStep implements StepInterface
         info.setMaskedByteRangeForSorting(maskedByteRangeForSorting);
         info.setDimensionMaskKeys(QueryExecutorUtility.getMaksedKeyForSorting(queryDimensions,
                 globalKeyGenerator, maskedByteRangeForSorting, maskByteRanges));
-        info.setColumnarSplitter(new MultiDimKeyVarLengthEquiSplitGenerator(
-                MolapUtil.getIncrementedCardinalityFullyFilled(slice.getDataCache(cube.getFactTableName())
-                        .getDimCardinality()), (byte)1));
-        info.setQueryDimOrdinal(QueryExecutorUtility.getSelectedDimnesionIndex(queryDimensions));
+        info.setColumnarSplitter(new MultiDimKeyVarLengthVariableSplitGenerator(MolapUtil.getDimensionBitLength(slice.getHybridStoreModel().getHybridCardinality(),slice.getHybridStoreModel().getDimensionPartitioner()),slice.getHybridStoreModel().getColumnSplit()));
+        if(slice.getHybridStoreModel().isHybridStore())
+        {
+        	 info.setQueryDimOrdinal(QueryExecutorUtility.getSelectedDimensionStoreIndex(queryDimensions,info.getHybridStoreMeta()));
+        }
+        else
+        {
+        	info.setQueryDimOrdinal(QueryExecutorUtility.getSelectedDimnesionIndex(queryDimensions));
+        }
+        
         List<Dimension> customDim = new ArrayList<Dimension>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
         info.setAllSelectedDimensions(QueryExecutorUtility.getAllSelectedDiemnsion(queryDimensions,dimAggInfo,customDim));
         info.setLimit(-1);
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/GraphGenerator.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/GraphGenerator.java
index 6207ad7..44e02ce 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/GraphGenerator.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/GraphGenerator.java
@@ -1519,14 +1519,11 @@ public class GraphGenerator
         //
         MolapCSVBasedSeqGenMeta seqMeta = new MolapCSVBasedSeqGenMeta();
         seqMeta.setMolapdim(graphConfiguration.getDimensionString());
-        seqMeta.setComplexTypeString(graphConfiguration.getComplexTypeString());
         seqMeta.setBatchSize(Integer.parseInt(graphConfiguration.getBatchSize()));
         seqMeta.setHighCardinalityDims(graphConfiguration.getHighCardinalityDims());
         // seqMeta.setStoreLocation(graphConfiguration.getStoreLocation());
         seqMeta.setCubeName(cubeName);
         seqMeta.setSchemaName(schemaName);
-        seqMeta.setComplexDelimiterLevel1(schemaInfo.getComplexDelimiterLevel1());
-        seqMeta.setComplexDelimiterLevel2(schemaInfo.getComplexDelimiterLevel2());
         seqMeta.setCurrentRestructNumber(graphConfiguration.getCurrentRestructNumber());
         seqMeta.setMolapMetaHier(graphConfiguration.getMetaHeirString());
         seqMeta.setMolapmsr(graphConfiguration.getMeasuresString());
@@ -1608,7 +1605,6 @@ public class GraphGenerator
         molapMdKey.setTableName(graphConfiguration.getTableName());
         molapMdKey.setSchemaName(schemaName);
         molapMdKey.setCubeName(cubeName);
-        molapMdKey.setComplexTypeString(graphConfiguration.getComplexTypeString());
         molapMdKey.setCurrentRestructNumber(graphConfiguration.getCurrentRestructNumber());
         molapMdKey.setAggregateLevels(MolapDataProcessorUtil
                 .getLevelCardinalitiesString(
@@ -1616,9 +1612,7 @@ public class GraphGenerator
                         graphConfiguration.getDimensions()));
         
         molapMdKey.setMeasureCount(graphConfiguration.getMeasureCount() + "");
-        molapMdKey.setDimensionCount(graphConfiguration.getActualDims().length + "");
-        molapMdKey.setComplexDimsCount(graphConfiguration.getComplexTypeString().isEmpty()?"0":graphConfiguration.getComplexTypeString().
-        		split(MolapCommonConstants.SEMICOLON_SPC_CHARACTER).length + "");
+        molapMdKey.setDimensionsStoreTypeString(graphConfiguration.getDimensionStoreTypeString());
         StepMeta mdkeyStepMeta = new StepMeta(
                 GraphGeneratorConstants.MDKEY_GENERATOR
                         + graphConfiguration.getTableName(),
@@ -2228,8 +2222,6 @@ public class GraphGenerator
         sortRowsMeta.setOutputRowSize(actualMeasures.length + 1 + "");
         sortRowsMeta.setCurrentRestructNumber(graphConfiguration.getCurrentRestructNumber());
         sortRowsMeta.setDimensionCount(graphConfiguration.getDimensions().length + "");
-        sortRowsMeta.setComplexDimensionCount(graphConfiguration.getComplexTypeString().isEmpty()?"0":graphConfiguration.getComplexTypeString().
-        		split(MolapCommonConstants.SEMICOLON_SPC_CHARACTER).length + "");
         sortRowsMeta.setIsUpdateMemberRequest(isUpdateMemberRequest + "");
         sortRowsMeta.setMeasureCount(graphConfiguration.getMeasureCount() + "");
         sortRowsMeta.setHighCardinalityDims(graphConfiguration.getHighCardinalityDims());
@@ -2264,8 +2256,6 @@ public class GraphGenerator
        // graphConfiguration.setHighCardinalityDims(MolapSchemaParser.getHighCardinalityDimensions(cube, schema));
         graphConfiguration.setActualDims(MolapSchemaParser.getDimensions(cube,
                 schema));
-        graphConfiguration.setComplexTypeString(MolapSchemaParser.getLevelDataTypeAndParentMapString(cube,
-        		schema));
         String factTableName = MolapSchemaParser.getFactTableName(cube);
         graphConfiguration.setTableName(factTableName);
         StringBuilder dimString = new StringBuilder();
@@ -2306,6 +2296,8 @@ public class GraphGenerator
         graphConfiguration.setConnectionName("target");
         graphConfiguration.setHeirAndDimLens(MolapSchemaParser
                 .getHeirAndCardinalityString(dimensions, schema));
+        //setting dimension store types
+        graphConfiguration.setDimensionStoreTypeString(MolapSchemaParser.getDimensionsStoreType(cube, schema));
         graphConfiguration.setPrimaryKeyString(MolapSchemaParser
                 .getPrimaryKeyString(dimensions, schema));
         graphConfiguration.setDenormColumns(MolapSchemaParser
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/configuration/GraphConfigurationInfo.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/configuration/GraphConfigurationInfo.java
index a3340f0..b522d89 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/configuration/GraphConfigurationInfo.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/graphgenerator/configuration/GraphConfigurationInfo.java
@@ -177,7 +177,6 @@ public class GraphConfigurationInfo
      * 
      */
     private String [] actualDims;
-
     /**
      * Sets the dimension:hirearchy#levelnames1,levelName2 
      */
@@ -192,13 +191,8 @@ public class GraphConfigurationInfo
      * mdkeySize
      */
     private String mdkeySize;
-    
-	/**
-	 * complexTypeString
-	 */
-	private String complexTypeString;
 
-	/**
+    /**
      * measureCount
      */
     
@@ -294,7 +288,23 @@ public class GraphConfigurationInfo
      
      private String levelAnddataType;
      
-    /**
+     /**
+      * true represent columnar store
+      * false represent row store
+      */
+     private String dimensionStoreType;
+     
+     public String getDimensionStoreTypeString()
+	 {
+		return dimensionStoreType;
+	 }
+
+	 public void setDimensionStoreTypeString(String dimensionStoreType)
+	 {
+		this.dimensionStoreType = dimensionStoreType;
+	 }
+
+	/**
      * @return the connectionName
      */
     public String getConnectionName()
@@ -379,14 +389,6 @@ public class GraphConfigurationInfo
         this.tableName = tableName;
     }
 
-    public String getComplexTypeString() {
-		return complexTypeString;
-	}
-
-	public void setComplexTypeString(String complexTypeString) {
-		this.complexTypeString = complexTypeString;
-	}
-	
     /**
      * @return the leafNodeSize
      */
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStep.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStep.java
index 85b23e5..3ba673f 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStep.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStep.java
@@ -16,18 +16,11 @@ wcFcE9sOJA21XxKLHhsfpiNjOXWVDTusYXFm8W8GB9h6a5aIG6Laf6S5m92gQg==*/
 */
 package com.huawei.unibi.molap.mdkeygen;
 
-import java.io.ByteArrayOutputStream;
-import java.io.DataOutputStream;
 import java.io.File;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
+
+
+
 
 import org.pentaho.di.core.exception.KettleException;
 import org.pentaho.di.core.row.RowMeta;
@@ -40,7 +33,6 @@ import org.pentaho.di.trans.step.StepDataInterface;
 import org.pentaho.di.trans.step.StepMeta;
 import org.pentaho.di.trans.step.StepMetaInterface;
 
-import com.huawei.datasight.molap.datatypes.GenericDataType;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.iweb.platform.logging.impl.StandardLogService;
@@ -49,7 +41,6 @@ import com.huawei.unibi.molap.file.manager.composite.FileData;
 import com.huawei.unibi.molap.file.manager.composite.IFileManagerComposite;
 import com.huawei.unibi.molap.file.manager.composite.LoadFolderData;
 import com.huawei.unibi.molap.keygenerator.KeyGenException;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.keygenerator.factory.KeyGeneratorFactory;
 import com.huawei.unibi.molap.store.MolapFactDataHandlerColumnar;
 import com.huawei.unibi.molap.store.MolapFactHandler;
@@ -60,6 +51,7 @@ import com.huawei.unibi.molap.util.MolapProperties;
 import com.huawei.unibi.molap.util.MolapUtil;
 import com.huawei.unibi.molap.util.MolapUtilException;
 import com.huawei.unibi.molap.util.RemoveDictionaryUtil;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 /**
  * Project Name 	: Carbon 
@@ -91,11 +83,6 @@ public class MDKeyGenStep extends BaseStep
     private int dimensionCount;
     
     /**
-     * dimsLenIncludingComplexPrimitives
-     */
-    private int dimsLenIncludingComplexPrimitives;
-    
-    /**
      * table name
      */
     private String tableName;
@@ -105,8 +92,6 @@ public class MDKeyGenStep extends BaseStep
      */
     private IFileManagerComposite fileManager;
     
-    private Map<Integer,GenericDataType> complexIndexMap;
-    
     /**
      * readCounter
      */
@@ -127,6 +112,8 @@ public class MDKeyGenStep extends BaseStep
      * dataHandler
      */
     private MolapFactHandler dataHandler;
+
+	private HybridStoreModel hybridStoreModel;
     
     /**
      * MolapMDKeyGenStep
@@ -167,7 +154,6 @@ public class MDKeyGenStep extends BaseStep
             StandardLogService.setThreadName(StandardLogService.getPartitionID(meta.getCubeName()), null);
             data = (MDKeyGenStepData)sdi;
             
-            meta.initialize();
             Object[] row = getRow();
             if(first)
             {
@@ -193,7 +179,7 @@ public class MDKeyGenStep extends BaseStep
             	putRow(data.outputRowMeta, new Object[measureCount + 1]);
             	return true;
             }
-            
+            long startTime=System.currentTimeMillis();
             if(null!=dataHandler && null!=finalMerger)
             {
 				try 
@@ -225,7 +211,8 @@ public class MDKeyGenStep extends BaseStep
 				}
 			}
             
-
+            long timeTaken=(System.currentTimeMillis()-startTime);
+            LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, "Time taken for MDKeygenStep:"+ timeTaken);
             LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, "Record Procerssed For table: "+ this.tableName);
             String logMessage= "Finished Molap Mdkey Generation Step: Read: " + readCounter + ": Write: "+ writeCounter;
             LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, logMessage);
@@ -302,18 +289,7 @@ public class MDKeyGenStep extends BaseStep
         
         int[] dimLens = null;
 		try {
-			int[] dimLensWithComplex = MolapUtil.getCardinalityFromLevelMetadataFile(levelCardinalityFilePath);
-			List<Integer> dimsLenList = new ArrayList<Integer>();
-			for(int eachDimLen : dimLensWithComplex)
-			{
-				if(eachDimLen != 0)
-					dimsLenList.add(eachDimLen);
-			}
-			dimLens = new int[dimsLenList.size()];
-			for(int i=0;i<dimsLenList.size();i++)
-			{
-				dimLens[i] = dimsLenList.get(i);
-			}
+			dimLens = MolapUtil.getCardinalityFromLevelMetadataFile(levelCardinalityFilePath);
 		} catch (MolapUtilException e) {
 			LOGGER.error(
                     MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG,
@@ -327,45 +303,19 @@ public class MDKeyGenStep extends BaseStep
                     "Cardinality could not determined. Nothing to process further in MDKeyGenstep");
 			return false;
 		}
-  
-		data.generator = new KeyGenerator[dimLens.length + 1];
+		
+		String[] dimStoreType = meta.getDimensionsStoreType().split(",");
+		boolean[] dimensionStoreType = new boolean[dimLens.length];
 		for(int i=0;i<dimLens.length;i++)
 		{
-			data.generator[i] = KeyGeneratorFactory.getKeyGenerator(new int[]{dimLens[i]});
+			dimensionStoreType[i]=Boolean.parseBoolean(dimStoreType[i]);
 		}
-        
-//      this.dimensionCount = dimLens.length;
-      this.dimensionCount = meta.getDimensionCount();
-      this.dimsLenIncludingComplexPrimitives = dimLens.length;
-      
-      int simpleDimsCount = this.dimensionCount - meta.getComplexDimsCount();
-      int[] simpleDimsLen = new int[simpleDimsCount];
-      for(int i=0;i<simpleDimsCount;i++)
-      {
-      	simpleDimsLen[i] = dimLens[i];
-      }
-      
-      //Actual primitive dimension used to generate start & end key 
-      data.generator[dimLens.length] = KeyGeneratorFactory.getKeyGenerator(simpleDimsLen);
-      
-      //To Set MDKey Index of each primitive type in complex type 
-      int surrIndex = simpleDimsCount;
-      Iterator<Entry<String,GenericDataType>> complexMap = meta.getComplexTypes().entrySet().iterator();
-      complexIndexMap = new HashMap<Integer,GenericDataType>(meta.getComplexDimsCount());
-      while(complexMap.hasNext())
-      {
-          Entry<String,GenericDataType> complexDataType = complexMap.next();
-          complexDataType.getValue().setOutputArrayIndex(0);
-          complexIndexMap.put(simpleDimsCount, complexDataType.getValue());
-          simpleDimsCount++;
-          List<GenericDataType> primitiveTypes = new ArrayList<GenericDataType>();
-          complexDataType.getValue().getAllPrimitiveChildren(primitiveTypes);
-          for(GenericDataType eachPrimitive : primitiveTypes)
-          {
-          	eachPrimitive.setSurrogateIndex(surrIndex++);
-          }
-      }
+		this.hybridStoreModel = MolapUtil.getHybridStoreMeta(dimLens,
+				dimensionStoreType,null);
       
+		data.generator = KeyGeneratorFactory.getKeyGenerator(hybridStoreModel.getHybridCardinality(),hybridStoreModel.getDimensionPartitioner());
+        
+        this.dimensionCount = dimLens.length;
         
         this.measureCount = meta.getMeasureCount();
 
@@ -382,31 +332,32 @@ public class MDKeyGenStep extends BaseStep
         /*finalMerger = new SingleThreadFinalSortFilesMerger(dataFolderLocation,
     			tableName, dimensionCount, measureCount,meta.getHighCardinalityDims().length);*/
         finalMerger = new SingleThreadFinalSortFilesMerger(dataFolderLocation,
-                tableName, dimensionCount - meta.getComplexDimsCount(), meta.getComplexDimsCount(), measureCount,meta.getHighCardinalityCount());
+                tableName, dimensionCount, measureCount,meta.getHighCardinalityCount());
         if(meta.getHighCardinalityCount() > 0)
         {
             dataHandler = new MolapFactDataHandlerColumnar(
                     meta.getSchemaName(), meta.getCubeName(), this.tableName,
-                    false, measureCount, data.generator[dimLens.length].getKeySizeInBytes(),
+                    false, measureCount, data.generator.getKeySizeInBytes(),
                     measureCount + 1, null, null, storeLocation, dimLens,
                     false, false, dimLens, null, null, true,
                     meta.getCurrentRestructNumber(),
-                    meta.getHighCardinalityCount(), dimensionCount, complexIndexMap);
+                    meta.getHighCardinalityCount(),this.hybridStoreModel);
         }
         else
         {
             dataHandler = new MolapFactDataHandlerColumnar(
                     meta.getSchemaName(), meta.getCubeName(), this.tableName,
-                    false, measureCount, data.generator[dimLens.length].getKeySizeInBytes(),
-                    measureCount, null, null, storeLocation, dimLens,
+                    false, measureCount, data.generator.getKeySizeInBytes(),
+                    measureCount , null, null, storeLocation, dimLens,
                     false, false, dimLens, null, null, true,
                     meta.getCurrentRestructNumber(),
-                    meta.getHighCardinalityCount(), dimensionCount, complexIndexMap);
+                    meta.getHighCardinalityCount(),this.hybridStoreModel);
         }
         return true;
     }
 
-    /**
+   
+	/**
      * This method will be used for setting the output interface.
      * Output interface is how this step will process the row to next step  
      */
@@ -450,16 +401,14 @@ public class MDKeyGenStep extends BaseStep
     {
         Object[] outputRow = null;
         // adding one for the high cardinality dims byte array.
-        if(meta.getHighCardinalityCount() > 0 || meta.getComplexDimsCount() > 0)
+        if(meta.getHighCardinalityCount() > 0)
         {
-        	outputRow = new Object[measureCount + 1 + 1];
+            outputRow = new Object[measureCount + 1 + 1];
         }
         else
         {
             outputRow = new Object[measureCount + 1];
         }
-        int[] keys = new int[this.dimensionCount];
-
         int l = 0;
         int index = 0;
         for(int i = 0; i < measureCount; i++)
@@ -470,10 +419,40 @@ public class MDKeyGenStep extends BaseStep
             	outputRow[l++] = (Double)RemoveDictionaryUtil.getMeasure(index++, row);
 //            }
         }
-        outputRow[l] =  RemoveDictionaryUtil.getByteArrayForNoDictionaryCols(row);
+         outputRow[l] =  RemoveDictionaryUtil.getByteArrayForNoDictionaryCols(row);
+        // copy all columnar dimension to columnar key array
+        int[] columnarStoreOrdinals=hybridStoreModel.getColumnStoreOrdinals();
+        int[] columnarDataKeys=new int[columnarStoreOrdinals.length];
+        for(int i=0;i<columnarStoreOrdinals.length;i++)
+        {
+        	 Object key =  RemoveDictionaryUtil.getDimension(columnarStoreOrdinals[i], row);;
+        	 columnarDataKeys[i] = (Integer)key;
+             
+        }
+        
+        //copy all row store dimension to row key array
+        int[] rowStoreOrdinals=hybridStoreModel.getRowStoreOrdinals();
+        int[] rowDataKeys=new int[rowStoreOrdinals.length];
+        for(int i=0;i<rowStoreOrdinals.length;i++)
+        {
+        	Object key =  RemoveDictionaryUtil.getDimension(rowStoreOrdinals[i],row);
+        	rowDataKeys[i] = (Integer)key;
+        }
         
+        try
+        {
+        	int[] completeData=new int[columnarDataKeys.length+rowDataKeys.length];
+        	System.arraycopy(rowDataKeys, 0, completeData, 0,rowDataKeys.length);
+        	System.arraycopy(columnarDataKeys, 0, completeData, rowDataKeys.length, columnarDataKeys.length);
+        	
+        	outputRow[outputRow.length - 1] = data.generator.generateKey(completeData);
+        }
+        catch(KeyGenException e)
+        {
+        	 throw new KettleException("Unbale to generate the mdkey", e);
+        }
         // copy all the dimension to keys Array. This key array will be used to generate id
-        for(int i = 0; i < this.dimensionCount; i++)
+      /*  for(int i = 0; i < this.dimensionCount; i++)
         {
             Object key = RemoveDictionaryUtil.getDimension(i, row);
             keys[i] = (Integer)key;
@@ -482,13 +461,13 @@ public class MDKeyGenStep extends BaseStep
         try
         {
             // generate byte array from id.
-            byte[] k = data.generator[data.generator.length-1].generateKey(keys);
+            byte[] k = data.generator.generateKey(keys);
             outputRow[outputRow.length - 1] = k;
         }
         catch(KeyGenException e)
         {
             throw new KettleException("Unbale to generate the mdkey", e);
-        }
+        }*/
         
         return outputRow;
     }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepData.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepData.java
index 890603d..71d51e1 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepData.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepData.java
@@ -47,9 +47,9 @@ public class MDKeyGenStepData extends BaseStepData implements
   //  protected RowMetaInterface rowMeta;
     
     /**
-     * generator for each column independently
+     * generator
      */
-    protected KeyGenerator[] generator;
+    protected KeyGenerator generator;
     
     /**
      * precomputed default objects
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepMeta.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepMeta.java
index edb93bb..9f0e8e3 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepMeta.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/mdkeygen/MDKeyGenStepMeta.java
@@ -18,7 +18,6 @@ ha0lV5CtaKBMz+q4WgyOq9DZZsMS3YQWs9M5OKLquLd1C9HNPFoI0S8QtbtLrA==*/
  */
 package com.huawei.unibi.molap.mdkeygen;
 
-import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 
@@ -41,11 +40,6 @@ import org.pentaho.di.trans.step.StepMeta;
 import org.pentaho.di.trans.step.StepMetaInterface;
 import org.w3c.dom.Node;
 
-import com.huawei.datasight.molap.datatypes.ArrayDataType;
-import com.huawei.datasight.molap.datatypes.GenericDataType;
-import com.huawei.datasight.molap.datatypes.PrimitiveDataType;
-import com.huawei.datasight.molap.datatypes.StructDataType;
-import com.huawei.unibi.molap.constants.MolapCommonConstants;
 import com.huawei.unibi.molap.util.MolapDataProcessorUtil;
 
 /**
@@ -59,7 +53,7 @@ import com.huawei.unibi.molap.util.MolapDataProcessorUtil;
  */
 public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
 {
-	/**
+    /**
      * for i18n purposes
      */
     private static Class<?> pkg = MDKeyGenStepMeta.class;
@@ -94,24 +88,14 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
      */
     private String measureCount;
     
+    private int currentRestructNumber;
+
     /**
-     * dimensionCount
-     */
-    private String dimensionCount;
-    
-    /**
-     * complexDimsCount
-     */
-    private String complexDimsCount;
-    
-    /**
-     * ComplexTypeString
+     * this states whether given dimension is columnar or row based store
+     * true: columnar
+     * false: row
      */
-    private String complexTypeString;
-    
-    private Map<String, GenericDataType> complexTypes;
-    
-    private int currentRestructNumber;
+	private String dimensionsStoreType;
     
 	private String  highCardinalityDims;
 	
@@ -135,6 +119,7 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
         aggregateLevels = "";
         cubeName = "";
         schemaName = "";
+        dimensionsStoreType = "";       
         highCardinalityDims="";
         currentRestructNumber = -1;
     }
@@ -153,9 +138,7 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
         retval.append("    ").append(XMLHandler.addTagValue("schemaName", schemaName));
         retval.append("    ").append(XMLHandler.addTagValue("highCardinalityDims", highCardinalityDims));
         retval.append("    ").append(XMLHandler.addTagValue("measureCount", measureCount));
-        retval.append("    ").append(XMLHandler.addTagValue("dimensionCount", dimensionCount));
-        retval.append("    ").append(XMLHandler.addTagValue("complexDimsCount", complexDimsCount));
-        retval.append("    ").append(XMLHandler.addTagValue("complexTypeString", complexTypeString));
+        retval.append("    ").append(XMLHandler.addTagValue("dimensionsStoreType", dimensionsStoreType));
         retval.append("    ").append(XMLHandler.addTagValue("currentRestructNumber", currentRestructNumber));
         return retval.toString();
     }
@@ -174,9 +157,7 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
             cubeName = XMLHandler.getTagValue(stepnode, "cubeName");
             highCardinalityDims = XMLHandler.getTagValue(stepnode, "highCardinalityDims");
             measureCount = XMLHandler.getTagValue(stepnode, "measureCount");
-            dimensionCount = XMLHandler.getTagValue(stepnode, "dimensionCount");
-            complexDimsCount = XMLHandler.getTagValue(stepnode, "complexDimsCount");
-            complexTypeString = XMLHandler.getTagValue(stepnode, "complexTypeString");
+            dimensionsStoreType=XMLHandler.getTagValue(stepnode, "dimensionsStoreType");
             currentRestructNumber = Integer.parseInt(XMLHandler.getTagValue(
                     stepnode, "currentRestructNumber"));
         }
@@ -204,9 +185,7 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
             rep.saveStepAttribute(idTransformation, idStep, "cubeName", cubeName);
             rep.saveStepAttribute(idTransformation, idStep, "highCardinalityDims", highCardinalityDims);
             rep.saveStepAttribute(idTransformation, idStep, "measureCount", measureCount);
-            rep.saveStepAttribute(idTransformation, idStep, "dimensionCount", dimensionCount);
-            rep.saveStepAttribute(idTransformation, idStep, "complexDimsCount", complexDimsCount);
-            rep.saveStepAttribute(idTransformation, idStep, "complexTypeString", complexTypeString);
+            rep.saveStepAttribute(idTransformation,idStep,"dimensionsStoreType",dimensionsStoreType);
             rep.saveStepAttribute(idTransformation, idStep, "currentRestructNumber", 
                     currentRestructNumber);
         }
@@ -231,9 +210,7 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
             cubeName = rep.getStepAttributeString(idStep, "cubeName");
             highCardinalityDims=rep.getStepAttributeString(idStep, "highCardinalityDims");
             measureCount = rep.getStepAttributeString(idStep, "measureCount");
-            dimensionCount = rep.getStepAttributeString(idStep, "dimensionCount");
-            complexDimsCount = rep.getStepAttributeString(idStep, "complexDimsCount");
-            complexTypeString = rep.getStepAttributeString(idStep, "complexTypeString");
+            dimensionsStoreType=rep.getStepAttributeString(idStep, "dimensionsStoreType");
             currentRestructNumber = (int)rep.getStepAttributeInteger(idStep, 
                     "currentRestructNumber");
         }
@@ -283,15 +260,7 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
     {
         return aggregateLevels;
     }
-    
-    public Map<String, GenericDataType> getComplexTypes() {
-		return complexTypes;
-	}
 
-	public void setComplexTypes(Map<String, GenericDataType> complexTypes) {
-		this.complexTypes = complexTypes;
-	}
-    
     public String getNumberOfCores()
     {
         return numberOfCores;
@@ -325,30 +294,6 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
     {
         this.measureCount = measureCount;
     }
-    
-    /**
-     * @param dimensionCount the dimensionCount to set
-     */
-    public void setDimensionCount(String dimensionCount)
-    {
-    	this.dimensionCount = dimensionCount;
-    }
-    
-    /**
-     * @param complexDimsCount the complexDimsCount to set
-     */
-    public void setComplexDimsCount(String complexDimsCount)
-    {
-    	this.complexDimsCount = complexDimsCount;
-    }
-
-    /**
-     * @param complexTypeString the complexTypeString to set
-     */
-    public void setComplexTypeString(String complexTypeString)
-    {
-    	this.complexTypeString = complexTypeString;
-    }
 
     /**
      * @param cubeName the cubeName to set
@@ -357,7 +302,7 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
     {
         this.cubeName = cubeName;
     }
-    
+
     /**
      * @param schemaName the schemaName to set
      */
@@ -375,30 +320,6 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
     }
     
     /**
-     * @return the dimensionCount
-     */
-    public int getDimensionCount()
-    {
-    	return Integer.parseInt(dimensionCount);
-    }
-
-    /**
-     * @return the complexDimsCount
-     */
-    public int getComplexDimsCount()
-    {
-    	return Integer.parseInt(complexDimsCount);
-    }
-
-    /**
-     * @return the complexTypeString
-     */
-    public int getComplexTypeString()
-    {
-    	return Integer.parseInt(complexTypeString);
-    }
-    
-    /**
      * @return the currentRestructNumber
      */
     public int getCurrentRestructNumber()
@@ -444,42 +365,17 @@ public class MDKeyGenStepMeta extends BaseStepMeta implements StepMetaInterface
     {
         this.highCardinalityCount = highCardinalityCount;
     }
-    
-    public void initialize()
-    {
-    	complexTypes = getComplexTypesMap(complexTypeString);
-    }
-    private Map<String,GenericDataType> getComplexTypesMap(String complexTypeString)
-    {
-    	if(null==complexTypeString)
-    	{
-    		return new LinkedHashMap<>();
-    	}
-    	Map<String,GenericDataType> complexTypesMap = new LinkedHashMap<String,GenericDataType>();
-    	String[] hierarchies = complexTypeString.split(MolapCommonConstants.SEMICOLON_SPC_CHARACTER);
-        for(int i = 0;i < hierarchies.length;i++)
-        {
-            String[] levels = hierarchies[i].split(MolapCommonConstants.HASH_SPC_CHARACTER);
-            String[] levelInfo = levels[0].split(MolapCommonConstants.COLON_SPC_CHARACTER);
-			GenericDataType g = levelInfo[1].equals("Array")?
-						new ArrayDataType(levelInfo[0], ""):new StructDataType(levelInfo[0], "");
-			complexTypesMap.put(levelInfo[0], g);
-            for(int j = 1;j < levels.length;j++)
-            {
-            	levelInfo = levels[j].split(MolapCommonConstants.COLON_SPC_CHARACTER);
-				switch(levelInfo[1])
-				{
-					case "Array" : 
-						g.addChildren(new ArrayDataType(levelInfo[0], levelInfo[2]));
-						break;
-					case "Struct" : 
-						g.addChildren(new StructDataType(levelInfo[0], levelInfo[2]));
-						break;
-					default :
-						g.addChildren(new PrimitiveDataType(levelInfo[0], levelInfo[2]));
-				}
-            }
-        }
-        return complexTypesMap;
-    }
+
+
+	public void setDimensionsStoreTypeString(String dimensionStoreType)
+	{
+		this.dimensionsStoreType=dimensionStoreType;
+		
+	}
+	
+	public String getDimensionsStoreType()
+	{
+		return this.dimensionsStoreType;
+	}
+
 }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapColumnarSliceMerger.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapColumnarSliceMerger.java
index 94a87b7..5018b96 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapColumnarSliceMerger.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapColumnarSliceMerger.java
@@ -1,7 +1,6 @@
 package com.huawei.unibi.molap.merger;
 
 import java.io.File;
-import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
@@ -18,8 +17,6 @@ import com.huawei.unibi.molap.datastorage.store.compression.ValueCompressionMode
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
 import com.huawei.unibi.molap.exception.MolapDataProcessorException;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.keygenerator.factory.KeyGeneratorFactory;
 import com.huawei.unibi.molap.merger.columnar.ColumnarFactFileMerger;
 import com.huawei.unibi.molap.merger.columnar.impl.NonTimeBasedMergerColumnar;
 import com.huawei.unibi.molap.merger.columnar.impl.TimeBasedMergerColumnar;
@@ -28,15 +25,11 @@ import com.huawei.unibi.molap.merger.sliceMerger.DimesionMappingFileMerger;
 import com.huawei.unibi.molap.merger.sliceMerger.HierarchyFileMerger;
 import com.huawei.unibi.molap.metadata.LeafNodeInfoColumnar;
 import com.huawei.unibi.molap.metadata.SliceMetaData;
-
-
 import com.huawei.unibi.molap.schema.metadata.AggregateTable;
 import com.huawei.unibi.molap.schema.metadata.MolapColumnarFactMergerInfo;
 import com.huawei.unibi.molap.util.ByteUtil;
-import com.huawei.unibi.molap.util.MolapCoreLogEvent;
 import com.huawei.unibi.molap.util.MolapDataProcessorLogEvent;
 import com.huawei.unibi.molap.util.MolapDataProcessorUtil;
-import com.huawei.unibi.molap.util.MolapMergerUtil;
 import com.huawei.unibi.molap.util.MolapProperties;
 import com.huawei.unibi.molap.util.MolapSchemaParser;
 import com.huawei.unibi.molap.util.MolapSliceAndFiles;
@@ -59,10 +52,6 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
      * table name to be merged
      */
     private String tableName;
-    
-    private List<String> loadsToBeMerged;
-    
-    private String mergedLoadName;
 
     /**
      * logger
@@ -136,24 +125,20 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
             cube.name = cube.name + '_' + molapSliceMergerInfo.getPartitionID();
         }
         this.tableName = molapSliceMergerInfo.getTableName();
-        
-        this.loadsToBeMerged = molapSliceMergerInfo.getLoadsToBeMerged();
-        
-        this.mergedLoadName = molapSliceMergerInfo.getMergedLoadName();
     }
 
     @Override
-    public boolean fullMerge(int currentRestructNumber) throws SliceMergerException
+    public void fullMerge(int currentRestructNumber) throws SliceMergerException
     {
-        
         String hdfsLocation = MolapProperties.getInstance().getProperty(
                 MolapCommonConstants.STORE_LOCATION_HDFS)
                 + '/' + schema.name + '/' + cube.name;
 
         LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG,"HDFS Location: "+ hdfsLocation);
-//        String tempLocationKey = schema.name + '/' + cube.name;
+//        System.out.println("HDFS Location: "+ hdfsLocation);
+        String tempLocationKey = schema.name + '/' + cube.name;
         String localStore = MolapProperties.getInstance().getProperty(
-                MolapCommonConstants.STORE_LOCATION,
+                tempLocationKey,
                 MolapCommonConstants.STORE_LOCATION_DEFAULT_VAL)
                 + '/' + schema.name + '/' + cube.name;
 
@@ -166,33 +151,10 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
         hdfsLocation = hdfsLocation + '/'
                 + MolapCommonConstants.RESTRUCTRE_FOLDER + restrctFolderCount
                 + '/' + tableName;
-        
-        
-        
-        try
-        {
-            if(!FileFactory.isFileExist(hdfsLocation, FileFactory.getFileType(hdfsLocation)))
-            {
-                return false;
-            }
-        }
-        catch(IOException e)
-        {
-            LOGGER.error(
-                    MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG ,
-                    "Error occurred :: " + e.getMessage());
-        }
-        
-        
-        
-        List<MolapSliceAndFiles> slicesFromHDFS = MolapMergerUtil.getSliceAndFilesList(
-                hdfsLocation, this.tableName,FileFactory.getFileType(hdfsLocation),loadsToBeMerged);
-        
-        if(slicesFromHDFS.isEmpty())
-        {
-            return false;
-        }
-        
+        List<MolapSliceAndFiles> slicesFromHDFS = MolapUtil.getSlicesFromHDFS(
+                hdfsLocation, this.tableName, FileFactory.getFileType(hdfsLocation));
+        String[] lastloadFolder = slicesFromHDFS.get(slicesFromHDFS.size() - 1)
+                .getPath().split("_");
         localStore = localStore
                 + '/'
                 + MolapCommonConstants.RESTRUCTRE_FOLDER
@@ -200,16 +162,18 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
                 + '/'
                 + tableName
                 +'/'
-                + MolapCommonConstants.LOAD_FOLDER+mergedLoadName;
+                + MolapCommonConstants.LOAD_FOLDER
+                + (Integer.parseInt(lastloadFolder[lastloadFolder.length - 1]) + 1);
 
         String destinationLocation = localStore
+                + MolapCommonConstants.MERGERD_EXTENSION
                 + MolapCommonConstants.FILE_INPROGRESS_STATUS;
       File file = new File(destinationLocation);
       if(!file.mkdirs())
       {
           throw new SliceMergerException("Problem while creating the destination location for slicemerging");
-          
       }
+      
       startMerge(slicesFromHDFS,
               MolapUtil.readSliceMetaDataFile(hdfsLocation, restrctFolderCount),file.getAbsolutePath(), restrctFolderCount);
       
@@ -217,12 +181,61 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
       {
           throw new SliceMergerException("Problem while renaming the destination location for slicemerging");
       }
-      return true;
     }
 
+//    @Override
+//    public void fullMerge() throws SliceMergerException
+//    {
+//        String hdfsLocation = MolapProperties.getInstance().getProperty(
+//                MolapCommonConstants.STORE_LOCATION,
+//                MolapCommonConstants.STORE_LOCATION_DEFAULT_VAL)
+//                + "/" + schema.name + "/" + cube.name;
+//
+//        String localStore = MolapProperties.getInstance().getProperty(
+//                MolapCommonConstants.STORE_LOCATION,
+//                MolapCommonConstants.STORE_LOCATION_DEFAULT_VAL)
+//                + "/" + schema.name + "/" + cube.name;
+//
+//        int restrctFolderCount = MolapUtil
+//                .checkAndReturnNextRestructFolderNumber(hdfsLocation);
+//        if(restrctFolderCount == -1)
+//        {
+//            restrctFolderCount = 0;
+//        }
+//        hdfsLocation = hdfsLocation + File.separator
+//                + MolapCommonConstants.RESTRUCTRE_FOLDER + restrctFolderCount
+//                + File.separator + tableName;
+//        List<MolapSliceAndFiles> slicesFromHDFS = MolapUtil.getSlicesFromLocal(
+//                hdfsLocation, this.tableName);
+//
+//        if(slicesFromHDFS.size() < 2)
+//        {
+//            return;
+//        }
+//        String[] lastloadFolder = slicesFromHDFS.get(slicesFromHDFS.size() - 1)
+//                .getPath().split("_");
+//        localStore = localStore
+//                + File.separator
+//                + MolapCommonConstants.RESTRUCTRE_FOLDER
+//                + restrctFolderCount
+//                + File.separator
+//                + tableName
+//                + File.separator
+//                + MolapCommonConstants.LOAD_FOLDER
+//                + (Integer.parseInt(lastloadFolder[lastloadFolder.length - 1]) + 1)
+//                + MolapCommonConstants.MERGERD_EXTENSION
+//                + MolapCommonConstants.FILE_INPROGRESS_STATUS;
+//
+//        File file = new File(localStore);
+//        file.mkdirs();
+//        startMerge(slicesFromHDFS,
+//                MolapUtil.readSliceMetaDataFile(hdfsLocation),
+//                file.getAbsolutePath());
+//    }
 
     /**
      * startMerge
+     * 
      * @throws SliceMergerException
      * @throws MolapDataProcessorException
      */
@@ -232,17 +245,43 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
             throws SliceMergerException
     {
         String factTableName = MolapSchemaParser.getFactTableName(this.cube);
+        if(MolapCommonConstants.MOLAP_AUTO_TYPE_VALUE
+                .equalsIgnoreCase(this.cube.autoAggregationType)
+                || MolapCommonConstants.MOLAP_MANUAL_TYPE_VALUE
+                        .equalsIgnoreCase(this.cube.autoAggregationType))
+        {
+            AggregateTable[] aggregateTables = MolapSchemaParser
+                    .getAggregateTable(this.cube, schema);
+            String[] aggregator = null;
             if(factTableName.equals(this.tableName))
             {
                 mergerSlice(slicesFromHDFS, sliceMetaData, null, null,
                         destinationLocation, currentRestructNumber);
             }
+            else
+            {
+                for(int i = 0;i < aggregateTables.length;i++)
+                {
+                    if(aggregateTables[i].getAggregateTableName().equals(
+                            this.tableName))
+                    {
+                        aggregator = aggregateTables[i].getAggregator();
+                        aggregator = MolapDataProcessorUtil
+                                .getUpdatedAggregator(aggregator);
+                        mergerSlice(slicesFromHDFS, sliceMetaData, aggregator,
+                                aggregateTables[i].getAggregateClass(),
+                                destinationLocation, currentRestructNumber);
+                        break;
                     }
+                }
+            }
+        }
+    }
 
     private MolapColumnarFactMergerInfo getMolapColumnarFactMergerInfo(
             List<MolapSliceAndFiles> slicesFromHDFS, String[] aggType,
             String[] aggClass, SliceMetaData readSliceMetaDataFile,
-            String destinationLocation, KeyGenerator globalKeyGen)
+            String destinationLocation)
     {
         MolapColumnarFactMergerInfo columnarFactMergerInfo = new MolapColumnarFactMergerInfo();
         columnarFactMergerInfo.setAggregatorClass(aggClass);
@@ -271,9 +310,6 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
         columnarFactMergerInfo.setTableName(tableName);
         columnarFactMergerInfo.setDimLens(readSliceMetaDataFile.getDimLens());
         columnarFactMergerInfo.setSlicesFromHDFS(slicesFromHDFS);
-        
-        columnarFactMergerInfo.setGlobalKeyGen(globalKeyGen);
-        
         char[] type = new char[readSliceMetaDataFile.getMeasures().length];
         Arrays.fill(type, 'n');
         if(null != aggType)
@@ -299,6 +335,7 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
      * Below method will be used for merging the slice All the concrete classes
      * will override this method and will implements its own type of merging
      * method
+     * 
      * @throws SliceMergerException
      *             will throw slice merger exception if any problem occurs
      *             during merging the slice
@@ -330,18 +367,10 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
                         factFiles[j], sliceMetaData.getMeasures().length,
                         sliceMetaData.getKeyGenerator().getKeySizeInBytes()));
             }
-
-            int [] cardinality = MolapMergerUtil.getCardinalityFromLevelMetadata(sliceAndFiles.getPath(),tableName);
-            KeyGenerator localKeyGen = KeyGeneratorFactory.getKeyGenerator(cardinality);
-            sliceAndFiles.setKeyGen(localKeyGen);
-            
-            
             leafNodeInfoList.add(sliceLeafNodeInfo);
             existingSliceCompressionModel
                     .add(getCompressionModel(sliceAndFiles.getPath(),
                             sliceMetaData.getMeasures().length));
-            
-            
         }
         for(int i = 0;i < sliceLocation.length;i++)
         {
@@ -382,26 +411,89 @@ public class MolapColumnarSliceMerger implements MolapSliceMerger
             writeMeasureMetaFile(maxValue, minValue, uniqueValue,
                     decimalLength, existingSliceCompressionModel.get(0)
                             .getType(), destinationLocation);
-            
-            // write level metadata
-            
-            int [] maxCardinality = MolapMergerUtil.mergeLevelMetadata(sliceLocation,tableName,destinationLocation);
-            
-            KeyGenerator globalKeyGen=KeyGeneratorFactory.getKeyGenerator(maxCardinality);
-            
-            
-            
+            boolean isTimeBased = checkIfTimeBased(leafNodeInfoList);
             ColumnarFactFileMerger factMerger = null;
-            
-            // pass global key generator;
+            // isTimeBased = false;
+            if(isTimeBased)
+            {
+                factMerger = new TimeBasedMergerColumnar(
+                        getMolapColumnarFactMergerInfo(slicesFromHDFS, aggType,
+                                aggClass, sliceMetaData, destinationLocation), currentRestructNumber);
+            }
+            else
+            {
                 factMerger = new NonTimeBasedMergerColumnar(
                         getMolapColumnarFactMergerInfo(slicesFromHDFS, aggType,
-                                aggClass, sliceMetaData, destinationLocation,globalKeyGen), currentRestructNumber);
+                                aggClass, sliceMetaData, destinationLocation), currentRestructNumber);
+            }
             LOGGER.info(
                     MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG,
                     "Starting fact file merging: ");
             factMerger.mergerSlice();
+            LOGGER.info(
+                    MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG,
+                    "Merging dimension mapping file");
+            DimesionMappingFileMerger dimesionMerger = new DimesionMappingFileMerger(
+                    destinationLocation);
+            dimesionMerger.mergerDimesionFile(sliceLocation, false, null);
+
+            LOGGER.info(
+                    MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG,
+                    "Merger Hierarchy file");
+            HierarchyFileMerger hierMerger = new HierarchyFileMerger(
+                    destinationLocation,
+                    getHeirAndKeySizeMap(sliceMetaData.getHeirAnKeySize()));
+            hierMerger.mergerData(sliceLocation);
+        }
+    }
+
+    /**
+     * setHeirAndKeySizeMap
+     * 
+     * @param heirAndKeySize
+     *            void
+     */
+    private Map<String, Integer> getHeirAndKeySizeMap(String heirAndKeySize)
+    {
+        String[] split = heirAndKeySize
+                .split(MolapCommonConstants.AMPERSAND_SPC_CHARACTER);
+        String[] split2 = null;
+        Map<String, Integer> heirAndKeySizeMap = new HashMap<String, Integer>(
+                split.length);
+        for(int i = 0;i < split.length;i++)
+        {
+            split2 = split[i].split(MolapCommonConstants.COLON_SPC_CHARACTER);
+            heirAndKeySizeMap.put(split2[0], Integer.parseInt(split2[1]));
+        }
+        return heirAndKeySizeMap;
+    }
+
+    /**
+     * This method checks whether its a time based merger or not If startkey of
+     * leaf is less than end key of next lef then its a time based merge
+     * 
+     * @param leafNodeInfoList
+     *            leafNodeInfoList
+     * @return is time based or not
+     * 
+     */
+    private boolean checkIfTimeBased(
+            List<List<LeafNodeInfoColumnar>> leafNodeInfoList)
+    {
+        byte[] startKey = null;
+        byte[] endKey = null;
+        for(int i = 1;i < leafNodeInfoList.size();i++)
+        {
+            List<LeafNodeInfoColumnar> list1 = leafNodeInfoList.get(i - 1);
+            endKey = list1.get(list1.size() - 1).getEndKey();
+            List<LeafNodeInfoColumnar> list2 = leafNodeInfoList.get(i);
+            startKey = list2.get(0).getStartKey();
+            if(ByteUtil.compare(endKey, startKey) > 0)
+            {
+                return false;
+            }
         }
+        return true;
     }
 
     /**
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMerger.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMerger.java
index 6b440c0..55d1ae0 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMerger.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMerger.java
@@ -4,5 +4,5 @@ import com.huawei.unibi.molap.merger.exeception.SliceMergerException;
 
 public interface MolapSliceMerger
 {
-    boolean fullMerge(int currentRestructNumber) throws SliceMergerException;
+    void fullMerge(int currentRestructNumber) throws SliceMergerException;
 }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMergerInfo.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMergerInfo.java
index c8838a6..0c8001d 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMergerInfo.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/MolapSliceMergerInfo.java
@@ -1,7 +1,5 @@
 package com.huawei.unibi.molap.merger;
 
-import java.util.List;
-
 import com.huawei.unibi.molap.olap.MolapDef.Schema;
 
 public class MolapSliceMergerInfo
@@ -17,12 +15,6 @@ public class MolapSliceMergerInfo
     private Schema schema;
     
     private String schemaPath;
-    
-    private String metadataPath;
-    
-    private List<String> loadsToBeMerged;
-    
-    private String mergedLoadName;
 
     /**
      * @return the schemaName
@@ -119,54 +111,6 @@ public class MolapSliceMergerInfo
     {
         this.schemaPath = schemaPath;
     }
-
-    /**
-     * @return the metadataPath
-     */
-    public String getMetadataPath()
-    {
-        return metadataPath;
-    }
-
-    /**
-     * @param metadataPath the metadataPath to set
-     */
-    public void setMetadataPath(String metadataPath)
-    {
-        this.metadataPath = metadataPath;
-    }
-
-    /**
-     * @return the loadsToBeMerged
-     */
-    public List<String> getLoadsToBeMerged()
-    {
-        return loadsToBeMerged;
-    }
-
-    /**
-     * @param loadsToMerge the loadsToBeMerged to set
-     */
-    public void setLoadsToBeMerged(List<String> loadsToMerge)
-    {
-        this.loadsToBeMerged = loadsToMerge;
-    }
-
-    /**
-     * @return the mergedLoadName
-     */
-    public String getMergedLoadName()
-    {
-        return mergedLoadName;
-    }
-
-    /**
-     * @param mergedLoadName the mergedLoadName to set
-     */
-    public void setMergedLoadName(String mergedLoadName)
-    {
-        this.mergedLoadName = mergedLoadName;
-    }
     
     
 }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/columnar/ColumnarFactFileMerger.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/columnar/ColumnarFactFileMerger.java
index ff8bd5b..9f14e03 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/columnar/ColumnarFactFileMerger.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/columnar/ColumnarFactFileMerger.java
@@ -9,7 +9,6 @@ import com.huawei.unibi.molap.factreader.FactReaderInfo;
 import com.huawei.unibi.molap.factreader.MolapSurrogateTupleHolder;
 import com.huawei.unibi.molap.merger.columnar.iterator.MolapDataIterator;
 import com.huawei.unibi.molap.merger.columnar.iterator.impl.MolapColumnarLeafTupleDataIterator;
-import com.huawei.unibi.molap.merger.columnar.iterator.impl.MolapLeafTupleWrapperIterator;
 import com.huawei.unibi.molap.merger.exeception.SliceMergerException;
 import com.huawei.unibi.molap.schema.metadata.MolapColumnarFactMergerInfo;
 import com.huawei.unibi.molap.store.MolapFactDataHandlerColumnarMerger;
@@ -80,13 +79,9 @@ public abstract class ColumnarFactFileMerger
         for(MolapSliceAndFiles sliceInfo : molapColumnarFactMergerInfo
                 .getSlicesFromHDFS())
         {
-            /*leaftTupleIterator = new MolapColumnarLeafTupleDataIterator(
+            leaftTupleIterator = new MolapColumnarLeafTupleDataIterator(
                     sliceInfo.getPath(), sliceInfo.getSliceFactFilesList(),
-                    getFactReaderInfo(molapColumnarFactMergerInfo), mdkeyLength);*/
-            
-            leaftTupleIterator = new MolapLeafTupleWrapperIterator(sliceInfo.getKeyGen(), molapColumnarFactMergerInfo.getGlobalKeyGen(), new MolapColumnarLeafTupleDataIterator(
-                    sliceInfo.getPath(), sliceInfo.getSliceFactFilesList(),
-                    getFactReaderInfo(molapColumnarFactMergerInfo), mdkeyLength));
+                    getFactReaderInfo(molapColumnarFactMergerInfo), mdkeyLength);
             if(leaftTupleIterator.hasNext())
             {
                 leaftTupleIterator.fetchNextData();
@@ -138,7 +133,6 @@ public abstract class ColumnarFactFileMerger
             blockIndex[i] = i;
         }
         factReaderInfo.setBlockIndex(blockIndex);
-        factReaderInfo.setUpdateMeasureRequired(true);
 
         return factReaderInfo;
     }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/columnar/iterator/impl/MolapLeafTupleWrapperIterator.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/columnar/iterator/impl/MolapLeafTupleWrapperIterator.java
deleted file mode 100644
index 39fbe52..0000000
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/merger/columnar/iterator/impl/MolapLeafTupleWrapperIterator.java
+++ /dev/null
@@ -1,70 +0,0 @@
-package com.huawei.unibi.molap.merger.columnar.iterator.impl;
-
-import com.huawei.iweb.platform.logging.LogService;
-import com.huawei.iweb.platform.logging.LogServiceFactory;
-import com.huawei.unibi.molap.factreader.MolapSurrogateTupleHolder;
-import com.huawei.unibi.molap.keygenerator.KeyGenException;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.merger.columnar.iterator.MolapDataIterator;
-import com.huawei.unibi.molap.util.MolapCoreLogEvent;
-
-/**
- * This class is a wrapper class over MolapColumnarLeafTupleDataIterator.
- * This uses the global key gen for generating key.
- * @author R00903928
- *
- */
-public class MolapLeafTupleWrapperIterator implements MolapDataIterator<MolapSurrogateTupleHolder>
-{
-    MolapDataIterator<MolapSurrogateTupleHolder> iterator;
-    
-    private KeyGenerator localKeyGen; 
-    
-    private KeyGenerator globalKeyGen;
-    
-    /**
-     * logger
-     */
-    private static final LogService LOGGER = LogServiceFactory
-            .getLogService(MolapLeafTupleWrapperIterator.class.getName());
-    
-    public MolapLeafTupleWrapperIterator(KeyGenerator localKeyGen, KeyGenerator globalKeyGen, MolapDataIterator<MolapSurrogateTupleHolder> iterator)
-    {
-        this.iterator = iterator;
-        this.localKeyGen = localKeyGen;
-        this.globalKeyGen = globalKeyGen;
-    }
-
-    @Override
-    public boolean hasNext()
-    {
-        return iterator.hasNext();
-    }
-
-    @Override
-    public void fetchNextData()
-    {
-        iterator.fetchNextData();
-    }
-
-    @Override
-    public MolapSurrogateTupleHolder getNextData()
-    {
-        MolapSurrogateTupleHolder nextData = iterator.getNextData();
-        byte[] mdKey = nextData.getMdKey();
-        long[] keyArray = localKeyGen.getKeyArray(mdKey);
-        byte[] generateKey = null;
-        try
-        {
-            generateKey = globalKeyGen.generateKey(keyArray);
-        }
-        catch(KeyGenException e)
-        {
-            LOGGER.error(
-                    MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG ,
-                    "Error occurred :: " + e.getMessage());
-        }
-        nextData.setSurrogateKey(generateKey);
-        return nextData;
-    }
-}
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapColumnarFactMergerInfo.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapColumnarFactMergerInfo.java
index 82a12c9..9d00694 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapColumnarFactMergerInfo.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapColumnarFactMergerInfo.java
@@ -2,7 +2,6 @@ package com.huawei.unibi.molap.schema.metadata;
 
 import java.util.List;
 
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.util.MolapSliceAndFiles;
 
 
@@ -36,8 +35,6 @@ public class MolapColumnarFactMergerInfo
     private boolean isMergingRequestForCustomAgg;
 
 	private boolean isUpdateFact;
-	
-	private KeyGenerator globalKeyGen;
     
     /**
      * @return the tableName
@@ -256,20 +253,4 @@ public class MolapColumnarFactMergerInfo
 		return isUpdateFact;
 		
 	}
-
-    /**
-     * @return the globalKeyGen
-     */
-    public KeyGenerator getGlobalKeyGen()
-    {
-        return globalKeyGen;
-    }
-
-    /**
-     * @param globalKeyGen the globalKeyGen to set
-     */
-    public void setGlobalKeyGen(KeyGenerator globalKeyGen)
-    {
-        this.globalKeyGen = globalKeyGen;
-    }
 }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapInfo.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapInfo.java
index b59867e..0066eef 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapInfo.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/schema/metadata/MolapInfo.java
@@ -22,7 +22,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import com.huawei.datasight.molap.datatypes.GenericDataType;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 
 
@@ -156,18 +155,7 @@ public class MolapInfo
     private boolean[] dimsPresent;
     
     private String schemaName;
-    
-    private Map<String,GenericDataType> complexTypesMap;
-    
-	public Map<String, GenericDataType> getComplexTypesMap() {
-		return complexTypesMap;
-	}
-
-	public void setComplexTypesMap(Map<String, GenericDataType> complexTypesMap) {
-		this.complexTypesMap = complexTypesMap;
-	}
-
-	/**
+    /**
      * 
      * @return Returns the dims.
      * 
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileReader.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileReader.java
index fd27f52..3adf628 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileReader.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileReader.java
@@ -26,11 +26,6 @@ public abstract class AbstractTempSortFileReader implements TempSortFileReader
      * Measure count 
      */
     protected int dimensionCount;
-    
-    /**
-     * complexDimension count 
-     */
-    protected int complexDimensionCount;
 
     /**
      * entryCount
@@ -61,16 +56,15 @@ public abstract class AbstractTempSortFileReader implements TempSortFileReader
      * @param dimensionCount
      * @param tempFile
      */
-    public AbstractTempSortFileReader(int dimensionCount, int complexDimensionCount, int measureCount, File tempFile,int highCardinalityCount)
+    public AbstractTempSortFileReader(int dimensionCount, int measureCount, File tempFile,int highCardinalityCount)
     {
         this.measureCount = measureCount;
         this.dimensionCount = dimensionCount;
         this.highCardinalityCount = highCardinalityCount;
-		this.complexDimensionCount = complexDimensionCount;
         this.fileHolder = new FileHolderImpl(1);
         this.filePath = tempFile.getAbsolutePath();
         entryCount = fileHolder.readInt(filePath);
-        eachRecordSize = dimensionCount + complexDimensionCount + measureCount;
+        eachRecordSize = dimensionCount + measureCount;
     }
     
     /**
@@ -117,13 +111,6 @@ public abstract class AbstractTempSortFileReader implements TempSortFileReader
 	        {
 	        	record[index++] = buffer.getInt();
 	        }
-
-	        for(int j = 0; j < complexDimensionCount; j++)
-	        {
-	        	byte[] complexByteArray = new byte[buffer.getInt()];
-	        	buffer.get(complexByteArray);
-	        	record[index++] = complexByteArray;
-	        }
 	        
 	        for(int j = 0; j < measureCount; j++)
 	        {
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileWriter.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileWriter.java
index 6d214cb..171b348 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileWriter.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/AbstractTempSortFileWriter.java
@@ -36,11 +36,6 @@ public abstract class AbstractTempSortFileWriter implements TempSortFileWriter
      * Measure count 
      */
     protected int dimensionCount;
-    
-    /**
-     * complexDimension count 
-     */
-    protected int complexDimensionCount;
 
     /**
      * stream
@@ -58,12 +53,11 @@ public abstract class AbstractTempSortFileWriter implements TempSortFileWriter
      * @param dimensionCount
      * @param measureCount
      */
-    public AbstractTempSortFileWriter(int dimensionCount, int complexDimensionCount,
+    public AbstractTempSortFileWriter(int dimensionCount, 
     		int measureCount,int highCardinalityCount, int writeBufferSize)
     {
         this.writeBufferSize = writeBufferSize;
         this.dimensionCount = dimensionCount;
-        this.complexDimensionCount = complexDimensionCount;
         this.measureCount = measureCount;
         this.highCardinalityCount = highCardinalityCount;
     }
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileReader.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileReader.java
index c650332..c9c253a 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileReader.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileReader.java
@@ -24,10 +24,10 @@ public class CompressedTempSortFileReader extends AbstractTempSortFileReader
      * @param tempFile
      * @param type
      */
-    public CompressedTempSortFileReader(int dimensionCount, int complexDimensionCount, int measureCount,
+    public CompressedTempSortFileReader(int dimensionCount, int measureCount,
     		File tempFile,int highCardinalityCount)
     {
-        super(dimensionCount, complexDimensionCount, measureCount, tempFile, highCardinalityCount);
+        super(dimensionCount, measureCount, tempFile, highCardinalityCount);
     }
 
     /**
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileWriter.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileWriter.java
index 0fa2794..0d1b89b 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileWriter.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/CompressedTempSortFileWriter.java
@@ -27,10 +27,10 @@ public class CompressedTempSortFileWriter extends AbstractTempSortFileWriter
      * @param dimensionCount
      * @param measureCount
      */
-    public CompressedTempSortFileWriter(int dimensionCount, int complexDimensionCount,
+    public CompressedTempSortFileWriter(int dimensionCount, 
     		int measureCount,int highCardinalityCount, int writeBufferSize)
     {
-        super(dimensionCount, complexDimensionCount, measureCount,highCardinalityCount, writeBufferSize);
+        super(dimensionCount, measureCount,highCardinalityCount, writeBufferSize);
     }
 
     /**
@@ -53,7 +53,7 @@ public class CompressedTempSortFileWriter extends AbstractTempSortFileWriter
             blockDataArray = new ByteArrayOutputStream(totalSize);
             dataOutputStream = new DataOutputStream(blockDataArray);
             
-            UnCompressedTempSortFileWriter.writeDataOutputStream(records, dataOutputStream, measureCount, dimensionCount, highCardinalityCount, complexDimensionCount);
+            UnCompressedTempSortFileWriter.writeDataOutputStream(records, dataOutputStream, measureCount, dimensionCount, highCardinalityCount);
             
             /*for(int recordIndex = 0; recordIndex < records.length; recordIndex++)
             {
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/FileMergerParameters.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/FileMergerParameters.java
index 78a9f88..8aee9c0 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/FileMergerParameters.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/FileMergerParameters.java
@@ -28,11 +28,6 @@ public class FileMergerParameters
      * measure count
      */
     private int dimColCount;
-  
-    /**
-     * complexDimColCount
-     */
-    private int complexDimColCount;
     
     /**
      * measure count
@@ -115,16 +110,6 @@ public class FileMergerParameters
 		this.dimColCount = dimColCount;
 	}
 
-	public int getComplexDimColCount()
-	{
-		return complexDimColCount;
-	}
-
-	public void setComplexDimColCount(int complexDimColCount)
-	{
-		this.complexDimColCount = complexDimColCount;
-	}
-
 	public File getOutFile()
 	{
 		return outFile;
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/IntermediateFileMerger.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/IntermediateFileMerger.java
index 7f2258c..ad89587 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/IntermediateFileMerger.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/IntermediateFileMerger.java
@@ -215,7 +215,7 @@ public class IntermediateFileMerger implements Callable<Void>
         else
         {
         	 writer = TempSortFileWriterFactory.getInstance().getTempSortFileWriter(mergerParameters.isCompressionEnabled(), 
-        			 mergerParameters.getDimColCount(), mergerParameters.getComplexDimColCount(), mergerParameters.getMeasureColCount(), mergerParameters.getHighCardinalityCount(),mergerParameters.getFileWriteBufferSize());
+        			 mergerParameters.getDimColCount(), mergerParameters.getMeasureColCount(), mergerParameters.getHighCardinalityCount(),mergerParameters.getFileWriteBufferSize());
         	 writer.initiaize(mergerParameters.getOutFile(), totalNumberOfRecords);
         	 
         	 if(mergerParameters.isPrefetch())
@@ -301,9 +301,7 @@ public class IntermediateFileMerger implements Callable<Void>
         {
             // create chunk holder
         	sortTempFileChunkHolder = new SortTempFileChunkHolder(
-                    tempFile, mergerParameters.getDimColCount(), 
-                    mergerParameters.getComplexDimColCount(),
-                    mergerParameters.getMeasureColCount(), 
+                    tempFile, mergerParameters.getDimColCount(), mergerParameters.getMeasureColCount(), 
                     mergerParameters.getFileReadBufferSize(),mergerParameters.getHighCardinalityCount());
             
         	// initialize
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortDataRows.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortDataRows.java
index 79fc7f2..cec6ac5 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortDataRows.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortDataRows.java
@@ -79,11 +79,6 @@ public class SortDataRows
     private int dimColCount;
 
     /**
-     * measure count
-     */
-    private int complexDimColCount;
-
-    /**
      * fileBufferSize
      */
     private int fileBufferSize;
@@ -192,7 +187,7 @@ public class SortDataRows
 	private int highCardinalityCount;
     
     
-	public SortDataRows(String tabelName, int dimColCount, int complexDimColCount, int measureColCount,
+	public SortDataRows(String tabelName, int dimColCount, int measureColCount,
 			SortObserver observer, int currentRestructNum,int highCardinalityCount)
 	{
 		// set table name
@@ -204,7 +199,6 @@ public class SortDataRows
         this.dimColCount = dimColCount;
         
         this.highCardinalityCount = highCardinalityCount;
-		this.complexDimColCount = complexDimColCount;
         
         // processed file list
         this.procFiles = new ArrayList<File>(MolapCommonConstants.CONSTANT_SIZE_TEN);
@@ -547,13 +541,6 @@ public class SortDataRows
                     stream.writeInt(RemoveDictionaryUtil.getDimension(fieldIndex++, row));
 //                	stream.writeInt((Integer)row[fieldIndex++]);
                 }
-
-                for(int dimCount = 0; dimCount < this.complexDimColCount; dimCount++)
-                {
-                	int complexByteArrayLength = ((byte[])row[fieldIndex]).length;
-                	stream.writeInt(complexByteArrayLength);
-                	stream.write(((byte[])row[fieldIndex++]));
-                }
                 
                 // if any high cardinality dims are present then write it to the file.
                 if(this.highCardinalityCount > 0)
@@ -622,7 +609,7 @@ public class SortDataRows
     {
     	TempSortFileWriter chunkWriter = null;
     	TempSortFileWriter writer = TempSortFileWriterFactory.getInstance().getTempSortFileWriter(
-        		isSortFileCompressionEnabled, dimColCount, complexDimColCount, measureColCount,highCardinalityCount, fileWriteBufferSize);
+        		isSortFileCompressionEnabled, dimColCount, measureColCount,highCardinalityCount, fileWriteBufferSize);
         
         if(prefetch && !isSortFileCompressionEnabled)
         {
@@ -648,7 +635,6 @@ public class SortDataRows
         FileMergerParameters parameters = new FileMergerParameters();
         
         parameters.setDimColCount(dimColCount);
-        parameters.setComplexDimColCount(complexDimColCount);
         parameters.setMeasureColCount(measureColCount);
         parameters.setIntermediateFiles(intermediateFiles);
         parameters.setFileReadBufferSize(fileBufferSize);
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortTempFileChunkHolder.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortTempFileChunkHolder.java
index 78553ab..ea17185 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortTempFileChunkHolder.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/SortTempFileChunkHolder.java
@@ -88,16 +88,11 @@ public class SortTempFileChunkHolder
     private int measureCount;
     
     /**
-     * number of dimensionCount
+     * number of measures
      */
     private int dimensionCount;
 
     /**
-     * number of complexDimensionCount
-     */
-    private int complexDimensionCount;
-
-    /**
      * fileBufferSize for file reader stream size
      */
     private int fileBufferSize;
@@ -158,7 +153,7 @@ public class SortTempFileChunkHolder
      *            mdkey length
      * 
      */
-    public SortTempFileChunkHolder(File tempFile, int dimensionCount, int complexDimensionCount,  int measureCount, 
+    public SortTempFileChunkHolder(File tempFile, int dimensionCount, int measureCount, 
             int fileBufferSize, int highCardinalityCount)
     {
         // set temp file
@@ -167,13 +162,11 @@ public class SortTempFileChunkHolder
         // set measure and dimension count
         this.measureCount = measureCount;
         this.dimensionCount = dimensionCount;
-        this.complexDimensionCount = complexDimensionCount;
-        
         this.highCardinalityCount = highCardinalityCount;
         // set mdkey length
         this.fileBufferSize = fileBufferSize;
         this.executorService = Executors.newFixedThreadPool(1);
-        this.outRecSize = this.measureCount + dimensionCount + this.highCardinalityCount + complexDimensionCount;
+        this.outRecSize = this.measureCount + dimensionCount + this.highCardinalityCount;
     }
 
     /**
@@ -238,7 +231,7 @@ public class SortTempFileChunkHolder
         try
         {
         	reader = TempSortFileReaderFactory.getInstance().getTempSortFileReader(
-        			isSortTempFileCompressionEnabled, dimensionCount, complexDimensionCount, measureCount, tempFile,highCardinalityCount);
+        			isSortTempFileCompressionEnabled, dimensionCount, measureCount, tempFile,highCardinalityCount);
         	
         	if(isSortTempFileCompressionEnabled)
     		{
@@ -396,13 +389,6 @@ public class SortTempFileChunkHolder
         		dim[index++] = stream.readInt();
             }
         	
-        	//Complex Type ByteArray to be read and kept for columnar
-        	for(int i = 0; i < this.complexDimensionCount; i++)
-        	{
-        		byte[] complexArray = new byte[stream.readInt()];
-        		stream.read(complexArray);
-        		holder[index++] = complexArray;
-        	}
         	if(this.highCardinalityCount > 0)
         	{
         	    short lengthOfByteArray = stream.readShort();
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileReaderFactory.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileReaderFactory.java
index 9ae94ff..cd73886 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileReaderFactory.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileReaderFactory.java
@@ -26,16 +26,16 @@ public final class TempSortFileReaderFactory
 	}
 	
 	public TempSortFileReader getTempSortFileReader(boolean isCompressionEnabled, int dimensionCount,
-			int complexDimensionCount, int measureCount, File tempFile,int highCardinalityCount)
+			int measureCount, File tempFile,int highCardinalityCount)
 	{
 		if(isCompressionEnabled)
 		{
-			return new CompressedTempSortFileReader(dimensionCount, complexDimensionCount,
+			return new CompressedTempSortFileReader(dimensionCount,
 					measureCount, tempFile,highCardinalityCount);
 		}
 		else
 		{
-			return new UnCompressedTempSortFileReader(dimensionCount, complexDimensionCount,
+			return new UnCompressedTempSortFileReader(dimensionCount,
 					measureCount, tempFile,highCardinalityCount);
 		}
 	}
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileWriterFactory.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileWriterFactory.java
index e6f678f..3f11ff1 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileWriterFactory.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/TempSortFileWriterFactory.java
@@ -25,16 +25,16 @@ public final class TempSortFileWriterFactory
 	}
 	
 	public TempSortFileWriter getTempSortFileWriter(boolean isCompressionEnabled, int dimensionCount, 
-    		int complexDimensionCount, int measureCount,int highCardinalityCount, int writeBufferSize)
+    		int measureCount,int highCardinalityCount, int writeBufferSize)
 	{
 		if(isCompressionEnabled)
 		{
-			return new CompressedTempSortFileWriter(dimensionCount, complexDimensionCount,
+			return new CompressedTempSortFileWriter(dimensionCount,
 					measureCount,highCardinalityCount, writeBufferSize);
 		}
 		else
 		{
-			return new UnCompressedTempSortFileWriter(dimensionCount, complexDimensionCount,
+			return new UnCompressedTempSortFileWriter(dimensionCount,
 					measureCount,highCardinalityCount, writeBufferSize);
 		}
 	}
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileReader.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileReader.java
index 4804411..bae7e92 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileReader.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileReader.java
@@ -23,10 +23,10 @@ public class UnCompressedTempSortFileReader extends AbstractTempSortFileReader
      * @param tempFile
      * @param type
      */
-    public UnCompressedTempSortFileReader(int dimensionCount, int complexDimensionCount, int measureCount,
+    public UnCompressedTempSortFileReader(int dimensionCount, int measureCount,
     		File tempFile, int highCardinalityCount)
     {
-        super(dimensionCount, complexDimensionCount, measureCount, tempFile,highCardinalityCount);
+        super(dimensionCount, measureCount, tempFile,highCardinalityCount);
     }
 
     /**
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileWriter.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileWriter.java
index 1a80b00..aa36d14 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileWriter.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortData/UnCompressedTempSortFileWriter.java
@@ -27,10 +27,10 @@ public class UnCompressedTempSortFileWriter extends AbstractTempSortFileWriter
      * @param dimensionCount
      * @param measureCount
      */
-    public UnCompressedTempSortFileWriter(int dimensionCount, int complexDimensionCount, 
+    public UnCompressedTempSortFileWriter(int dimensionCount, 
     		int measureCount,int highCardinalityCount, int writeBufferSize)
     {
-        super(dimensionCount, complexDimensionCount, measureCount,highCardinalityCount, writeBufferSize);
+        super(dimensionCount, measureCount,highCardinalityCount, writeBufferSize);
     }
 
     /**
@@ -53,7 +53,7 @@ public class UnCompressedTempSortFileWriter extends AbstractTempSortFileWriter
             blockDataArray = new ByteArrayOutputStream(totalSize);
             dataOutputStream = new DataOutputStream(blockDataArray);
             
-            writeDataOutputStream(records, dataOutputStream,measureCount,dimensionCount,highCardinalityCount,complexDimensionCount);
+            writeDataOutputStream(records, dataOutputStream,measureCount,dimensionCount,highCardinalityCount);
             stream.writeInt(records.length);
             byte[] byteArray = blockDataArray.toByteArray();
             stream.writeInt(byteArray.length);
@@ -79,7 +79,7 @@ public class UnCompressedTempSortFileWriter extends AbstractTempSortFileWriter
 	 * @throws IOException
 	 */
 	public static void writeDataOutputStream(Object[][] records,
-			DataOutputStream dataOutputStream, int measureCount, int dimensionCount,int highCardinalityCount, int complexDimensionCount) throws IOException
+			DataOutputStream dataOutputStream, int measureCount, int dimensionCount,int highCardinalityCount) throws IOException
 	{
 		Object[] row;
 		for(int recordIndex = 0; recordIndex < records.length; recordIndex++)
@@ -98,13 +98,6 @@ public class UnCompressedTempSortFileWriter extends AbstractTempSortFileWriter
 		        dataOutputStream.write(RemoveDictionaryUtil.getByteArrayForNoDictionaryCols(row));
 		    }
 		    fieldIndex = 0;
-		    for(int counter = 0; counter < complexDimensionCount; counter++)
-            {
-            	int complexByteArrayLength = ((byte[])row[fieldIndex]).length;
-            	dataOutputStream.writeInt(complexByteArrayLength);
-            	dataOutputStream.write(((byte[])row[fieldIndex++]));
-            }
-		    
 		    for(int counter = 0; counter < measureCount; counter++)
 		    {
 		    	if(null != row[fieldIndex])
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStep.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStep.java
index 908834a..953f064 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStep.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStep.java
@@ -180,8 +180,7 @@ public class SortKeyStep extends BaseStep
             this.meta.setHighCardinalityCount(RemoveDictionaryUtil.extractHighCardCount(meta.getHighCardinalityDims()));
             
             this.sortDataRows = new SortDataRows(meta.getTabelName(),
-					meta.getDimensionCount() - meta.getComplexDimensionCount(), 
-					meta.getComplexDimensionCount(), meta.getMeasureCount(), this.observer, meta.getCurrentRestructNumber(),meta.getHighCardinalityCount());
+					meta.getDimensionCount(), meta.getMeasureCount(), this.observer, meta.getCurrentRestructNumber(),meta.getHighCardinalityCount());
 			try 
 			{
 				// initialize sort
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStepMeta.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStepMeta.java
index 04eb740..4f6dc3c 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStepMeta.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/sortandgroupby/sortDataStep/SortKeyStepMeta.java
@@ -82,11 +82,6 @@ public class SortKeyStepMeta extends BaseStepMeta implements StepMetaInterface
      * Dimension Count
      */
     private String dimensionCount;
-
-    /**
-     * ComplexTypes Count
-     */
-    private String complexDimensionCount;
     
     /**
      * Dimension Count
@@ -123,7 +118,6 @@ public class SortKeyStepMeta extends BaseStepMeta implements StepMetaInterface
         highCardinalityDims="";
         cubeName = "";
         dimensionCount = "";
-        complexDimensionCount = "";
         measureCount = "";
         updateMemberRequest = "";
         currentRestructNumber = -1;
@@ -147,7 +141,6 @@ public class SortKeyStepMeta extends BaseStepMeta implements StepMetaInterface
         retval.append("    ").append(XMLHandler.addTagValue("schemaName", this.schemaName));
         retval.append("    ").append(XMLHandler.addTagValue("dimensionCount", this.dimensionCount));
         retval.append("    ").append(XMLHandler.addTagValue("highCardinalityDims", this.highCardinalityDims));
-        retval.append("    ").append(XMLHandler.addTagValue("complexDimensionCount", this.complexDimensionCount));
         retval.append("    ").append(XMLHandler.addTagValue("measureCount", this.measureCount));
         retval.append("    ").append(XMLHandler.addTagValue("isUpdateMemberRequest", this.updateMemberRequest));
         retval.append("    ").append(XMLHandler.addTagValue("currentRestructNumber", currentRestructNumber));
@@ -178,7 +171,6 @@ public class SortKeyStepMeta extends BaseStepMeta implements StepMetaInterface
             this.schemaName = XMLHandler.getTagValue(stepnode, "schemaName");
             this.dimensionCount = XMLHandler.getTagValue(stepnode, "dimensionCount");
             this.highCardinalityDims=XMLHandler.getTagValue(stepnode, "highCardinalityDims");
-            this.complexDimensionCount = XMLHandler.getTagValue(stepnode, "complexDimensionCount");
             this.measureCount = XMLHandler.getTagValue(stepnode, "measureCount");
             this.updateMemberRequest = XMLHandler.getTagValue(stepnode, "isUpdateMemberRequest");
             currentRestructNumber = Integer.parseInt(XMLHandler.getTagValue(stepnode, "currentRestructNumber"));
@@ -214,7 +206,6 @@ public class SortKeyStepMeta extends BaseStepMeta implements StepMetaInterface
             rep.saveStepAttribute(idTransformation, idStep, "schemaName", this.schemaName); 
             rep.saveStepAttribute(idTransformation, idStep, "dimensionCount", this.dimensionCount);
             rep.saveStepAttribute(idTransformation, idStep, "highCardinalityDims", this.highCardinalityDims);
-            rep.saveStepAttribute(idTransformation, idStep, "complexDimensionCount", this.complexDimensionCount);
             rep.saveStepAttribute(idTransformation, idStep, "measureCount", this.measureCount); 
             rep.saveStepAttribute(idTransformation, idStep, "isUpdateMemberRequest", this.updateMemberRequest); 
             rep.saveStepAttribute(idTransformation, idStep, "currentRestructNumber", currentRestructNumber);
@@ -251,7 +242,6 @@ public class SortKeyStepMeta extends BaseStepMeta implements StepMetaInterface
             this.cubeName = rep.getStepAttributeString(idStep, "cubeName");
             this.dimensionCount = rep.getStepAttributeString(idStep, "dimensionCount");
             this.highCardinalityDims=rep.getStepAttributeString(idStep, "highCardinalityDims");
-            this.complexDimensionCount = rep.getStepAttributeString(idStep, "complexDimensionCount");
             this.measureCount = rep.getStepAttributeString(idStep, "measureCount");
             this.updateMemberRequest = rep.getStepAttributeString(idStep, "isUpdateMemberRequest");
             this.currentRestructNumber = (int)rep.getStepAttributeInteger(idStep, "currentRestructNumber");
@@ -408,33 +398,19 @@ public class SortKeyStepMeta extends BaseStepMeta implements StepMetaInterface
         return schemaName;
     }
 
-	/**
-	 * @return the dimensionCount
-	 */
-	public int getDimensionCount()
+    /**
+     * @return the dimensionCount
+     */
+    public int getDimensionCount()
 	{
 		return Integer.parseInt(dimensionCount);
 	}
-	
+
 	public void setDimensionCount(String dimensionCount)
 	{
 		this.dimensionCount = dimensionCount;
 	}
 
-	
-	/**
-	 * @return the complexDimensionCount
-	 */
-	public int getComplexDimensionCount()
-	{
-		return Integer.parseInt(complexDimensionCount);
-	}
-	
-	public void setComplexDimensionCount(String complexDimensionCount)
-	{
-		this.complexDimensionCount = complexDimensionCount;
-	}
-
 	/**
      * @return the measureCount
      */
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnar.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnar.java
index a6a70f5..bd7d24e 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnar.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnar.java
@@ -16,14 +16,12 @@ import java.nio.ByteBuffer;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
-import java.util.Map;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
-import com.huawei.datasight.molap.datatypes.GenericDataType;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
@@ -44,6 +42,7 @@ import com.huawei.unibi.molap.keygenerator.KeyGenException;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.keygenerator.columnar.ColumnarSplitter;
 import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthEquiSplitGenerator;
+import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthVariableSplitGenerator;
 import com.huawei.unibi.molap.keygenerator.factory.KeyGeneratorFactory;
 import com.huawei.unibi.molap.store.writer.MolapFactDataWriter;
 import com.huawei.unibi.molap.store.writer.MolapFactDataWriterImpl;
@@ -57,6 +56,7 @@ import com.huawei.unibi.molap.util.MolapProperties;
 import com.huawei.unibi.molap.util.MolapUtil;
 import com.huawei.unibi.molap.util.RemoveDictionaryUtil;
 import com.huawei.unibi.molap.util.ValueCompressionUtil;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 
 /**
@@ -111,20 +111,13 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
      * data store which will hold the measure data
      */
     private NodeMeasureDataStore dataStore;
-    
-    private Map<Integer,GenericDataType> complexIndexMap;
-
-	/**
-     * measure count
-     */
-    private int measureCount;
 
     /**
      * measure count
      */
-    private int dimensionCount;
+    private int measureCount;
     
-	/**
+    /**
      * uniqueValue
      */
     private double[] uniqueValue;
@@ -280,6 +273,8 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
 
     private int highCardCount;
     
+    private HybridStoreModel hybridStoreModel;
+    
 //    private String[] aggregator;
  
     //TODO SIMIAN
@@ -302,63 +297,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             int mdkeyLength, int mdKeyIndex, String[] aggregators,
             String[] aggregatorClass, String storeLocation, int[] factDimLens,
             boolean isMergingRequestForCustomAgg, boolean isUpdateMemberRequest,  int[] dimLens, String[] factLevels,
-            String[] aggLevels, boolean isDataWritingRequest, int currentRestructNum, int highCardCount, 
-            int dimensionCount, Map<Integer,GenericDataType> complexIndexMap)
-    {
-    	this(schemaName, cubeName, tableName, isGroupByEnabled, measureCount, 
-    			mdkeyLength, mdKeyIndex, aggregators, aggregatorClass, storeLocation, 
-    			factDimLens, isMergingRequestForCustomAgg, isUpdateMemberRequest, 
-    			dimLens, factLevels, aggLevels, isDataWritingRequest, currentRestructNum, highCardCount);
-    	this.dimensionCount = dimensionCount;
-    	this.complexIndexMap = complexIndexMap;
-    	
-    	this.aggKeyBlock = new boolean[dimLens.length];
-        this.isAggKeyBlock = Boolean
-        		.parseBoolean(MolapProperties.getInstance().getProperty(
-                MolapCommonConstants.AGGREAGATE_COLUMNAR_KEY_BLOCK,
-                MolapCommonConstants.AGGREAGATE_COLUMNAR_KEY_BLOCK_DEFAULTVALUE));
-        if(isAggKeyBlock)
-        {
-            int highCardinalityValue = Integer.parseInt(MolapProperties.getInstance().getProperty(
-                MolapCommonConstants.HIGH_CARDINALITY_VALUE,
-                MolapCommonConstants.HIGH_CARDINALITY_VALUE_DEFAULTVALUE));
-            for(int i = 0;i < dimLens.length;i++)
-            {
-                if(dimLens[i]<highCardinalityValue)
-                {
-                    this.aggKeyBlock[i]=true;
-                }
-            }
-            if(dimensionCount < dimLens.length)
-            {
-            	int allColsCount = getColsCount();
-            	List<Boolean> aggKeyBlockWithComplex = new ArrayList<Boolean>(allColsCount);
-                for(int i = 0;i < dimensionCount;i++)
-                {
-                	GenericDataType complexDataType = complexIndexMap.get(i);
-            		if(complexDataType != null)
-            		{
-            			complexDataType.fillAggKeyBlock(aggKeyBlockWithComplex, this.aggKeyBlock);
-            		}
-            		else
-            		{
-            			aggKeyBlockWithComplex.add(this.aggKeyBlock[i]);
-            		}
-                }
-                this.aggKeyBlock = new boolean[allColsCount];
-                for(int i=0;i<allColsCount;i++)
-                {
-                	this.aggKeyBlock[i] = aggKeyBlockWithComplex.get(i);
-                }
-            }
-        }
-    }
-    public MolapFactDataHandlerColumnar(String schemaName, String cubeName,
-            String tableName, boolean isGroupByEnabled, int measureCount,
-            int mdkeyLength, int mdKeyIndex, String[] aggregators,
-            String[] aggregatorClass, String storeLocation, int[] factDimLens,
-            boolean isMergingRequestForCustomAgg, boolean isUpdateMemberRequest,  int[] dimLens, String[] factLevels,
-            String[] aggLevels, boolean isDataWritingRequest, int currentRestructNum, int highCardCount)
+            String[] aggLevels, boolean isDataWritingRequest, int currentRestructNum, int highCardCount,HybridStoreModel hybridStoreModel)
     {
         this.schemaName = schemaName;
         this.cubeName = cubeName;
@@ -373,18 +312,36 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
         this.factDimLens=factDimLens;
         this.highCardCount = highCardCount;
         this.isMergingRequestForCustomAgg=isMergingRequestForCustomAgg;
+        this.hybridStoreModel=hybridStoreModel;
 //        this.isUpdateMemberRequest=isUpdateMemberRequest;
-        this.dimLens=dimLens;
+        this.dimLens=hybridStoreModel.getHybridCardinality();
         
-        boolean [] noDict = new boolean[dimLens.length+this.highCardCount];
-        // setting true value for dims of high card
-        for(int i = dimLens.length;i < noDict.length ; i++)
+      
+        //row store dimensions will be stored first and than other columnar store dimension will be stored in fact file
+        int aggIndex=0;
+        int noDictStartIndex=0;
+        if(this.hybridStoreModel.isHybridStore())
         {
-            noDict[i] = true;
+        	this.aggKeyBlock=new boolean[this.hybridStoreModel.getColumnStoreOrdinals().length+highCardCount+1];
+           //hybrid store related changes, row store dimension will not get sorted and hence run length encoding alls will not be applied
+            //thus setting aggKeyBlock for row store index as false
+        	this.aggKeyBlock[aggIndex++]=false;
+        	this.isNoDictionary=new boolean[this.hybridStoreModel.getColumnStoreOrdinals().length+highCardCount+1];
+        	noDictStartIndex=this.hybridStoreModel.getColumnStoreOrdinals().length+1;
+        }
+        else
+        {
+        	//if not hybrid store than as usual
+        	this.aggKeyBlock=new boolean[this.hybridStoreModel.getColumnStoreOrdinals().length+highCardCount];	
+        	this.isNoDictionary=new boolean[this.hybridStoreModel.getColumnStoreOrdinals().length+highCardCount+1];
+        	noDictStartIndex=this.hybridStoreModel.getColumnStoreOrdinals().length;
+        }
+       // setting true value for dims of high card
+      
+        for(int i = noDictStartIndex;i < isNoDictionary.length ; i++)
+        {
+        	this.isNoDictionary[i] = true;
         }
-        
-        this.isNoDictionary = noDict;
-        
         this.aggKeyBlock= new boolean[dimLens.length+highCardCount];
         this.currentRestructNumber = currentRestructNum;
         isIntBasedIndexer = Boolean
@@ -397,12 +354,15 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             int highCardinalityValue = Integer.parseInt(MolapProperties.getInstance().getProperty(
                 MolapCommonConstants.HIGH_CARDINALITY_VALUE,
                 MolapCommonConstants.HIGH_CARDINALITY_VALUE_DEFAULTVALUE));
-            for(int i = 0;i < dimLens.length;i++)
+            //since row store index is already set to false, below aggKeyBlock is initialised for remanining dimension
+            for(int i=this.hybridStoreModel.getRowStoreOrdinals().length;i<dimLens.length;i++)
             {
-                if(dimLens[i]<highCardinalityValue)
+            	if(dimLens[i]<highCardinalityValue)
                 {
-                    this.aggKeyBlock[i]=true;
+                    this.aggKeyBlock[aggIndex++]=true;
+                    continue;
                 }
+            	aggIndex++;
             }
         }
         
@@ -511,7 +471,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
     {
         byte[] mdkey = (byte[])row[this.mdKeyIndex];
         byte[] highCardKey = null;
-        if(highCardCount > 0 || complexIndexMap.size() > 0)
+        if(highCardCount > 0)
         {
              highCardKey = (byte[])row[this.mdKeyIndex - 1];
         }
@@ -533,9 +493,6 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
         {
             highCardkeyDataHolder.setWritableByteArrayValueByIndex(entryCount, highCardKey);
         }
-        //Add all columns to keyDataHolder
-        keyDataHolder.setWritableByteArrayValueByIndex(entryCount, this.mdKeyIndex, row);
-        
      // CHECKSTYLE:OFF Approval No:Approval-351
         for(int k = 0;k < otherMeasureIndex.length;k++) 
         {
@@ -577,7 +534,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
 //                data[i]=keyBlockHolder[i].getKeyBlock().clone();
 //            }
             byte[][] byteArrayValues = keyDataHolder.getByteArrayValues().clone();
-            byte[][][] columnByteArrayValues = keyDataHolder.getColumnByteArrayValues().clone();
+            
             //TODO need to handle high card also here
             
             byte[][] writableMeasureDataArray = this.dataStore.getWritableMeasureDataArray(dataHolder).clone();
@@ -586,8 +543,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             byte[] endKeyLocal=endKey;
             startKey= new byte[mdkeyLength];
             endKey= new byte[mdkeyLength];
-//            writerExecutorService.submit(new DataWriterThread(byteArrayValues,writableMeasureDataArray,entryCountLocal,startKeyLocal,endKeyLocal));
-            writerExecutorService.submit(new DataWriterThread(byteArrayValues,writableMeasureDataArray,columnByteArrayValues,entryCountLocal,startKeyLocal,endKeyLocal));
+            writerExecutorService.submit(new DataWriterThread(byteArrayValues,writableMeasureDataArray,entryCountLocal,startKeyLocal,endKeyLocal));
 //            writeDataToFile(data,writableMeasureDataArray,entryCount,startKey,endKey);
             // set the entry count to zero
             processedDataCount+=entryCount;
@@ -599,169 +555,63 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
         }
     }
 
-//    private void writeDataToFile(byte[][] data,
-//            byte[][] dataHolderLocal, int entryCountLocal,
-//            byte[] startkeyLocal, byte[] endKeyLocal)
-//            throws MolapDataWriterException
-//    {
-//        ExecutorService executorService= Executors.newFixedThreadPool(5);
-//        List<Future<IndexStorage>> submit = new ArrayList<Future<IndexStorage>>(numberOfColumns);
-//        byte[][][] columnsData = new byte[numberOfColumns][data.length][];
-//        for(int i = 0;i < data.length;i++)
-//        {
-//            byte[][] splitKey = columnarSplitter.splitKey(data[i]);
-//            for(int j = 0;j < splitKey.length;j++)
-//            {
-//                columnsData[j][i]=splitKey[j];
-//            }
-//        }
-//        for(int i = 0;i < numberOfColumns;i++)
-//        {
-//            submit.add(executorService.submit(new BlockSortThread(i,columnsData[i])));
-//        }
-//        executorService.shutdown();
-//        try
-//        {
-//            executorService.awaitTermination(1, TimeUnit.DAYS);
-//        }
-//        catch(InterruptedException ex) 
-//        { 
-//            // TODO Auto-generated catch block
-//         //   e.printStackTrace();
-//            LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, ex, ex.getMessage());
-//        }
-//        IndexStorage[] blockStorage = new IndexStorage[numberOfColumns];
-//        try
-//        {
-//            for(int i = 0;i < blockStorage.length;i++)
-//            {
-//                blockStorage[i]=submit.get(i).get();
-//            }
-//        }
-//        catch(Exception exception) 
-//        {
-//            // TODO Auto-generated catch block
-////            e.printStackTrace();
-//        	 LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, exception, exception.getMessage());
-//        }
-//        synchronized(lock)
-//        {
-//            this.dataWriter.writeDataToFile(
-//                    blockStorage,
-//                    dataHolderLocal,
-//                    entryCountLocal, startkeyLocal, endKeyLocal);
-//        }
-//    }
-    
     private void writeDataToFile(byte[][] data,
-    		byte[][] dataHolderLocal, byte[][][] columnData, int entryCountLocal,
-    		byte[] startkeyLocal, byte[] endKeyLocal)
-    				throws MolapDataWriterException
-    				{
-//    	for(int i = 0;i < data.length;i++)
-//    	{
-//    		byte[][] splitKey = columnarSplitter.splitKey(data[i]);
-//    		for(int j = 0;j < splitKey.length;j++)
-//    		{
-//    			columnsData[j][i]=splitKey[j];
-//    		}
-//    	}
-    	int allColsCount = getColsCount();
-    	List<ArrayList<byte[]>> colsAndValues = new ArrayList<ArrayList<byte[]>>();
-        for(int i=0;i<allColsCount;i++)
+            byte[][] dataHolderLocal, int entryCountLocal,
+            byte[] startkeyLocal, byte[] endKeyLocal)
+            throws MolapDataWriterException
+    {
+        ExecutorService executorService= Executors.newFixedThreadPool(5);
+        List<Future<IndexStorage>> submit = new ArrayList<Future<IndexStorage>>(numberOfColumns);
+        byte[][][] columnsData = new byte[numberOfColumns][data.length][];
+        for(int i = 0;i < data.length;i++)
         {
-        	colsAndValues.add(new ArrayList<byte[]>());
+            byte[][] splitKey = columnarSplitter.splitKey(data[i]);
+            for(int j = 0;j < splitKey.length;j++)
+            {
+                columnsData[j][i]=splitKey[j];
+            }
         }
-        
-        for(int i =0;i<columnData.length;i++)
+        for(int i = 0;i < numberOfColumns;i++)
         {
-        	int l=0;
-        	for(int j=0;j<dimensionCount;j++)
-        	{
-        		GenericDataType complexDataType = complexIndexMap.get(j);
-        		if(complexDataType != null)
-        		{
-        			List<ArrayList<byte[]>> columnsArray = new ArrayList<ArrayList<byte[]>>();
-        			for(int k=0;k<complexDataType.getColsCount();k++)
-        			{
-        				columnsArray.add(new ArrayList<byte[]>());
-        			}
-        			complexDataType.getColumnarDataForComplexType(columnsArray, ByteBuffer.wrap(columnData[i][j]));
-        			for(ArrayList<byte[]> eachColumn : columnsArray)
-        			{
-        				colsAndValues.get(l++).addAll(eachColumn);
-        			}
-        		}
-        		else
-        		{
-        			colsAndValues.get(l++).add(columnData[i][j]);
-        		}
-        	}
+            submit.add(executorService.submit(new BlockSortThread(i,columnsData[i])));
         }
-        
-//    	for(int i = 0;i < numberOfColumns;i++)
-//    	{
-//    		submit.add(executorService.submit(new BlockSortThread(i,columnsData[i])));
-//    	}
-        
-        ExecutorService executorService= Executors.newFixedThreadPool(5);
-        List<Future<IndexStorage>> submit = new ArrayList<Future<IndexStorage>>(allColsCount);
-        int l=0;
-    	for(int j=0;j<dimensionCount;j++)
-    	{
-    		GenericDataType complexDataType = complexIndexMap.get(j);
-    		if(complexDataType != null)
-    		{
-    			for(int k=0;k<complexDataType.getColsCount();k++)
-    			{
-    				submit.add(executorService.submit(new BlockSortThread(l, colsAndValues.get(l).toArray(new byte[colsAndValues.get(l++).size()][]), false)));
-    			}
-    		}
-    		else
-    		{
-    			submit.add(executorService.submit(new BlockSortThread(l, colsAndValues.get(l).toArray(new byte[colsAndValues.get(l++).size()][]), true)));
-    		}
-    	}
-        
-    	executorService.shutdown();
-    	try
-    	{
-    		executorService.awaitTermination(1, TimeUnit.DAYS);
-    	}
-    	catch(InterruptedException ex) 
-    	{ 
-    		// TODO Auto-generated catch block
-    		//   e.printStackTrace();
-    		LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, ex, ex.getMessage());
-    	}
-    	IndexStorage[] blockStorage = new IndexStorage[numberOfColumns];
-    	try
-    	{
-    		for(int i = 0;i < blockStorage.length;i++)
-    		{
-    			blockStorage[i]=submit.get(i).get();
-    		}
-    	}
-    	catch(Exception exception) 
-    	{
-    		// TODO Auto-generated catch block
+        executorService.shutdown();
+        try
+        {
+            executorService.awaitTermination(1, TimeUnit.DAYS);
+        }
+        catch(InterruptedException ex) 
+        { 
+            // TODO Auto-generated catch block
+         //   e.printStackTrace();
+            LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, ex, ex.getMessage());
+        }
+        IndexStorage[] blockStorage = new IndexStorage[numberOfColumns];
+        try
+        {
+            for(int i = 0;i < blockStorage.length;i++)
+            {
+                blockStorage[i]=submit.get(i).get();
+            }
+        }
+        catch(Exception exception) 
+        {
+            // TODO Auto-generated catch block
 //            e.printStackTrace();
-    		LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, exception, exception.getMessage());
-    	}
-    	synchronized(lock)
-    	{
-    		this.dataWriter.writeDataToFile(
-    				blockStorage,
-    				dataHolderLocal,
-    				entryCountLocal, startkeyLocal, endKeyLocal);
-    	}
-    				}
+        	 LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, exception, exception.getMessage());
+        }
+        synchronized(lock)
+        {
+            this.dataWriter.writeDataToFile(
+                    blockStorage,
+                    dataHolderLocal,
+                    entryCountLocal, startkeyLocal, endKeyLocal);
+        }
+    }
     
     private final class DataWriterThread implements Callable<IndexStorage>
     {
         private byte[][] data;
-
-        private byte[][][] columnData;
         
         private byte[][] dataHolderLocal;
         
@@ -778,21 +628,10 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             this.endKeyLocal=endKey;
             this.dataHolderLocal=dataHolderLocal;
         }
-        
-        private DataWriterThread(byte[][] data,byte[][] dataHolderLocal, byte[][][] columnData, int entryCountLocal, byte[] startKey, byte[] endKey)
-        {
-        	this.data=data;
-        	this.columnData = columnData;
-        	this.entryCountLocal=entryCountLocal;
-        	this.startkeyLocal=startKey;
-        	this.endKeyLocal=endKey;
-        	this.dataHolderLocal=dataHolderLocal;
-        }
         @Override
         public IndexStorage call() throws Exception
         {
-//            writeDataToFile(this.data,dataHolderLocal, entryCountLocal,startkeyLocal,endKeyLocal);
-            writeDataToFile(this.data,dataHolderLocal,columnData, entryCountLocal,startkeyLocal,endKeyLocal);
+            writeDataToFile(this.data,dataHolderLocal,entryCountLocal,startkeyLocal,endKeyLocal);
             return null;
         }
         
@@ -802,37 +641,45 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
         private int index;
         
         private byte[][] data;
-		private boolean isSortRequired;
+        
         private boolean isCompressionReq;
         
         private boolean isHighCardinality;
         
+        private boolean  isRowBlock;
         
-        private BlockSortThread(int index, byte[][] data, boolean isSortRequired)
+        private BlockSortThread(int index, byte[][] data)
         {
             this.index=index;
             this.data=data;
             isCompressionReq = aggKeyBlock[this.index];
-            this.isSortRequired = isSortRequired;
+            if(hybridStoreModel.isHybridStore() && this.index==0)
+            {
+            	isRowBlock=true;
+            }
+
         }
-        public BlockSortThread(int index, byte[][] data, boolean b, boolean isHighCardinality, boolean isSortRequired)
+        public BlockSortThread(int index, byte[][] data, boolean b, boolean isHighCardinality)
         {
             this.index = index;
             this.data = data;
             isCompressionReq = b;
             this.isHighCardinality = isHighCardinality;
-            this.isSortRequired = isSortRequired;
+            if(hybridStoreModel.isHybridStore() && this.index==0)
+            {
+            	isRowBlock=true;
+            }
+
         }
         @Override
         public IndexStorage call() throws Exception
         {
-            return new BlockIndexerStorageForInt(this.data,isCompressionReq,isHighCardinality, isSortRequired);
+        	
+            return new BlockIndexerStorageForInt(this.data,isCompressionReq,isHighCardinality,isRowBlock);
             
         }
         
     }
-    
-    
     /**
      * below method will be used to finish the data handler
      * @throws MolapDataWriterException
@@ -897,62 +744,21 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
                     columnsData[j][i]=splitKey[j];
                 }
             }
-            
             byte[][][] highCardColumnsData = null;
-            byte[][][] complexColumnsData = null;
-            List<ArrayList<byte[]>> colsAndValues = new ArrayList<ArrayList<byte[]>>();
-            int complexColCount = complexIndexMap.size();
-            
-            for(int i=0;i<complexColCount;i++)
-            {
-                colsAndValues.add(new ArrayList<byte[]>());
-            }
-            
             if(highCardCount > 0)
             {
                 byte[][] highCardData = highCardkeyDataHolder
                         .getByteArrayValues();
 
                 highCardColumnsData = new byte[highCardCount][highCardData.length][];
-                complexColumnsData = new byte[complexColCount][highCardData.length][];
-                
                 for(int i = 0;i < highCardData.length;i++)
                 {
 
                     byte[][] splitKey = RemoveDictionaryUtil.splitHighCardKey(
-                            highCardData[i], highCardCount+complexIndexMap.size());
-                    
-                    int complexTypeIndex = 0;
+                            highCardData[i], highCardCount);
                     for(int j = 0;j < splitKey.length;j++)
                     {
-                        //nodictionary Columns
-                        if(j < highCardCount)
-                        {
-                            highCardColumnsData[j][i] = splitKey[j];
-                        }
-                        //complex types
-                        else
-                        {
-                            //Need to write columnar block from complex byte array
-                            GenericDataType complexDataType = complexIndexMap.get(numberOfColumns+j);
-                            if(complexDataType != null)
-                            {
-                                List<ArrayList<byte[]>> columnsArray = new ArrayList<ArrayList<byte[]>>();
-                                for(int k=0;k<complexDataType.getColsCount();k++)
-                                {
-                                    columnsArray.add(new ArrayList<byte[]>());
-                                }
-                                complexDataType.getColumnarDataForComplexType(columnsArray, ByteBuffer.wrap(splitKey[j]));
-                                for(ArrayList<byte[]> eachColumn : columnsArray)
-                                {
-                                    colsAndValues.get(complexTypeIndex++).addAll(eachColumn);
-                                }
-                            }
-                            else
-                            {
-                                // This case not possible as ComplexType is the last columns
-                            }
-                        }
+                        highCardColumnsData[j][i] = splitKey[j];
                     }
                 }
             }
@@ -961,17 +767,13 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             int i = 0;
             for( i = 0;i < numberOfColumns;i++)
             {
-                submit.add(executorService.submit(new BlockSortThread(i, columnsData[i], true)));
+                submit.add(executorService.submit(new BlockSortThread(i, columnsData[i])));
+                
             }
             for(int j  = 0;j < highCardCount;j++)
             {
-                submit.add(executorService.submit(new BlockSortThread(i++, highCardColumnsData[j],false,true, true)));
-            }
-            for(int k  = 0;k < complexColCount;k++)
-            {
-                submit.add(executorService.submit(new BlockSortThread(i++, colsAndValues.get(k).toArray(new byte[colsAndValues.get(k).size()][]), false)));
+                submit.add(executorService.submit(new BlockSortThread(i++, highCardColumnsData[j],false,true)));
             }
-            
             executorService.shutdown();
             try
             {
@@ -983,7 +785,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
 //                e.printStackTrace();
                 LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, e, e.getMessage());
             }
-            IndexStorage[] blockStorage = new IndexStorage[numberOfColumns+highCardCount+complexColCount];
+            IndexStorage[] blockStorage = new IndexStorage[numberOfColumns+highCardCount];
             try
             {
                 for(int k = 0;k < blockStorage.length;k++)
@@ -995,7 +797,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             {
                 // TODO Auto-generated catch block
 //                e.printStackTrace();
-                 LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, e, e.getMessage());
+            	 LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, e, e.getMessage());
             }
             
             writerExecutorService.shutdown();
@@ -1007,7 +809,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             {
                 // TODO Auto-generated catch block
 //                e.printStackTrace();
-                 LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, e, e.getMessage());
+            	 LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, e, e.getMessage());
             }
             this.dataWriter.writeDataToFile(
                     blockStorage,
@@ -1025,7 +827,6 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             this.dataWriter.writeleafMetaDataToFile();
         }
     }
-    
     //TODO SIMIAN
     private byte[] getAggregateTableMdkey(byte[] maksedKey) throws MolapDataWriterException
     {
@@ -1048,22 +849,6 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
         }
     }
     
-    private int getColsCount()
-    {
-    	int count=0;
-    	for(int i=0;i<dimensionCount;i++)
-    	{
-    		GenericDataType complexDataType = complexIndexMap.get(i);
-    		if(complexDataType != null)
-    		{
-    			count += complexDataType.getColsCount();
-    		}
-    		else
-    			count++;
-    	}
-    	return count;
-    }
-    
     /**
      * below method will be used to close the handler
      */
@@ -1158,7 +943,12 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
         int[] keyBlockSize = null;
         if(dimLens.length > 0)
         {
-            this.columnarSplitter= new MultiDimKeyVarLengthEquiSplitGenerator(MolapUtil.getIncrementedCardinalityFullyFilled(dimLens.clone()),(byte)dimSet);
+        	//Using Variable length variable split generator
+        	//This will help in splitting mdkey to columns. variable split is required because all columns which are part of
+        	//row store will be in single column store
+        	//e.g if {0,1,2,3,4,5} is dimension and {0,1,2) is row store dimension 
+        	//than below splitter will return column as {0,1,2}{3}{4}{5}
+        	this.columnarSplitter = new MultiDimKeyVarLengthVariableSplitGenerator(MolapUtil.getDimensionBitLength(hybridStoreModel.getHybridCardinality(),hybridStoreModel.getDimensionPartitioner()),hybridStoreModel.getColumnSplit());
             this.keyBlockHolder= new MolapKeyBlockHolder [this.columnarSplitter.getBlockKeySize().length];
             keyBlockSize = columnarSplitter.getBlockKeySize();
         }
@@ -1228,6 +1018,8 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
 //        this.dataWriter = new MolapFactDataWriterImpl(this.storeLocation,
 //                this.measureCount, this.mdkeyLength, this.tableName,true,fileManager, this.columnarSplitter.getBlockKeySize());
         
+        
+        
         this.dataWriter=getFactDataWriter(this.storeLocation,
                 this.measureCount, this.mdkeyLength, this.tableName,true,fileManager, keyBlockSize);
         this.dataWriter.setIsNoDictionary(isNoDictionary);
@@ -1276,7 +1068,7 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
         else if(isIntBasedIndexer && isAggKeyBlock)
         {
             LOGGER.info(MolapDataProcessorLogEvent.UNIBI_MOLAPDATAPROCESSOR_MSG, "*************************************aggregated and int");
-            return new MolapFactDataWriterImplForIntIndexAndAggBlock(storeLocation, measureCount, mdKeyLength, tableName, isNodeHolder, fileManager, keyBlockSize,aggKeyBlock,false, isComplexTypes());
+            return new MolapFactDataWriterImplForIntIndexAndAggBlock(storeLocation, measureCount, mdKeyLength, tableName, isNodeHolder, fileManager, keyBlockSize,aggKeyBlock,false);
         }
         else if(isIntBasedIndexer)
         {
@@ -1289,58 +1081,4 @@ public class MolapFactDataHandlerColumnar implements MolapFactHandler
             return new MolapFactDataWriterImpl(storeLocation, measureCount, mdKeyLength, tableName, isNodeHolder, fileManager, keyBlockSize,false);
         }
     }
-    private int[] getBlockKeySizeWithComplexTypes(int[] primitiveBlockKeySize)
-    {
-    	int allColsCount = getColsCount();
-    	int[] blockKeySizeWithComplexTypes = new int[allColsCount];
-    	
-    	List<Integer> blockKeySizeWithComplex = new ArrayList<Integer>(allColsCount);
-        for(int i = 0;i < dimensionCount;i++)
-        {
-        	GenericDataType complexDataType = complexIndexMap.get(i);
-    		if(complexDataType != null)
-    		{
-    			complexDataType.fillBlockKeySize(blockKeySizeWithComplex, primitiveBlockKeySize);
-    		}
-    		else
-    		{
-    			blockKeySizeWithComplex.add(primitiveBlockKeySize[i]);
-    		}
-        }
-        for(int i=0;i<allColsCount;i++)
-        {
-        	blockKeySizeWithComplexTypes[i] = blockKeySizeWithComplex.get(i);
-        }
-    	
-    	return blockKeySizeWithComplexTypes;
-    }
-    private boolean[] isComplexTypes()
-    {
-    	int allColsCount = getColsCount();
-    	boolean[] isComplexType = new boolean[allColsCount];
-    	
-    	List<Boolean> complexTypesList = new ArrayList<Boolean>(allColsCount);
-    	for(int i = 0;i < dimensionCount;i++)
-    	{
-    		GenericDataType complexDataType = complexIndexMap.get(i);
-    		if(complexDataType != null)
-    		{
-    			int count = complexDataType.getColsCount();
-    			for(int j=0;j<count;j++)
-    			{
-    				complexTypesList.add(true);
-    			}
-    		}
-    		else
-    		{
-    			complexTypesList.add(false);
-    		}
-    	}
-    	for(int i=0;i<allColsCount;i++)
-    	{
-    		isComplexType[i] = complexTypesList.get(i);
-    	}
-    	
-    	return isComplexType;
-    }
-}
+}
\ No newline at end of file
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnarMerger.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnarMerger.java
index 59f7de4..c447756 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnarMerger.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/MolapFactDataHandlerColumnarMerger.java
@@ -458,8 +458,13 @@ public class MolapFactDataHandlerColumnarMerger implements MolapFactHandler
         @Override
         public IndexStorage call() throws Exception
         {
+        	boolean isColumnar=true;
+        	if(index==0)
+        	{
+        		isColumnar=false;	
+        	}
             return new BlockIndexerStorageForInt(this.data,
-                    aggKeyBlock[this.index], true);
+                    aggKeyBlock[this.index],isColumnar);
 
         }
 
@@ -840,4 +845,4 @@ public class MolapFactDataHandlerColumnarMerger implements MolapFactHandler
 		}
 	      
 	}
-}
+}
\ No newline at end of file
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/SingleThreadFinalSortFilesMerger.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/SingleThreadFinalSortFilesMerger.java
index f790c05..07024d9 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/SingleThreadFinalSortFilesMerger.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/SingleThreadFinalSortFilesMerger.java
@@ -80,7 +80,7 @@ public class SingleThreadFinalSortFilesMerger
     private int measureCount;
     
     /**
-     * dimensionCount
+     * measure count
      */
     private int dimensionCount;
     
@@ -90,23 +90,17 @@ public class SingleThreadFinalSortFilesMerger
     private int highCardinalityCount;
     
     /**
-     * complexDimensionCount
-     */
-    private int complexDimensionCount;
-    
-    /**
      * tempFileLocation
      */
     private String tempFileLocation;
     
     
     public SingleThreadFinalSortFilesMerger(String tempFileLocation, String tableName,
-            int dimensionCount, int complexDimensionCount, int measureCount, int highCardinalityCount)
+            int dimensionCount, int measureCount, int highCardinalityCount)
     {
         this.tempFileLocation = tempFileLocation;
         this.tableName = tableName;
         this.dimensionCount = dimensionCount;
-        this.complexDimensionCount = complexDimensionCount;
         this.measureCount = measureCount;
         this.highCardinalityCount = highCardinalityCount;
     }
@@ -191,7 +185,7 @@ public class SingleThreadFinalSortFilesMerger
                 {
                     // create chunk holder
                 	SortTempFileChunkHolder sortTempFileChunkHolder = new SortTempFileChunkHolder(
-                            tempFile, dimensionCount, complexDimensionCount, measureCount, fileBufferSize,highCardinalityCount);
+                            tempFile, dimensionCount, measureCount, fileBufferSize,highCardinalityCount);
                     
                 	// initialize
                 	sortTempFileChunkHolder.initialize();
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/AbstractFactDataWriter.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/AbstractFactDataWriter.java
index 8d558d3..c4e3916 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/AbstractFactDataWriter.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/AbstractFactDataWriter.java
@@ -491,7 +491,8 @@ public abstract class AbstractFactDataWriter<T> implements MolapFactDataWriter<T
     {
         // create the info object for leaf entry
     	LeafNodeInfoColumnar infoObj = new LeafNodeInfoColumnar(); 
-        // add total entry count
+    	
+    	// add total entry count
         infoObj.setNumberOfKeys(nodeHolder.getEntryCount());
 
         // add the key array length
@@ -540,10 +541,23 @@ public abstract class AbstractFactDataWriter<T> implements MolapFactDataWriter<T
         	offset+=nodeHolder.getKeyBlockIndexLength()[i];
 		}
         infoObj.setKeyBlockIndexOffSets(keyBlockIndexOffsets);
+        
+        //offset for rowsdata
+       /* offset+=nodeHolder.getRowsKeyLength();
+        infoObj.setRowsKeyLength(nodeHolder.getRowsKeyLength());
+        infoObj.setRowsKeyLenghtOffset(offset);*/
+        
+        // add dimensions which is part of columnar store
+    	//infoObj.setColStoreOrdinals(nodeHolder.getColStoreOrdinals());
+    	
+    	//add dimension which is part of row store
+    	//infoObj.setRowStoreOrdinals(nodeHolder.getRowStoreOrdinals());
+    	
         // set startkey
         infoObj.setStartKey(nodeHolder.getStartKey());
         // set end key
         infoObj.setEndKey(nodeHolder.getEndKey());
+        
         infoObj.setLeafNodeMetaSize(calculateAndSetLeafNodeMetaSize(nodeHolder));
         // return leaf metadata
         return infoObj;
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriter.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriter.java
index d50e596..9960d22 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriter.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriter.java
@@ -26,7 +26,7 @@ public interface MolapFactDataWriter<T>
      *          throws new MolapDataWriterException if any problem
 	 */
 	
-	void writeDataToFile(IndexStorage<T>[] keyStorageArray, byte[][] dataArray,
+	void writeDataToFile(IndexStorage<T>[] keyStorageArray,byte[][] dataArray,
 			int entryCount, byte[] startKey, byte[] endKey)
 			throws MolapDataWriterException;
 	
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImpl.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImpl.java
index caaf473..091f15d 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImpl.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImpl.java
@@ -20,7 +20,8 @@ public class MolapFactDataWriterImpl extends AbstractFactDataWriter<short[]>
 	}
 
 	@Override
-	public void writeDataToFile(IndexStorage<short[]>[] keyStorageArray, byte[][] dataArray,
+	public void writeDataToFile(IndexStorage<short[]>[] keyStorageArray,
+			 byte[][] dataArray,
 			int entryCount, byte[] startKey, byte[] endKey)
 			throws MolapDataWriterException
 	{
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndex.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndex.java
index 92b0059..a0c83b5 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndex.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndex.java
@@ -35,7 +35,8 @@ public class MolapFactDataWriterImplForIntIndex extends AbstractFactDataWriter<i
 	}
 
 	@Override
-	public void writeDataToFile(IndexStorage<int[]>[] keyStorageArray, byte[][] dataArray,
+	public void writeDataToFile(IndexStorage<int[]>[] keyStorageArray,
+			 byte[][] dataArray,
 			int entryCount, byte[] startKey, byte[] endKey)
 			throws MolapDataWriterException
 	{
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndexAndAggBlock.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndexAndAggBlock.java
index 160f969..681932e 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndexAndAggBlock.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/store/writer/MolapFactDataWriterImplForIntIndexAndAggBlock.java
@@ -21,22 +21,11 @@ public class MolapFactDataWriterImplForIntIndexAndAggBlock extends AbstractFactD
 {
     private NumberCompressor numberCompressor;
     
-    private boolean[] isComplexType;
-    
     protected boolean[] aggBlocks;
     
     private static final LogService LOGGER = LogServiceFactory
           .getLogService(MolapFactDataWriterImplForIntIndexAndAggBlock.class.getName());
 
-    public MolapFactDataWriterImplForIntIndexAndAggBlock(String storeLocation, int measureCount,
-            int mdKeyLength, String tableName, boolean isNodeHolder,
-            IFileManagerComposite fileManager, int[] keyBlockSize, 
-            boolean[] aggBlocks, boolean isUpdateFact, boolean[] isComplexType)
-    {
-    	this(storeLocation, measureCount, mdKeyLength, tableName, 
-    			isNodeHolder,fileManager, keyBlockSize, aggBlocks, isUpdateFact);
-    	this.isComplexType = isComplexType;
-    }
     
     public MolapFactDataWriterImplForIntIndexAndAggBlock(String storeLocation, int measureCount,
             int mdKeyLength, String tableName, boolean isNodeHolder,IFileManagerComposite fileManager, int[] keyBlockSize, boolean[] aggBlocks, boolean isUpdateFact)
@@ -109,7 +98,7 @@ public class MolapFactDataWriterImplForIntIndexAndAggBlock extends AbstractFactD
         {
             if(!isSortedData[i])
             {
-                dataAfterCompression[idx] =numberCompressor
+            	dataAfterCompression[idx] =numberCompressor
                         .compress(keyStorageArray[i].getDataAfterComp());
                 if(null!=keyStorageArray[i].getIndexMap() && keyStorageArray[i]
                         .getIndexMap().length>0)
@@ -220,7 +209,7 @@ public class MolapFactDataWriterImplForIntIndexAndAggBlock extends AbstractFactD
         {
             destPos=0;
             //handling for high card dims
-            if(i >= keyBlockSize.length && !isComplexType[i])
+            if(i >= keyBlockSize.length)
             {
                 int totalLength = 0;
                 // calc size of the total bytes in all the colmns.
@@ -241,7 +230,7 @@ public class MolapFactDataWriterImplForIntIndexAndAggBlock extends AbstractFactD
             }
             else
             {
-            	if(aggBlocks[i])
+                if(aggBlocks[i])
                 {
                     keyBlockData[i] = new byte[keyStorageArray[i]
                             .getTotalSize()];
@@ -255,19 +244,13 @@ public class MolapFactDataWriterImplForIntIndexAndAggBlock extends AbstractFactD
                 }
                 else
                 {
-                	if(isComplexType[i])
-	            	{
-	            		keyBlockData[i]= new byte[keyStorageArray[i].getKeyBlock().length* keyBlockSize[i]];
-	            	}
-	            	else
-	            	{
-	            		keyBlockData[i]= new byte[entryCount* keyBlockSize[i]];
-	            	}
-	                for(int j=0;j<keyStorageArray[i].getKeyBlock().length;j++)
-	                {
-	                    System.arraycopy(keyStorageArray[i].getKeyBlock()[j], 0, keyBlockData[i], destPos, keyBlockSize[i]);
-	                    destPos+=keyBlockSize[i];
-	                }
+                    keyBlockData[i] = new byte[entryCount * keyBlockSize[i]];
+                    for(int j = 0;j < keyStorageArray[i].getKeyBlock().length;j++)
+                    {
+                        System.arraycopy(keyStorageArray[i].getKeyBlock()[j],
+                                0, keyBlockData[i], destPos, keyBlockSize[i]);
+                        destPos += keyBlockSize[i];
+                    }
                 }
             }
             keyBlockData[i]=SnappyByteCompression.INSTANCE.compress(keyBlockData[i]);
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedDimSurrogateKeyGen.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedDimSurrogateKeyGen.java
index d99a45c..cd9efa1 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedDimSurrogateKeyGen.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedDimSurrogateKeyGen.java
@@ -23,10 +23,8 @@ import it.unimi.dsi.fastutil.ints.Int2ObjectOpenHashMap;
 import java.io.File;
 import java.io.OutputStream;
 import java.sql.Connection;
-import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
@@ -35,7 +33,6 @@ import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 import org.pentaho.di.core.exception.KettleException;
 
-import com.huawei.datasight.molap.datatypes.GenericDataType;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
@@ -698,35 +695,14 @@ public abstract class MolapCSVBasedDimSurrogateKeyGen
     
     private void setDimensionTables(String[] dimeFileNames)
     {
-//        this.dimsFiles = dimeFileNames;
-//        max = new int[dimeFileNames.length];
-        int noOfPrimitiveDims = 0;
-        List<String> dimFilesForPrimitives = new ArrayList<String>();
+        this.dimsFiles = dimeFileNames;
+        max = new int[dimeFileNames.length];
+
         memberCache = new ConcurrentHashMap<String, Map<String, Integer>>();
         for(int i = 0;i < dimeFileNames.length;i++)
         {
-        	GenericDataType complexType = molapInfo.getComplexTypesMap().get(dimeFileNames[i].substring(molapInfo.getTableName().length() + 1));
-        	if(complexType != null)
-        	{
-        		List<GenericDataType> primitiveChild = new ArrayList<GenericDataType>();
-        		complexType.getAllPrimitiveChildren(primitiveChild);
-        		for(GenericDataType eachPrimitive: primitiveChild)
-        		{
-        			memberCache.put(molapInfo.getTableName()+"_"+eachPrimitive.getName(), new ConcurrentHashMap<String, Integer>());
-        			dimFilesForPrimitives.add(molapInfo.getTableName()+"_"+eachPrimitive.getName());
-        			eachPrimitive.setSurrogateIndex(noOfPrimitiveDims);
-        			noOfPrimitiveDims++;
-        		}
-        	}
-        	else
-        	{
-        		memberCache.put(dimeFileNames[i], new ConcurrentHashMap<String, Integer>());
-        		dimFilesForPrimitives.add(dimeFileNames[i]);
-        		noOfPrimitiveDims++;
-        	}
+            memberCache.put(dimeFileNames[i], new ConcurrentHashMap<String, Integer>());
         }
-        max = new int[noOfPrimitiveDims];
-        this.dimsFiles = dimFilesForPrimitives.toArray(new String[dimFilesForPrimitives.size()]);
 
        // checkDimTableCreated();
         createRespectiveDimFilesForDimTables();
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenMeta.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenMeta.java
index 0bf8c60..48d99ad 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenMeta.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenMeta.java
@@ -22,7 +22,6 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
-import java.util.LinkedHashMap;
 import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Map;
@@ -48,10 +47,6 @@ import org.pentaho.di.trans.step.StepMeta;
 import org.pentaho.di.trans.step.StepMetaInterface;
 import org.w3c.dom.Node;
 
-import com.huawei.datasight.molap.datatypes.ArrayDataType;
-import com.huawei.datasight.molap.datatypes.GenericDataType;
-import com.huawei.datasight.molap.datatypes.PrimitiveDataType;
-import com.huawei.datasight.molap.datatypes.StructDataType;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
 import com.huawei.unibi.molap.schema.metadata.HierarchiesInfo;
 import com.huawei.unibi.molap.util.MolapDataProcessorUtil;
@@ -193,56 +188,13 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
      * checkPointFileExits
      */
     private String checkPointFileExits;
-    
-    private String complexDelimiterLevel1;
-    
-	private String complexDelimiterLevel2;
 
     /**
      * dims
      */
     protected int[] dims;
- 
-    /**
-     * dims
-     */
-    protected Map<String, GenericDataType> complexTypes = new HashMap<String, GenericDataType>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
-    
-    private String complexTypeString;
-
-    public Map<String, GenericDataType> getComplexTypes() {
-		return complexTypes;
-	}
-
-	public void setComplexTypes(Map<String, GenericDataType> complexTypes) {
-		this.complexTypes = complexTypes;
-	}
-	
-	public String getComplexDelimiterLevel1() {
-		return complexDelimiterLevel1;
-	}
-
-	public void setComplexDelimiterLevel1(String complexDelimiterLevel1) {
-		this.complexDelimiterLevel1 = complexDelimiterLevel1;
-	}
-
-	public String getComplexDelimiterLevel2() {
-		return complexDelimiterLevel2;
-	}
-
-	public void setComplexDelimiterLevel2(String complexDelimiterLevel2) {
-		this.complexDelimiterLevel2 = complexDelimiterLevel2;
-	}
-	
-	public String getComplexTypeString() {
-		return complexTypeString;
-	}
 
-	public void setComplexTypeString(String complexTypeString) {
-		this.complexTypeString = complexTypeString;
-	}
-
-	/**
+    /**
      * dimLens
      */
     protected int[] dimLens;
@@ -737,9 +689,6 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
         tableName="";
         molaphierColumn="";
         foreignKeyHierarchyString="";
-        complexTypeString="";
-        complexDelimiterLevel1 = "";
-        complexDelimiterLevel2 = "";
         primaryKeysString="";
         molapMeasureNames = "";
         actualDimNames = "";
@@ -798,9 +747,6 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
         retval.append("    ").append(XMLHandler.addTagValue("metadataFilePath", metaHeirSQLQuery));
         retval.append("    ").append(XMLHandler.addTagValue("molapMetaHier", molapMetaHier));
         retval.append("    ").append(XMLHandler.addTagValue("foreignKeyHierarchyString", foreignKeyHierarchyString));
-        retval.append("    ").append(XMLHandler.addTagValue("complexTypeString", complexTypeString));
-        retval.append("    ").append(XMLHandler.addTagValue("complexDelimiterLevel1", complexDelimiterLevel1));
-        retval.append("    ").append(XMLHandler.addTagValue("complexDelimiterLevel2", complexDelimiterLevel2));
         retval.append("    ").append(XMLHandler.addTagValue("primaryKeysString", primaryKeysString));
         retval.append("    ").append(XMLHandler.addTagValue("molapMeasureNames", molapMeasureNames));
         retval.append("    ").append(XMLHandler.addTagValue("actualDimNames", actualDimNames));
@@ -848,9 +794,6 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
             molapMetaHier = XMLHandler.getTagValue(stepnode, "molapMetaHier");
             molaphierColumn = XMLHandler.getTagValue(stepnode, "molaphierColumn");
             foreignKeyHierarchyString = XMLHandler.getTagValue(stepnode, "foreignKeyHierarchyString");
-            complexTypeString = XMLHandler.getTagValue(stepnode, "complexTypeString");
-            complexDelimiterLevel1 = XMLHandler.getTagValue(stepnode, "complexDelimiterLevel1");
-            complexDelimiterLevel2 = XMLHandler.getTagValue(stepnode, "complexDelimiterLevel2");
             primaryKeysString = XMLHandler.getTagValue(stepnode, "primaryKeysString");
             molapMeasureNames = XMLHandler.getTagValue(stepnode, "molapMeasureNames");
             actualDimNames = XMLHandler.getTagValue(stepnode, "actualDimNames");
@@ -901,10 +844,7 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
     
     public void initialize() throws KettleException
     {
-        if(null != complexTypeString)
-        {
-            complexTypes = getComplexTypesMap(complexTypeString);
-        }
+        
         updateDimensions(molapdim,molapmsr,highCardinalityDims);
         
         hirches = getHierarichies(molaphier);
@@ -912,7 +852,6 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
         hierColumnMap = getHierarchiesColumnMap(molaphierColumn);
         
         foreignKeyHierarchyMap = getForeignKeyHierMap(foreignKeyHierarchyString);
-
         
         primaryKeyMap = updatePrimaryKeyMap(primaryKeysString);
         
@@ -1171,36 +1110,6 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
         hierNames = actualHierList.toArray(new String[actualHierList.size()]);
     }
 
-    
-    private Map<String,GenericDataType> getComplexTypesMap(String complexTypeString)
-    {
-    	Map<String,GenericDataType> complexTypesMap = new LinkedHashMap<String,GenericDataType>();
-    	String[] hierarchies = complexTypeString.split(MolapCommonConstants.SEMICOLON_SPC_CHARACTER);
-        for(int i = 0;i < hierarchies.length;i++)
-        {
-            String[] levels = hierarchies[i].split(MolapCommonConstants.HASH_SPC_CHARACTER);
-            String[] levelInfo = levels[0].split(MolapCommonConstants.COLON_SPC_CHARACTER);
-			GenericDataType g = levelInfo[1].equals("Array")?
-						new ArrayDataType(levelInfo[0], ""):new StructDataType(levelInfo[0], "");
-			complexTypesMap.put(levelInfo[0], g);
-            for(int j = 1;j < levels.length;j++)
-            {
-            	levelInfo = levels[j].split(MolapCommonConstants.COLON_SPC_CHARACTER);
-				switch(levelInfo[1])
-				{
-					case "Array" : 
-						g.addChildren(new ArrayDataType(levelInfo[0], levelInfo[2]));
-						break;
-					case "Struct" : 
-						g.addChildren(new StructDataType(levelInfo[0], levelInfo[2]));
-						break;
-					default :
-						g.addChildren(new PrimitiveDataType(levelInfo[0], levelInfo[2]));
-				}
-            }
-        }
-        return complexTypesMap;
-    }
     /**
      * 
      * @param foreignKeyHierarchyString2
@@ -1536,7 +1445,7 @@ public class MolapCSVBasedSeqGenMeta extends BaseStepMeta implements StepMetaInt
         dimLens = lens;
 //      columns.put(DIMENSIONS, list);
         dimColNames = list.toArray(new String[list.size()]);
-        highCardCols= new String[0];
+        
         //for high card dims
         if(null != highCardinalityDims)
         {
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenStep.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenStep.java
index 572cbaf..268f6e1 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenStep.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/surrogatekeysgenerator/csvbased/MolapCSVBasedSeqGenStep.java
@@ -19,8 +19,6 @@ package com.huawei.unibi.molap.surrogatekeysgenerator.csvbased;
 
 import it.unimi.dsi.fastutil.ints.Int2ObjectMap;
 
-import java.io.ByteArrayOutputStream;
-import java.io.DataOutputStream;
 import java.io.File;
 import java.io.FileWriter;
 import java.io.IOException;
@@ -60,7 +58,6 @@ import org.pentaho.di.trans.step.StepDataInterface;
 import org.pentaho.di.trans.step.StepMeta;
 import org.pentaho.di.trans.step.StepMetaInterface;
 
-import com.huawei.datasight.molap.datatypes.GenericDataType;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.iweb.platform.logging.impl.StandardLogService;
@@ -520,7 +517,6 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
                 molapInfo.setTableName(meta.getTableName());
                 molapInfo.setPrimaryKeyMap(meta.getPrimaryKeyMap());
                 molapInfo.setMeasureColumns(meta.measureColumn);
-                molapInfo.setComplexTypesMap(meta.getComplexTypes());
                 
                 updateBagLogFileName();
                 String key = meta.getSchemaName() +'/' +meta.getCubeName()+'_'+meta.getTableName();
@@ -613,25 +609,10 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
                	MolapCSVBasedDimSurrogateKeyGen surrogateKeyGenObj = data.getSurrogateKeyGen();
                	if(null != surrogateKeyGenObj)
                	{
-               		int index=0;
                		for(int j=0; j<meta.dimColNames.length;j++)
                		{
-               			GenericDataType complexType = molapInfo.getComplexTypesMap().get(meta.dimColNames[j].substring(meta.getTableName().length() + 1));
-                    	if(complexType != null)
-                    	{
-                    		List<GenericDataType> primitiveChild = new ArrayList<GenericDataType>();
-                    		complexType.getAllPrimitiveChildren(primitiveChild);
-                    		for(GenericDataType eachPrimitive: primitiveChild)
-                    		{
-                    			surrogateKeyGenObj.generateSurrogateKeys(MolapCommonConstants.MEMBER_DEFAULT_VAL, meta.getTableName()+"_"+eachPrimitive.getName(), index, new Object[0]);
-                    			index++;
-                    		}
-                    	}
-                    	else
-                    	{
-                    		surrogateKeyGenObj.generateSurrogateKeys(MolapCommonConstants.MEMBER_DEFAULT_VAL, meta.dimColNames[j], index, new Object[0]);
-                    		index++;
-                    	}
+               			
+               			surrogateKeyGenObj.generateSurrogateKeys(MolapCommonConstants.MEMBER_DEFAULT_VAL, meta.dimColNames[j], j, new Object[0]);
                		}
                	}
                }
@@ -689,8 +670,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
 //            }
 //        }
         updateAndWriteSliceMetadataFile();
-//        MolapUtil.writeLevelCardinalityFile(loadFolderLoc, meta.getTableName(), data.getSurrogateKeyGen().max);
-        MolapUtil.writeLevelCardinalityFile(loadFolderLoc, meta.getTableName(), getUpdatedCardinality(data.getSurrogateKeyGen().max));
+        MolapUtil.writeLevelCardinalityFile(loadFolderLoc, meta.getTableName(), data.getSurrogateKeyGen().max);
         writeDataFileVersion();
         badRecordslogger.closeStreams();
         if(!meta.isAggregate())
@@ -1295,7 +1275,6 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
         sliceMetaData.setMeasuresAggregator(meta.msrAggregators);
         sliceMetaData.setHeirAnKeySize(meta.getHeirKeySize());
         sliceMetaData.setTableNamesToLoadMandatory(null);
-        sliceMetaData.setComplexTypeString(meta.getComplexTypeString());
 //        int measureOrdinal =0;
 //        for(String agg : meta.msrAggregators)
 //        {
@@ -1345,32 +1324,11 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
     private int[] getUpdatedCardinality(int[] dimCardinality)
     {
     	int[] maxSurrogateKeyArray = data.getSurrogateKeyGen().max;
+    	int length = dimCardinality.length;
     	
-    	List<Integer> dimCardWithComplex = new ArrayList<Integer>();
-    	
-    	for(int i=0;i<meta.dimColNames.length;i++)
-    	{
-    		GenericDataType complexDataType = meta.complexTypes.get(meta.dimColNames[i].substring(meta.getTableName().length() + 1));
-    		if(complexDataType != null)
-    		{
-    			complexDataType.fillCardinalityAfterDataLoad(dimCardWithComplex, maxSurrogateKeyArray);
-    		}
-    		else
-    		{
-    			dimCardWithComplex.add(maxSurrogateKeyArray[i]);
-    		}
-    	}
+    	System.arraycopy(maxSurrogateKeyArray, 0, dimCardinality, 0, length);
     	
-//    	int length = dimCardinality.length;
-//    	System.arraycopy(maxSurrogateKeyArray, 0, dimCardinality, 0, length);
-//    	
-//    	return dimCardinality;
-    	int[] complexDimCardinality = new int[dimCardWithComplex.size()]; 
-    	for(int i=0;i<dimCardWithComplex.size();i++)
-    	{
-    		complexDimCardinality[i] = dimCardWithComplex.get(i);
-    	}
-    	return complexDimCardinality;
+    	return dimCardinality;
     }
     
 	/**
@@ -1993,7 +1951,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
 //        int[] dimMapping = meta.dimMapping;
         // Copy the dimension String values to output
         int [] memberMapping = meta.memberMapping;
-        int inputColumnsSize = metaColumnNames.length;
+        int inputRowSize = metaColumnNames.length;
         boolean isGenerated=false;
         int generatedSurrogate=-1;
         
@@ -2006,7 +1964,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
         
         if(null == r[1])
         {
-            badRecordslogger.addBadRecordsToBilder(r, inputColumnsSize,
+            badRecordslogger.addBadRecordsToBilder(r, inputRowSize,
                     "Column Names are coming NULL", "null");
             return null;
         }
@@ -2021,7 +1979,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
         ByteBuffer[] byteBufferArr = null;
         if(null != meta.highCardCols)
         {
-            byteBufferArr = new ByteBuffer[meta.highCardCols.length + meta.complexTypes.size()];
+            byteBufferArr = new ByteBuffer[meta.highCardCols.length];
         }
         int i = 0;
         int n=0;
@@ -2029,8 +1987,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
         int l = 0;
         boolean isNull=false;
       //CHECKSTYLE:OFF    Approval No:Approval-367
-        int complexIndex = meta.highCardCols.length;
-        for(int j = 0;j < inputColumnsSize;j++)
+        for(int j = 0;j < inputRowSize;j++)
         {
             String columnName = metaColumnNames[j];
             String foreignKeyColumnName = foreignKeyMappingColumns[j];
@@ -2099,7 +2056,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
                     	}
                     	catch(NumberFormatException ex)
                     	{
-                            badRecordslogger.addBadRecordsToBilder(r, inputColumnsSize,
+                            badRecordslogger.addBadRecordsToBilder(r, inputRowSize,
                                     "Measure should be number",valueToCheckAgainst);
                             return null;
                     	}
@@ -2173,7 +2130,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
                             }
                             else
                             {
-                                addMemberNotExistEntry(r, inputColumnsSize, j,
+                                addMemberNotExistEntry(r, inputRowSize, j,
 										columnName);
                                 return null;
                             }
@@ -2184,7 +2141,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
                             // in bad records
                             if(null == surrogateKeyForHierarchy)
                             {
-                                addCardinalityExcededEntry(r, inputColumnsSize, j,
+                                addCardinalityExcededEntry(r, inputRowSize, j,
 										columnName);
                                 return null;
 
@@ -2229,127 +2186,102 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
             //If it refers to single hierarchy
             else
             {
-            	String complexDataTypeName = foreignKeyColumnName.substring(meta.getTableName().length() + 1);
-            	GenericDataType complexType = meta.getComplexTypes().get(complexDataTypeName);
-            	if(complexType != null)
-	            {
-            		try {
-            			ByteArrayOutputStream byteArray = new ByteArrayOutputStream();
-            			DataOutputStream dataOutputStream = new DataOutputStream(byteArray);
-//						complexType.parseStringAndWriteByteArray(meta.getTableName(), (String)r[j], new String[]{"\\$","\\:"}, 0, dataOutputStream, surrogateKeyGen);
-						complexType.parseStringAndWriteByteArray(meta.getTableName(), (String)r[j], 
-								new String[]{meta.getComplexDelimiterLevel1(),meta.getComplexDelimiterLevel2()}, 
-								0, dataOutputStream, surrogateKeyGen);
-//						out[memberMapping[i]] = byteArray.toByteArray();
-						byteBufferArr[complexIndex++] = ByteBuffer.wrap(byteArray.toByteArray());
-						if(null != byteArray)
-						{
-							byteArray.close();
-						}
-					} catch (IOException e1) {
-						throw new KettleException("Parsing complex string and generating surrogates/ByteArray failed. ", e1);
-					}
-            		i++;
-	            }
-            	else
-            	{
-	                Map<String, Integer> memberCache = allMemberCache.get(foreignKeyColumnName);
-	                
-	                String actualHierName = null;
-	                if(!isPresentInSchema)
-	                {
-	                    actualHierName = meta.hierNames[l++];
-	                    
-	                }
-	                
-	                Int2ObjectMap<int[]> cache = surrogateKeyGen.getHierCache()
-	                        .get(actualHierName);
-	                int[] surrogateKeyForHrrchy = null;
-	                if(null != cache)
-	                {
-	                    Integer keyFromCsv = memberCache.get(((String)r[j]));    
-	                    
-	                    if(null != keyFromCsv)
-	                    {
-	                        surrogateKeyForHrrchy = cache.get(keyFromCsv);
-	                    }
-	                    else
-	                    {
-	                        addMemberNotExistEntry(r, inputColumnsSize, j, columnName);
-	                        return null;
-	                    }
-	                    // If cardinality exceeded for some levels then for that hierarchy will not be their 
-	                    // so while joining with fact table if we are getting this scenerio we will log it 
-	                    // in bad records
-	                    if(null == surrogateKeyForHrrchy)
-	                    {
-	                        addCardinalityExcededEntry(r, inputColumnsSize, j,
-									columnName);
-	                        return null;
-	
-	                    }
-	                }
-	                else
-	                {
-	                    int[] propIndex = propMap.get(foreignKeyColumnName);
-	                    Object []properties;
-	                    if(null == propIndex)
-	                    {
-	                        properties = new Object[0]; 
-	                    }
-	                    else
-	                    {
-	                        properties = new Object[propIndex.length];
-	                        for(int ind = 0; ind < propIndex.length; ind++)
-	                        {
-	                            properties[ind]= r[propIndex[ind]];
-	                        }
-	                    }
-	                    surrogateKeyForHrrchy = new int[1];
-	                    if(isGenerated && !isNull)
-	                    {
-	                        surrogateKeyForHrrchy[0]=generatedSurrogate;
-	                        isGenerated=false;
-	                        generatedSurrogate=-1;
-	                    }
-	                    else
-	                    {
-	                        surrogateKeyForHrrchy[0] = surrogateKeyGen
-	                                .generateSurrogateKeys(((String)r[j]),
-	                                        foreignKeyColumnName,
-	                                        n,
-	                                        properties);
-	                    }
-	                    if(surrogateKeyForHrrchy[0] == -1)
-	                    {
-	                        addCardinalityExcededEntry(r, inputColumnsSize, j,
-									columnName);
-	                        return null;
-	                    }
-	                }
-	                for(int k = 0;k < surrogateKeyForHrrchy.length;k++)
-	                {
-	                    if(dimPresentCsvOrder[i])
-	                    {
-	                        if(duplicateColMapping[j] != null)
-	                        {
-	                            for (int m = 0; m < duplicateColMapping[j].length; m++) 
-	                            {
-	                                out[duplicateColMapping[j][m]] = Integer.valueOf(
-	                                        surrogateKeyForHrrchy[k]);
-	                            }
-	                        }
-	                        else
-	                        {
-	                            out[memberMapping[i]] = Integer.valueOf(
-	                                    surrogateKeyForHrrchy[k]);
-	                        }
-	                    }
-	                    
-	                    i++;
-	                }
-	                
-	            }
+                Map<String, Integer> memberCache = allMemberCache.get(foreignKeyColumnName);
+                
+                String actualHierName = null;
+                if(!isPresentInSchema)
+                {
+                    actualHierName = meta.hierNames[l++];
+                    
+                }
+                
+                Int2ObjectMap<int[]> cache = surrogateKeyGen.getHierCache()
+                        .get(actualHierName);
+                int[] surrogateKeyForHrrchy = null;
+                if(null != cache)
+                {
+                    Integer keyFromCsv = memberCache.get(((String)r[j]));    
+                    
+                    if(null != keyFromCsv)
+                    {
+                        surrogateKeyForHrrchy = cache.get(keyFromCsv);
+                    }
+                    else
+                    {
+                        addMemberNotExistEntry(r, inputRowSize, j, columnName);
+                        return null;
+                    }
+                    // If cardinality exceeded for some levels then for that hierarchy will not be their 
+                    // so while joining with fact table if we are getting this scenerio we will log it 
+                    // in bad records
+                    if(null == surrogateKeyForHrrchy)
+                    {
+                        addCardinalityExcededEntry(r, inputRowSize, j,
+								columnName);
+                        return null;
+
+                    }
+                }
+                else
+                {
+                    int[] propIndex = propMap.get(foreignKeyColumnName);
+                    Object []properties;
+                    if(null == propIndex)
+                    {
+                        properties = new Object[0]; 
+                    }
+                    else
+                    {
+                        properties = new Object[propIndex.length];
+                        for(int ind = 0; ind < propIndex.length; ind++)
+                        {
+                            properties[ind]= r[propIndex[ind]];
+                        }
+                    }
+                    surrogateKeyForHrrchy = new int[1];
+                    if(isGenerated && !isNull)
+                    {
+                        surrogateKeyForHrrchy[0]=generatedSurrogate;
+                        isGenerated=false;
+                        generatedSurrogate=-1;
+                    }
+                    else
+                    {
+                        surrogateKeyForHrrchy[0] = surrogateKeyGen
+                                .generateSurrogateKeys(((String)r[j]),
+                                        foreignKeyColumnName,
+                                        n,
+                                        properties);
+                    }
+                    if(surrogateKeyForHrrchy[0] == -1)
+                    {
+                        addCardinalityExcededEntry(r, inputRowSize, j,
+								columnName);
+                        return null;
+                    }
+                }
+                for(int k = 0;k < surrogateKeyForHrrchy.length;k++)
+                {
+                    if(dimPresentCsvOrder[i])
+                    {
+                        if(duplicateColMapping[j] != null)
+                        {
+                            for (int m = 0; m < duplicateColMapping[j].length; m++) 
+                            {
+                                out[duplicateColMapping[j][m]] = Integer.valueOf(
+                                        surrogateKeyForHrrchy[k]);
+                            }
+                        }
+                        else
+                        {
+                            out[memberMapping[i]] = Integer.valueOf(
+                                    surrogateKeyForHrrchy[k]);
+                        }
+                    }
+                    
+                    i++;
+                }
+                
             }
         }
         
@@ -2632,18 +2564,15 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
                 int[] levelsIndxs = meta.hirches.get(hierName);
                 int[] levelSKeys = new int[levelsIndxs.length];
 
-                if(meta.complexTypes.get(meta.hierColumnMap.get(hierName)[0]) == null)
+                for(int i = 0;i < levelSKeys.length;i++)
                 {
-	                for(int i = 0;i < levelSKeys.length;i++)
-	                {
-	                    levelSKeys[i] = (Integer)rowWithKeys[levelsIndxs[i]];
-	                }
-	
-	                if(levelSKeys.length > 1)
-	                {
-	                    data.getSurrogateKeyGen().checkNormalizedHierExists(
-	                            levelSKeys, hierName, hierWriter);
-	                }
+                    levelSKeys[i] = (Integer)rowWithKeys[levelsIndxs[i]];
+                }
+
+                if(levelSKeys.length > 1)
+                {
+                    data.getSurrogateKeyGen().checkNormalizedHierExists(
+                            levelSKeys, hierName, hierWriter);
                 }
             }
         }
@@ -3148,11 +3077,6 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
             else
             {
                 String[] columns = meta.hierColumnMap.get(name);
-                
-                if(meta.getComplexTypes().get(columns[0]) != null)
-                {
-                	continue;
-                }
                 //
                 for(int i = 0;i < a.length;i++)
                 {
@@ -3178,19 +3102,7 @@ public class MolapCSVBasedSeqGenStep extends BaseStep
             keyGenerators.put(name, generator);
         
         }
-        
-        Iterator<Entry<String,GenericDataType>> complexMap = meta.getComplexTypes().entrySet().iterator();
-        while(complexMap.hasNext())
-        {
-            Entry<String,GenericDataType> complexDataType = complexMap.next();
-            List<GenericDataType> primitiveTypes = new ArrayList<GenericDataType>();
-            complexDataType.getValue().getAllPrimitiveChildren(primitiveTypes);
-            for(GenericDataType eachPrimitive : primitiveTypes)
-            {
-            	KeyGenerator generator = KeyGeneratorFactory.getKeyGenerator(new int[]{-1});
-            	keyGenerators.put(eachPrimitive.getName(), generator);
-            }
-        }
+                
     }
 
     /**
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSchemaParser.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSchemaParser.java
index eb2b2d3..f472d30 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSchemaParser.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSchemaParser.java
@@ -35,10 +35,6 @@ import org.eigenbase.xom.Parser;
 import org.eigenbase.xom.XOMException;
 import org.eigenbase.xom.XOMUtil;
 
-import com.huawei.datasight.molap.datatypes.ArrayDataType;
-import com.huawei.datasight.molap.datatypes.GenericDataType;
-import com.huawei.datasight.molap.datatypes.PrimitiveDataType;
-import com.huawei.datasight.molap.datatypes.StructDataType;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.api.dataloader.SchemaInfo;
@@ -386,9 +382,7 @@ public final class MolapSchemaParser
                     
                     for(Level levels : hierarchy.levels)
                     {
-                    	if(levels.parentname != null)
-                    		continue;
-                    	if(foreignKeys.contains(levels.name))
+                        if(foreignKeys.contains(levels.name))
                         {
                             columns.append(levels.name);
                             columns.append(MolapCommonConstants.HASH_SPC_CHARACTER);
@@ -685,8 +679,6 @@ public final class MolapSchemaParser
                 {
                     for(Level level : hierarchy.levels)
                     {
-                    	if(level.parentname != null)
-                    		continue;
                         if(levelColumn.equals(level.column))
                         {
                             if(null != level.nameColumn)
@@ -734,8 +726,6 @@ public final class MolapSchemaParser
                 {
                     for(Level level : hierarchy.levels)
                     {
-                    	if(level.parentname != null)
-                    		continue;
                         if(levelColumn.equals(level.column))
                         {
                             if(null != level.nameColumn)
@@ -1129,8 +1119,6 @@ public final class MolapSchemaParser
                     Level[] levels = hierarchy.levels;
                     for(Level level : levels)
                     {
-                    	if(level.parentname != null)
-                    		continue;
                         query.append(System.getProperty("line.separator"));
                         if(counter!=0)
                         {
@@ -1183,14 +1171,9 @@ public final class MolapSchemaParser
                         : ((Table)hierarchy.relation).name;
                 // String tableName = hierarchy.relation.toString();
                 int i = hierarchy.levels.length;
-                boolean appendComma = true;
+
                 for(Level level : hierarchy.levels)
                 { //Added for Normalized hierarchy AR-UniBI-OLAP-003
-                	if(level.parentname != null)
-                	{
-                		appendComma = false;
-                		continue;
-                	}
                     if(hierarchy.normalized)
                     {
                         if(i==1)
@@ -1231,8 +1214,7 @@ public final class MolapSchemaParser
                     i--;
 
                 }
-                if(appendComma)
-                	dimString.append(MolapCommonConstants.COMA_SPC_CHARACTER);
+                dimString.append(MolapCommonConstants.COMA_SPC_CHARACTER);
             }
         }
 /*
@@ -1306,8 +1288,6 @@ public final class MolapSchemaParser
                 int counter=0;
                 for(Level level : hierarchy.levels)
                 {
-                	if(level.parentname != null)
-                		continue;
                     if(hierarchy.normalized)
                     {
                         if(counter==hierarchy.levels.length-1)
@@ -1365,8 +1345,6 @@ public final class MolapSchemaParser
                 : ((Table)hierarchy.relation).name;
         for(Level level : hierarchy.levels)
         {
-        	if(level.parentname != null)
-        		continue;
             cardinalities.put(tableName + '_' + level.column,
                     level.levelCardinality + "");
         }
@@ -1850,8 +1828,6 @@ public final class MolapSchemaParser
                 : ((Table)hierarchy.relation).name;
         for(Level level : hierarchy.levels)
         {
-        	if(level.parentname != null)
-        		continue;
             list.add(tableName + '_' + level.column);
 
 //            if(hasOrdinalColumn(level))
@@ -1887,8 +1863,6 @@ public final class MolapSchemaParser
         int counter = 0;
         for(Level level : hierarchy.levels)
         {
-        	if(level.parentname != null)
-        		continue;
         	if(hierarchy.normalized)
         	{
         		if(counter == hierarchy.levels.length-1)
@@ -1929,9 +1903,7 @@ public final class MolapSchemaParser
                         : ((Table)hierarchy.relation).name;
                 for(Level level : hierarchy.levels)
                 {
-                	if(level.parentname != null)
-                		continue;
-                    list.add(tableName + '_' + level.column);
+                        list.add(tableName + '_' + level.column);
                     //
                 }
             }
@@ -1941,59 +1913,41 @@ public final class MolapSchemaParser
         return fields;
     }
     
-    
     /**
+     * This method will give dimensions store type i.e either its columnar or row based
+     * e.g dimname!@#true
+     * it means dimension dimname is columnar store type
      * @param cube
+     * @param schema
      * @return
      */
-    public static Map<String,GenericDataType> getComplexDimensions(Cube cube,Schema schema)
-    {  
-    	MolapDef.CubeDimension[] dimensions = cube.dimensions;
-    	Map<String,GenericDataType> complexTypeMap = new HashMap<String,GenericDataType>();
-    	for(CubeDimension cDimension : dimensions)
-    	{
-    		//
-    		Hierarchy[] hierarchies = null;
-    		hierarchies = extractHierarchies(schema, cDimension);
-    		for(Hierarchy hierarchy : hierarchies)
-    		{
-    			if(hierarchy.levels.length > 1 && (hierarchy.levels[0].type.equals("Array") 
-    					|| hierarchy.levels[0].type.equals("Struct")))
-    			{
-    				Level levelZero = hierarchy.levels[0];
-    				GenericDataType g = levelZero.type.equals("Array")?
-    						new ArrayDataType(levelZero.name, ""):new StructDataType(levelZero.name, "");
-    				complexTypeMap.put(levelZero.name, g);
-    				boolean isFirst = true;
-	    			for(Level level : hierarchy.levels)
-	    			{
-	    				if(isFirst)
-	    				{
-	    					isFirst = false;
-	    					continue;
-	    				}
-	    				else
-	    				{
-		    				switch(level.type)
-		    				{
-		    					case "Array" : 
-		    						g.addChildren(new ArrayDataType(level.name, level.parentname));
-		    						break;
-		    					case "Struct" : 
-		    						g.addChildren(new StructDataType(level.name, level.parentname));
-		    						break;
-		    					default :
-		    						g.addChildren(new PrimitiveDataType(level.name, level.parentname));
-		    				}
-	    				}
-	    			}
-    			}
-    		}
-    	}
-    	return complexTypeMap;
+    public static String getDimensionsStoreType(Cube cube,Schema schema)
+    {
+    	StringBuffer buffer =new StringBuffer();
+         MolapDef.CubeDimension[] dimensions = cube.dimensions;
+         int dimCounter=0;
+         for(CubeDimension cDimension : dimensions)
+         {
+             //
+             Hierarchy[] hierarchies = null;
+             hierarchies = extractHierarchies(schema, cDimension);
+             for(Hierarchy hierarchy : hierarchies)
+             {
+                 for(Level level : hierarchy.levels)
+                 {
+                	// buffer.append(level.column+"!@#"+level.columnar);
+                	 buffer.append(level.columnar);
+                     //
+                 }
+             }
+             if(dimCounter<dimensions.length-1)
+             {
+            	 buffer.append(",");	 
+             }
+             dimCounter++;
+         }
+        return buffer.toString();
     }
-    
-    
     /**
      * @param cube
      * @return
@@ -2283,8 +2237,6 @@ private static String getDimensionTable(String dimName, String hierName, String
                 {
                     for(Level levels : hierarchy.levels)
                     {
-                    	if(levels.parentname != null)
-                    		continue;
                         if(levelName.equals(levels.name))
                         {
                             RelationOrJoin relation = hierarchy.relation;
@@ -2327,8 +2279,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                 {
                     for(Level levels : hierarchy.levels)
                     {
-                    	if(levels.parentname != null)
-                    		continue;
                         if(levelName.equals(levels.name))
                         {
                             RelationOrJoin relation = hierarchy.relation;
@@ -2388,8 +2338,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
     {
         for(Level level : hierarchy.levels)
         {
-        	if(level.parentname != null)
-        		continue;
             boolean levelAdded = false;
 
             // First is ordinal column
@@ -2477,8 +2425,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                 builder.append(dimName+'_'+heirName+".hierarchy");
                 for(Level level : hierarchy.levels)
                 {
-                	if(level.parentname != null)
-                		continue;
                     cardinalityList.add(level.levelCardinality);
                 }
                 for(int i = 0;i < cardinalityList.size();i++)
@@ -2522,8 +2468,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                 {
                     for(Level level : hierarchy.levels)
                     {
-                    	if(level.parentname != null)
-                    		continue;
                         cardinalityList.add(level.levelCardinality);
                     }
                 }
@@ -2620,8 +2564,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
         propString.append(MolapCommonConstants.SEMICOLON_SPC_CHARACTER);
         for(Level level : hierarchy.levels)
         {
-        	if(level.parentname != null)
-        		continue;
             String levelType = level.levelType;
             if(LevelType.TimeYears.name().equals(levelType))
             {
@@ -2680,8 +2622,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
         propString.append(MolapCommonConstants.COLON_SPC_CHARACTER);
         for(Level level : hierarchy.levels)
         {
-        	if(level.parentname != null)
-        		continue;
             propString.append(tableName + '_' + level.column);
 
             // First is ordinal column
@@ -2749,8 +2689,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                 {
                     for(Level level : hierarchy.levels)
                     {
-                    	if(level.parentname != null)
-                    		continue;
                         if(levelColumn.equals(level.column))
                         {
                             if(level.nameColumn != null
@@ -2858,8 +2796,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                 {
                 for(Level level :  hierarchy.levels)
                 {
-                	if(level.parentname != null)
-                		continue;
                     cardinalityList.add(level.levelCardinality);
                 }
                 }
@@ -2944,8 +2880,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                 heirName = heirName.replaceAll(" ", "_");
                 for(Level level : hierarchy.levels)
                 {
-                	if(level.parentname != null)
-                		continue;
                     cardinalityList.add(level.levelCardinality);
                 }
                 dims = new int[cardinalityList.size()];
@@ -3011,8 +2945,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                     // {
                     for(Level level : hierarchy.levels)
                     {
-                    	if(level.parentname != null)
-                    		continue;
 
                         localString.append(level.column);
 
@@ -3588,8 +3520,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
                 {
                     for(Level level : hierarchy.levels)
                     {
-                    	if(level.parentname != null)
-                    		continue;
                         actualDim.append(level.column);
                     actualDim.append(MolapCommonConstants.AMPERSAND_SPC_CHARACTER);
                     }
@@ -3778,8 +3708,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
             {
                 for(Level level:hier.levels)
                 {
-                	if(level.parentname != null)
-                		continue;
                     ordinalMap.put(dim.name+'_'+hier.name+'_'+level.name, count++);
                 }
             }
@@ -3801,8 +3729,6 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
         // CHECKSTYLE:OFF Approval No:V3R8C00_002
         for(Level level:hier.levels)
         {// CHECKSTYLE:ON
-        	if(level.parentname != null)
-        		continue;
             cardinalities[index++]=level.levelCardinality;
         }
         return cardinalities;
@@ -3845,61 +3771,12 @@ private static String getDimensionTable(String dimName, String levelName, Cube c
 
                 for(Level level : hierarchy.levels)
                 { // Added for Normalized hierarchy AR-UniBI-OLAP-003
-                	String levelName = tableName + '_' + level.column;
-                    dimString.append(levelName+MolapCommonConstants.LEVEL_FILE_EXTENSION
+
+                    dimString.append(tableName + '_' + level.column+MolapCommonConstants.LEVEL_FILE_EXTENSION
                             + MolapCommonConstants.COLON_SPC_CHARACTER
-                            + level.type
-                            + MolapCommonConstants.HASH_SPC_CHARACTER);
+                            + level.type);
                 }
-            }
-        }
-        return dimString.toString();
-    }
-    
-    /**
-     * Below method will be used to get the level and its data type string
-     * @param dimensions
-     * @param schema
-     * @param cube
-     * @return String
-     */
-    public static String getLevelDataTypeAndParentMapString(Cube cube, Schema schema)
-    {
-        StringBuilder dimString= new StringBuilder();
-        MolapDef.CubeDimension[] dimensions = cube.dimensions;
-        for(CubeDimension cDimension : dimensions)
-        {
-            Hierarchy[] hierarchies =  null;
-            hierarchies = extractHierarchies(schema, cDimension);
-            for(Hierarchy hierarchy : hierarchies)
-            {
-            	if(hierarchy.levels.length > 1 && (hierarchy.levels[0].type.equals("Array") 
-    					|| hierarchy.levels[0].type.equals("Struct")))
-    			{
-    				Level levelZero = hierarchy.levels[0];
-    				boolean isFirst = true;
-    				dimString.append(levelZero.name
-                            + MolapCommonConstants.COLON_SPC_CHARACTER
-                            + levelZero.type
-                            + MolapCommonConstants.COLON_SPC_CHARACTER
-                            + ""
-                            + MolapCommonConstants.HASH_SPC_CHARACTER);
-	                for(Level level : hierarchy.levels)
-	                { 
-	                	if(isFirst)
-	                	{
-	                		isFirst = false;
-	                		continue;
-	                	}
-	                    dimString.append(level.name
-	                            + MolapCommonConstants.COLON_SPC_CHARACTER
-	                            + level.type
-	                            + MolapCommonConstants.COLON_SPC_CHARACTER
-	                            + level.parentname
-	                            + MolapCommonConstants.HASH_SPC_CHARACTER);
-	                }
-	                dimString.append(MolapCommonConstants.SEMICOLON_SPC_CHARACTER);
-    			}
+                dimString.append(MolapCommonConstants.HASH_SPC_CHARACTER);
             }
         }
         return dimString.toString();
diff --git a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java
index 63a779a..de97fb5 100644
--- a/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java
+++ b/Molap/Molap-Data-Processor/src/com/huawei/unibi/molap/util/MolapSliceAndFiles.java
@@ -1,7 +1,6 @@
 package com.huawei.unibi.molap.util;
 
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
-import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 
 public class MolapSliceAndFiles
 {
@@ -15,8 +14,6 @@ public class MolapSliceAndFiles
      */
     private MolapFile[] sliceFactFilesList;
     
-    private KeyGenerator keyGen;
-    
     /**
      * This method will return the slice path
      * 
@@ -60,21 +57,4 @@ public class MolapSliceAndFiles
     {
         this.sliceFactFilesList = sliceFactFilesList;
     }
-
-    /**
-     * @return the keyGen
-     */
-    public KeyGenerator getKeyGen()
-    {
-        return keyGen;
-    }
-
-    /**
-     * @param keyGen the keyGen to set
-     */
-    public void setKeyGen(KeyGenerator keyGen)
-    {
-        this.keyGen = keyGen;
-    }
-
 }
diff --git a/Molap/Molap-Engine/.settings/org.eclipse.jdt.core.prefs b/Molap/Molap-Engine/.settings/org.eclipse.jdt.core.prefs
index 2a6d964..574fe12 100644
--- a/Molap/Molap-Engine/.settings/org.eclipse.jdt.core.prefs
+++ b/Molap/Molap-Engine/.settings/org.eclipse.jdt.core.prefs
@@ -1,14 +1,4 @@
 eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.7
-org.eclipse.jdt.core.compiler.codegen.unusedLocal=preserve
-org.eclipse.jdt.core.compiler.compliance=1.7
-org.eclipse.jdt.core.compiler.debug.lineNumber=generate
-org.eclipse.jdt.core.compiler.debug.localVariable=generate
-org.eclipse.jdt.core.compiler.debug.sourceFile=generate
-org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
-org.eclipse.jdt.core.compiler.problem.enumIdentifier=error
-org.eclipse.jdt.core.compiler.source=1.7
 org.eclipse.jdt.core.formatter.align_type_members_on_columns=false
 org.eclipse.jdt.core.formatter.alignment_for_arguments_in_allocation_expression=16
 org.eclipse.jdt.core.formatter.alignment_for_arguments_in_annotation=0
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/cache/QueryExecutorUtil.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/cache/QueryExecutorUtil.java
index 64faaa5..59c2183 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/cache/QueryExecutorUtil.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/cache/QueryExecutorUtil.java
@@ -13,6 +13,7 @@ package com.huawei.unibi.molap.engine.cache;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
@@ -40,6 +41,7 @@ import com.huawei.unibi.molap.metadata.MolapMetadata.Cube;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 //import mondrian.rolap.SqlStatement;
 import com.huawei.unibi.molap.olap.SqlStatement;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 /**
  * Util class
@@ -2488,7 +2490,7 @@ public final class QueryExecutorUtil
      * @param integers
      * @return
      */
-    public static int[] convertIntegerListToIntArray(List<Integer> integers)
+    public static int[] convertIntegerListToIntArray(Collection<Integer> integers)
     {
         int[] ret = new int[integers.size()];
         Iterator<Integer> iterator = integers.iterator();
@@ -2513,26 +2515,14 @@ public final class QueryExecutorUtil
         for(int i = 0;i < queryDimensions.length;i++)
         {
 
-            
-			if(queryDimensions[i].isHighCardinalityDim())
-            {
-                continue;
-            }
-			else if(queryDimensions[i].getDataType() == SqlStatement.Type.ARRAY)
+            if(queryDimensions[i].isHighCardinalityDim())
             {
                 continue;
             }
-            else if(queryDimensions[i].getDataType() == SqlStatement.Type.STRUCT)
-                continue;
-            else if(queryDimensions[i].getParentName() != null)
-                continue;
-            else
+            int[] range = generator.getKeyByteOffsets(queryDimensions[i].getOrdinal());
+            for(int j = range[0];j <= range[1];j++)
             {
-                int[] range = generator.getKeyByteOffsets(queryDimensions[i].getOrdinal());
-                for(int j = range[0];j <= range[1];j++)
-                {
-                    integers.add(j);
-                }
+                integers.add(j);
             }
 
         }
@@ -2548,6 +2538,61 @@ public final class QueryExecutorUtil
         return byteIndexs;
     }
     
+    public static int[] getMaskedByte(Dimension[] queryDimensions, KeyGenerator generator,HybridStoreModel hybridStoreModel)
+    {
+
+        Set<Integer> integers = new TreeSet<Integer>();
+        boolean isRowAdded=false;
+        //
+        for(int i = 0;i < queryDimensions.length;i++)
+        {
+            if(queryDimensions[i].isHighCardinalityDim())
+            {
+                continue;
+            }
+            //if querydimension is row store based, than add all row store ordinal in mask, because row store ordinal rangesare overalapped
+            //for e.g its possible
+            //dimension1 range: 0-1
+            //dimension2 range: 1-2
+            //hence to read only dimension2, you have to mask dimension1 also
+            if(!queryDimensions[i].isColumnar())
+            {
+                //if all row store ordinal is already added in range than no need to consider it again
+                if(!isRowAdded)
+                {
+                    isRowAdded=true;
+                    int[] rowOrdinals=hybridStoreModel.getRowStoreOrdinals();
+                    for(int r=0;r<rowOrdinals.length;r++)
+                    {
+                        int[] range = generator
+                                .getKeyByteOffsets(hybridStoreModel.getMdKeyOrdinal(rowOrdinals[r]));
+                        for(int j = range[0];j <= range[1];j++)
+                        {
+                            integers.add(j);
+                        }
+                        
+                    }
+                }
+                continue;
+                
+            }
+            int[] range = generator
+                    .getKeyByteOffsets(hybridStoreModel.getMdKeyOrdinal(queryDimensions[i].getOrdinal()));
+            for(int j = range[0];j <= range[1];j++)
+            {
+                integers.add(j);
+            }
+
+        }
+        //
+        int[] byteIndexs = convertIntegerListToIntArray(integers);
+        return byteIndexs;
+    }
+    
+    
+    
+    
+    
     /**
      * getMaskedByte
      * @param queryDimensions
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/ColumnarAggregatorInfo.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/ColumnarAggregatorInfo.java
index 823fe2a..3a4f431 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/ColumnarAggregatorInfo.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/ColumnarAggregatorInfo.java
@@ -1,23 +1,14 @@
 package com.huawei.unibi.molap.engine.columnar.aggregator;
 
 import java.util.List;
-import java.util.Map;
 
 import com.huawei.unibi.molap.engine.aggregator.CustomMolapAggregateExpression;
 import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInfo;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 
 public class ColumnarAggregatorInfo
 {
-    private int queryDimensionsLength;
-    
-    private Map<Integer,GenericQueryType> complexQueryDims;
-    
-    private Dimension[] dimensions;
-    
     /**
      * slice
      */
@@ -160,37 +151,7 @@ public class ColumnarAggregatorInfo
     {
         this.countMsrIndex = countMsrIndex;
     }
-    
-    public void setQueryDimensionsLength(int queryDimensionsLength)
-    {
-        this.queryDimensionsLength = queryDimensionsLength;
-    }
-    
-    public int getQueryDimensionsLength()
-    {
-        return queryDimensionsLength;
-    }
-    
-    public Dimension[] getDimensions()
-    {
-        return dimensions;
-    }
-
-    public void setDimensions(Dimension[] dimensions)
-    {
-        this.dimensions = dimensions;
-    }
-
-    public Map<Integer, GenericQueryType> getComplexQueryDims()
-    {
-        return complexQueryDims;
-    }
 
-    public void setComplexQueryDims(Map<Integer, GenericQueryType> complexQueryDims)
-    {
-        this.complexQueryDims = complexQueryDims;
-    }
-    
     /**
      * @return the avgMsrIndexes
      */
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/ListBasedResultAggregatorImpl.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/ListBasedResultAggregatorImpl.java
index ced2f0e..a93d536 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/ListBasedResultAggregatorImpl.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/ListBasedResultAggregatorImpl.java
@@ -56,24 +56,12 @@ public class ListBasedResultAggregatorImpl implements ColumnarScannedResultAggre
         this.values = new ArrayList<MeasureAggregator[]>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
         ByteArrayWrapper key = null;
         MeasureAggregator[] value = null;
+        long startTime=System.currentTimeMillis();
         while(keyValue.hasNext() && (limit == -1 || rowCounter < limit))
         {
             key = new ByteArrayWrapper();
-            //Primitives types selected
-            if(columnaraggreagtorInfo.getQueryDimensionsLength() == keyValue.getKeyBlockLength())
-            {
-                key.setMaskedKey(keyValue.getKeyArray());
-            }
-            else
-            {
-                //Complex columns selected.
-                List<byte[]> complexKeyArray = keyValue.getKeyArrayWithComplexTypes(this.columnaraggreagtorInfo.getComplexQueryDims());
-                key.setMaskedKey(complexKeyArray.remove(complexKeyArray.size() - 1));
-                for(byte[] complexKey : complexKeyArray)
-                {
-                    key.addComplexTypeData(complexKey);
-                }
-            }
+            byte[] keyArray=keyValue.getKeyArray(key);
+            key.setMaskedKey(keyArray);
             value = AggUtil.getAggregators(columnaraggreagtorInfo.getAggType(), isAggTable, null,
                         columnaraggreagtorInfo.getCubeUniqueName(),columnaraggreagtorInfo.getMsrMinValue(),columnaraggreagtorInfo.getHighCardinalityTypes());
             dataAggregator.aggregateData(keyValue, value,key);
@@ -81,6 +69,8 @@ public class ListBasedResultAggregatorImpl implements ColumnarScannedResultAggre
             values.add(value);
             rowCounter++;
         }
+        long timeTaken=(System.currentTimeMillis()-startTime);
+        LOGGER.info(MolapEngineLogEvent.UNIBI_MOLAPENGINE_MSG, "Time taken to scan result:"+ timeTaken);
         return rowCounter;
     }
 
@@ -137,13 +127,10 @@ public class ListBasedResultAggregatorImpl implements ColumnarScannedResultAggre
                         updatedData[data.length+k]=restructureHolder.metaData.getNewDimsSurrogateKeys()[k];
                     }
                 }
-                if(restructureHolder.getQueryDimsCount() == columnaraggreagtorInfo.getLatestKeyGenerator().getDimCount())
-                {
-                    key.setMaskedKey(QueryExecutorUtility.getMaskedKey(columnaraggreagtorInfo.getLatestKeyGenerator()
+                key.setMaskedKey(QueryExecutorUtility.getMaskedKey(columnaraggreagtorInfo.getLatestKeyGenerator()
                         .generateKey(updatedData), columnaraggreagtorInfo.getActualMaxKeyBasedOnDimensions(),
                         columnaraggreagtorInfo.getActalMaskedByteRanges(), columnaraggreagtorInfo
                                 .getActualMaskedKeyByteSize()));
-                }
                 finalKeys.add(key);
                 finalValues.add(values.get(i));
             }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/MapBasedResultAggregatorImpl.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/MapBasedResultAggregatorImpl.java
index 28e7b85..c06d7f6 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/MapBasedResultAggregatorImpl.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/MapBasedResultAggregatorImpl.java
@@ -2,7 +2,6 @@ package com.huawei.unibi.molap.engine.columnar.aggregator.impl;
 
 import java.util.Arrays;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.Map.Entry;
 
@@ -62,25 +61,11 @@ public class MapBasedResultAggregatorImpl implements ColumnarScannedResultAggreg
     @Override
     public int aggregateData(AbstractColumnarScanResult keyValue)
     {
-        ByteArrayWrapper dimensionsRowWrapper = null;
         while(keyValue.hasNext())
         {
-            dimensionsRowWrapper = new ByteArrayWrapper();
-            //Primitives types selected
-            if(columnaraggreagtorInfo.getDimensionAggInfos().size() == keyValue.getKeyBlockLength())
-            {
-                dimensionsRowWrapper.setMaskedKey(keyValue.getKeyArray());
-            }
-            else
-            {
-                //Complex columns selected.
-                List<byte[]> complexKeyArray = keyValue.getKeyArrayWithComplexTypes(this.columnaraggreagtorInfo.getComplexQueryDims());
-                dimensionsRowWrapper.setMaskedKey(complexKeyArray.remove(complexKeyArray.size() - 1));
-                for(byte[] complexKey : complexKeyArray)
-                {
-                    dimensionsRowWrapper.addComplexTypeData(complexKey);
-                }
-            }
+            ByteArrayWrapper dimensionsRowWrapper = new ByteArrayWrapper(xxHash32);
+
+            dimensionsRowWrapper.setMaskedKey(keyValue.getKeyArray(dimensionsRowWrapper));
             MeasureAggregator[] currentMsrRowData = aggData.get(dimensionsRowWrapper);
             
             if(null == currentMsrRowData)
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/dimension/DimensionDataAggreagtor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/dimension/DimensionDataAggreagtor.java
index b7583aa..6b13a8c 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/dimension/DimensionDataAggreagtor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/aggregator/impl/dimension/DimensionDataAggreagtor.java
@@ -1,33 +1,23 @@
 package com.huawei.unibi.molap.engine.columnar.aggregator.impl.dimension;
 
-import java.io.ByteArrayOutputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
-import com.huawei.iweb.platform.logging.LogService;
-import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
 import com.huawei.unibi.molap.engine.aggregator.MeasureAggregator;
 import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInfo;
 import com.huawei.unibi.molap.engine.columnar.aggregator.ColumnarAggregatorInfo;
 import com.huawei.unibi.molap.engine.columnar.keyvalue.AbstractColumnarScanResult;
 import com.huawei.unibi.molap.engine.datastorage.Member;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.util.DataTypeConverter;
-import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
 import com.huawei.unibi.molap.engine.util.QueryExecutorUtility;
 import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.olap.SqlStatement;
-import com.huawei.unibi.molap.olap.SqlStatement.Type;
 
 public class DimensionDataAggreagtor
 {
-    private static final LogService LOGGER = LogServiceFactory.getLogService(DimensionDataAggreagtor.class.getName());
 
     private int[][] dimCountAndDistinctCountAGGIndex;
 
@@ -128,63 +118,32 @@ public class DimensionDataAggreagtor
             {
              dimSurrogate = keyValue.getDimDataForAgg(dimensionAggregatorInfo.getDim().getOrdinal());
             Object dataBasedOnDataType = null;
-            byte[] complexSurrogates = null;
-            GenericQueryType complexType = null;
-            if(dimensionAggregatorInfo.getDim().getDataType() != Type.ARRAY &&  dimensionAggregatorInfo.getDim().getDataType() != Type.STRUCT)
+            if(dimSurrogate==1)
             {
-                dimSurrogate = keyValue.getDimDataForAgg(dimensionAggregatorInfo.getDim().getOrdinal());
-                if(dimSurrogate==1)
-                {
-                    break;
-                }
-            }
-            else
-            {
-                try
-                {
-                    complexType = this.columnaraggreagtorInfo.getComplexQueryDims().get(dimensionAggregatorInfo.getDim().getOrdinal());
-                    ByteArrayOutputStream byteStream = new ByteArrayOutputStream();
-                    DataOutputStream dataOutputStream = new DataOutputStream(byteStream);
-                    keyValue.getComplexDimDataForAgg(complexType, dataOutputStream);
-                    complexSurrogates = byteStream.toByteArray();
-                    byteStream.close();
-                }
-                catch(IOException e)
-                {
-                    LOGGER.error(MolapEngineLogEvent.UNIBI_MOLAPENGINE_MSG, e);
-                }
+                break;
             }
             for(int j = 0;j < dimCountAndDistinctCountAGGIndex[i].length;j++)
             {
-                if(dimensionAggregatorInfo.getDim().getDataType() != Type.ARRAY &&  dimensionAggregatorInfo.getDim().getDataType() != Type.STRUCT)
+                if(dimensionAggregatorInfo.getDim().getDataType()!=SqlStatement.Type.STRING)
                 {
-                    if(dimensionAggregatorInfo.getDim().getDataType()!=SqlStatement.Type.STRING)
+                    if(null==dataBasedOnDataType)
                     {
-                        if(null==dataBasedOnDataType)
-                        {
-                            dataBasedOnDataType = QueryExecutorUtility
-                                    .getMemberBySurrogateKey(dimensionAggregatorInfo.getDim(), dimSurrogate,
-                                            columnaraggreagtorInfo.getSlices(), columnaraggreagtorInfo.getCurrentSliceIndex()).toString();
-                            dataBasedOnDataType = DataTypeConverter.getDataBasedOnDataType((String)dataBasedOnDataType,
-                                    dimensionAggregatorInfo.getDim().getDataType());
-                        }
-                        if(null!=dataBasedOnDataType)
-                        {
-                            currentMsrRowData[dimCountAndDistinctCountAGGIndex[i][j]].agg(dimSurrogate, null, 0, 0);
-                        }
+                        dataBasedOnDataType = QueryExecutorUtility
+                                .getMemberBySurrogateKey(dimensionAggregatorInfo.getDim(), dimSurrogate,
+                                        columnaraggreagtorInfo.getSlices(), columnaraggreagtorInfo.getCurrentSliceIndex()).toString();
+                        dataBasedOnDataType = DataTypeConverter.getDataBasedOnDataType((String)dataBasedOnDataType,
+                                dimensionAggregatorInfo.getDim().getDataType());
                     }
-                    else
+                    if(null!=dataBasedOnDataType)
                     {
                         currentMsrRowData[dimCountAndDistinctCountAGGIndex[i][j]].agg(dimSurrogate, null, 0, 0);
                     }
                 }
                 else
                 {
-                    currentMsrRowData[dimCountAndDistinctCountAGGIndex[i][j]].agg(complexSurrogates, null, 0, 0);
-                    dataBasedOnDataType = complexType.getDataBasedOnDataTypeFromSurrogates(this.columnaraggreagtorInfo.getSlices(), ByteBuffer.wrap(complexSurrogates), this.columnaraggreagtorInfo.getDimensions());
+                    currentMsrRowData[dimCountAndDistinctCountAGGIndex[i][j]].agg(dimSurrogate, null, 0, 0);
                 }
             }
-            
             for(int j = 0;j < dimAggNormalIndex[i].length;j++)
             {
                 if(dataBasedOnDataType== null)
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/AbstractColumnarDataStoreProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/AbstractColumnarDataStoreProcessor.java
index 9ad55e6..7017901 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/AbstractColumnarDataStoreProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/AbstractColumnarDataStoreProcessor.java
@@ -1,10 +1,14 @@
 package com.huawei.unibi.molap.engine.columnar.datastoreblockprocessor.impl;
 
+import com.huawei.iweb.platform.logging.LogService;
+import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
 import com.huawei.unibi.molap.engine.columnar.datastoreblockprocessor.ColumnarDataStoreBlockProcessorInfo;
 import com.huawei.unibi.molap.engine.columnar.datastoreblockprocessor.DataStoreBlockProcessor;
 import com.huawei.unibi.molap.engine.columnar.keyvalue.AbstractColumnarScanResult;
 import com.huawei.unibi.molap.engine.evaluators.BlockDataHolder;
+import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
+
 
 public abstract class AbstractColumnarDataStoreProcessor implements DataStoreBlockProcessor
 {
@@ -12,6 +16,9 @@ public abstract class AbstractColumnarDataStoreProcessor implements DataStoreBlo
     
     protected ColumnarDataStoreBlockProcessorInfo columnarDataStoreBlockInfo;
     
+    private static final LogService LOGGER = LogServiceFactory
+            .getLogService(AbstractColumnarDataStoreProcessor.class.getName());
+    
     public AbstractColumnarDataStoreProcessor(ColumnarDataStoreBlockProcessorInfo columnarDataStoreBlockInfo)
     {
         this.columnarDataStoreBlockInfo=columnarDataStoreBlockInfo;
@@ -23,13 +30,17 @@ public abstract class AbstractColumnarDataStoreProcessor implements DataStoreBlo
         keyValue.setMeasureBlock(blockDataHolder.getLeafDataBlock().getNodeMsrDataWrapper(columnarDataStoreBlockInfo.getAllSelectedMeasures(),
                 columnarDataStoreBlockInfo.getFileHolder()).getValues());
         keyValue.setNumberOfRows(blockDataHolder.getLeafDataBlock().getnKeys());
+        long startTime=System.currentTimeMillis();
         ColumnarKeyStoreDataHolder[] columnarKeyStore = blockDataHolder.getLeafDataBlock().getColumnarKeyStore(columnarDataStoreBlockInfo.getFileHolder(),
                 columnarDataStoreBlockInfo.getAllSelectedDimensions(), new boolean[columnarDataStoreBlockInfo.getAllSelectedDimensions().length]);
+        long timeTaken=(System.currentTimeMillis()-startTime);
+        LOGGER.info(MolapEngineLogEvent.UNIBI_MOLAPENGINE_MSG, "Time taken to read all data from store:"+ timeTaken);        
         ColumnarKeyStoreDataHolder[] temp = new  ColumnarKeyStoreDataHolder[columnarDataStoreBlockInfo.getTotalNumberOfDimension()];
         for(int i = 0;i < columnarDataStoreBlockInfo.getAllSelectedDimensions().length;i++)
         {
             temp[columnarDataStoreBlockInfo.getAllSelectedDimensions()[i]]=columnarKeyStore[i];
         }
+        
         keyValue.setKeyBlock(temp);
     }
     
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/FilterDataStoreProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/FilterDataStoreProcessor.java
index 2064691..708b2d5 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/FilterDataStoreProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/datastoreblockprocessor/impl/FilterDataStoreProcessor.java
@@ -4,6 +4,7 @@ import java.util.BitSet;
 
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
+import com.huawei.unibi.molap.datastorage.store.KeyStoreDataHolder;
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
 import com.huawei.unibi.molap.datastorage.store.dataholder.MolapReadDataHolder;
 import com.huawei.unibi.molap.engine.columnar.datastoreblockprocessor.ColumnarDataStoreBlockProcessorInfo;
@@ -46,6 +47,7 @@ public class FilterDataStoreProcessor extends AbstractColumnarDataStoreProcessor
         {
             isMinMaxEnabled=Boolean.parseBoolean(minMaxEnableValue);
         }
+        isMinMaxEnabled=false;
         if(isMinMaxEnabled)
         {
             BitSet bitSet = filterEvaluatorTree.isScanRequired(blockDataHolder.getLeafDataBlock().getBlockMaxData(), blockDataHolder.getLeafDataBlock().getBlockMinData());
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/AbstractColumnarScanResult.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/AbstractColumnarScanResult.java
index 26bc9f2..6058b7d 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/AbstractColumnarScanResult.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/AbstractColumnarScanResult.java
@@ -1,26 +1,14 @@
 package com.huawei.unibi.molap.engine.columnar.keyvalue;
 
-import java.io.ByteArrayOutputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
 import java.util.Map;
-
-import com.huawei.iweb.platform.logging.LogService;
-import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
 import com.huawei.unibi.molap.datastorage.store.dataholder.MolapReadDataHolder;
 import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
-import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.util.ByteUtil;
 
 public abstract class AbstractColumnarScanResult
 {
-    private static final LogService LOGGER = LogServiceFactory.getLogService(AbstractColumnarScanResult.class.getName());
-    
     private int totalNumberOfRows;
 
     protected int currentRow = -1;
@@ -33,9 +21,9 @@ public abstract class AbstractColumnarScanResult
 
     protected MolapReadDataHolder[] measureBlocks;
 
-    private int rowCounter;
+    protected int rowCounter;
 
-    private int[] selectedDimensionIndex;
+    protected int[] selectedDimensionIndex;
 
     protected ColumnarKeyStoreDataHolder[] columnarKeyStoreDataHolder;
 
@@ -50,11 +38,6 @@ public abstract class AbstractColumnarScanResult
     {
         this.columnarKeyStoreDataHolder = columnarKeyStoreDataHolder;
     }
-    
-    public int getKeyBlockLength()
-    {
-        return columnarKeyStoreDataHolder.length;
-    }
 
     public void setMeasureBlock(MolapReadDataHolder[] measureBlocks)
     {
@@ -97,7 +80,21 @@ public abstract class AbstractColumnarScanResult
                 updateByteArrayWithDirectSurrogateKeyVal(keyVal,columnIndex,columnarKeyStoreDataHolder[selectedDimensionIndex[i]]);
                 continue;
             }
-            if(!columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().isSorted())
+            if(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().isRowStore())
+            {
+                //handleRowStore(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getKeyBlockData(),columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().getEachRowSize(),row);
+                System.arraycopy(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getKeyBlockData(), ((columnIndex) * columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().getEachRowSize()), completeKeyArray, destinationPosition,
+                        columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().getEachRowSize());
+                
+            }
+            else if(!columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().isSorted())
+            {
+                //handleRowStore(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getKeyBlockData(),columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().getEachRowSize(),row);
+                System.arraycopy(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getKeyBlockData(), ((columnIndex) * columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().getEachRowSize()), completeKeyArray, destinationPosition,
+                        columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().getEachRowSize());
+                
+            }
+            else if(!columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().isSorted())
             {
                 System.arraycopy(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getKeyBlockData(),
                         columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata()
@@ -176,84 +173,11 @@ public abstract class AbstractColumnarScanResult
         return completeKeyArray;
     }
 
-    protected List<byte[]> getKeyArrayWithComplexTypes(int columnIndex, Map<Integer, GenericQueryType> complexQueryDims)
-    {
-//        byte[] completeKeyArray = new byte[keySize];
-//        int destinationPosition = 0;
-        int keyArrayLength = 0;
-        List<byte[]> completeComplexKey = new ArrayList<byte[]>();
-        List<byte[]> completePrimitiveKey = new ArrayList<byte[]>();
-        for(int i = 0;i < selectedDimensionIndex.length;i++)
-        {
-            GenericQueryType complexType = complexQueryDims.get(selectedDimensionIndex[i]);
-            if(complexType == null)
-            {
-                byte[] currentColBytes = new byte[columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata()
-                                                  .getEachRowSize()];
-                if(!columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata().isSorted())
-                {
-                    System.arraycopy(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getKeyBlockData(),
-                            columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata()
-                            .getColumnReverseIndex()[columnIndex]
-                                    * columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata()
-                                    .getEachRowSize(), currentColBytes, 0,
-                                    columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata()
-                                    .getEachRowSize());
-                }
-                else
-                {
-                    
-                    System.arraycopy(columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getKeyBlockData(), columnIndex
-                            * columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata()
-                            .getEachRowSize(), currentColBytes, 0,
-                            columnarKeyStoreDataHolder[selectedDimensionIndex[i]].getColumnarKeyStoreMetadata()
-                            .getEachRowSize());
-                }
-                completePrimitiveKey.add(currentColBytes);
-                keyArrayLength += currentColBytes.length;
-            }
-            else
-            {
-                try
-                {
-                    ByteArrayOutputStream byteStream = new ByteArrayOutputStream();
-                    DataOutputStream dataOutput = new DataOutputStream(byteStream);
-                    complexType.parseBlocksAndReturnComplexColumnByteArray(columnarKeyStoreDataHolder, columnIndex, dataOutput);
-                    completeComplexKey.add(byteStream.toByteArray());
-//                    keyArrayLength += byteStream.toByteArray().length;
-                    byteStream.close();
-                }
-                catch(IOException e)
-                {
-                    LOGGER.error(MolapEngineLogEvent.UNIBI_MOLAPENGINE_MSG, e);
-                }
-                i += (complexType.getColsCount() - 1);
-            }
-        }
-        byte[] completeKeyArray = new byte[keyArrayLength];
-        int l=0;
-        for(byte[] key : completePrimitiveKey)
-        {
-            for(int i=0;i<key.length;i++)
-            {
-                completeKeyArray[l++] = key[i];
-            }
-        }
-        completeComplexKey.add(completeKeyArray);
-        rowCounter++;
-        return completeComplexKey;
-    }
-
     protected int getSurrogateKey(int index, int dimOrdinal)
     {
         return columnarKeyStoreDataHolder[dimOrdinal].getSurrogateKey(index);
     }
     
-    protected void getComplexSurrogateKey(int index, GenericQueryType complexType, DataOutputStream dataOutputStream) throws IOException
-    {
-        complexType.parseBlocksAndReturnComplexColumnByteArray(columnarKeyStoreDataHolder, index, dataOutputStream);
-    }
-    
     public int getNotNullCount(byte[] notNullByteArray, Dimension dim)
     {
         int start=ByteUtil.UnsafeComparer.INSTANCE.compareTo(
@@ -281,13 +205,10 @@ public abstract class AbstractColumnarScanResult
 
     public abstract byte[] getKeyArray(ByteArrayWrapper key);
     public abstract byte[] getKeyArray();
-
-    public abstract List<byte[]> getKeyArrayWithComplexTypes(Map<Integer, GenericQueryType> complexQueryDims);
     
     public abstract int getDimDataForAgg(int dimOrdinal);
 
     public abstract byte[] getHighCardinalityDimDataForAgg(Dimension dimension);
-    public abstract void getComplexDimDataForAgg(GenericQueryType complexType, DataOutputStream dataOutputStream) throws IOException;
 
 
 
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/FilterScanResult.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/FilterScanResult.java
index 03e3a38..224285c 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/FilterScanResult.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/FilterScanResult.java
@@ -1,8 +1,5 @@
 package com.huawei.unibi.molap.engine.columnar.keyvalue;
 
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.util.List;
 import java.util.Map;
 
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreMetadata;
@@ -10,9 +7,6 @@ import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 
 
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
-
-
 public class FilterScanResult extends AbstractColumnarScanResult
 {
     public FilterScanResult(int keySize, int[] selectedDimensionIndex) 
@@ -35,11 +29,6 @@ public class FilterScanResult extends AbstractColumnarScanResult
         ++currentRow;
         return getKeyArray(rowMapping[++sourcePosition],key);
     }
-    public List<byte[]> getKeyArrayWithComplexTypes(Map<Integer, GenericQueryType> complexQueryDims)
-    {
-        ++currentRow;
-        return getKeyArrayWithComplexTypes(rowMapping[++sourcePosition], complexQueryDims);
-    }
 
     @Override
     public int getDimDataForAgg(int dimOrdinal)
@@ -72,10 +61,4 @@ public class FilterScanResult extends AbstractColumnarScanResult
         return null;
 
     }
-    
-    @Override
-    public void getComplexDimDataForAgg(GenericQueryType complexType, DataOutputStream dataOutputStream) throws IOException
-    {
-        getComplexSurrogateKey(rowMapping[currentRow], complexType, dataOutputStream);
-    }
 }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/NonFilterScanResult.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/NonFilterScanResult.java
index 7e63a5e..5c34cbf 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/NonFilterScanResult.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/columnar/keyvalue/NonFilterScanResult.java
@@ -1,14 +1,10 @@
 package com.huawei.unibi.molap.engine.columnar.keyvalue;
 
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.util.List;
 import java.util.Map;
 
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreMetadata;
 import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 
 
 
@@ -32,12 +28,6 @@ public class NonFilterScanResult extends AbstractColumnarScanResult
         ++currentRow;
         return getKeyArray(++sourcePosition,keyVal);
     }
-
-    public List<byte[]> getKeyArrayWithComplexTypes(Map<Integer, GenericQueryType> complexQueryDims)
-    {
-        ++currentRow;
-        return getKeyArrayWithComplexTypes(++sourcePosition, complexQueryDims);
-    }
     
     
     
@@ -76,10 +66,4 @@ public class NonFilterScanResult extends AbstractColumnarScanResult
    
     
 
-    @Override
-    public void getComplexDimDataForAgg(GenericQueryType complexType, DataOutputStream dataOutputStream)
-            throws IOException
-    {
-        getComplexSurrogateKey(currentRow, complexType, dataOutputStream);
-    }
 }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/ArrayQueryType.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/ArrayQueryType.java
deleted file mode 100644
index 8ede4cd..0000000
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/ArrayQueryType.java
+++ /dev/null
@@ -1,219 +0,0 @@
-package com.huawei.unibi.molap.engine.complex.querytypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.List;
-
-import org.apache.spark.sql.types.ArrayType;
-import org.apache.spark.sql.types.DataType;
-import org.apache.spark.sql.types.GenericArrayData;
-
-import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
-import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
-import com.huawei.unibi.molap.engine.evaluators.BlockDataHolder;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
-
-public class ArrayQueryType implements GenericQueryType {
-	
-	private GenericQueryType children;
-	
-	private String name;
-	
-	private String parentname;
-	
-	private int blockIndex;
-	
-	private int keyOrdinalForQuery;
-
-	@Override
-	public void addChildren(GenericQueryType children) {
-		if(this.getName().equals(children.getParentname()))
-		{
-			this.children = children;
-		}
-		else
-		{
-			this.children.addChildren(children);
-		}
-	}
-	
-	public ArrayQueryType(String name, String parentname, int blockIndex)
-	{
-		this.name = name;
-		this.parentname = parentname;
-		this.blockIndex = blockIndex;
-	}
-	
-	@Override
-	public void setName(String name) {
-		this.name = name;
-	}
-	
-	@Override
-	public String getName() {
-		return name;
-	}
-	
-	@Override
-	public void setParentname(String parentname) {
-		this.parentname = parentname;
-		
-	}
-
-	@Override
-	public String getParentname() {
-		return parentname;
-	}
-	
-	@Override
-	public void getAllPrimitiveChildren(List<GenericQueryType> primitiveChild) {
-		if (children instanceof PrimitiveQueryType) 
-		{
-			primitiveChild.add(children);
-		}
-		else
-		{
-			children.getAllPrimitiveChildren(primitiveChild);
-		}
-	}
-	
-	
-	@Override
-	public int getSurrogateIndex() {
-		return 0;
-	}
-
-	@Override
-	public void setSurrogateIndex(int surrIndex) {
-		
-	}
-	
-	@Override
-	public int getBlockIndex()
-    {
-        return blockIndex;
-    }
-	
-	@Override
-    public void setBlockIndex(int blockIndex)
-    {
-        this.blockIndex = blockIndex;
-    }
-	
-	@Override
-	public int getColsCount() {
-		return children.getColsCount() + 1;
-	}
-	
-    @Override
-    public void parseBlocksAndReturnComplexColumnByteArray(ColumnarKeyStoreDataHolder[] columnarKeyStoreDataHolder, int rowNumber, DataOutputStream dataOutputStream) throws IOException
-    {
-        byte[] input = new byte[8];
-        if(!columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata().isSorted())
-        {
-            System.arraycopy(columnarKeyStoreDataHolder[blockIndex].getKeyBlockData(),
-                    columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                    .getColumnReverseIndex()[rowNumber]
-                            * columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                            .getEachRowSize(), input, 0,
-                            columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                            .getEachRowSize());
-        }
-        else
-        {
-            
-            System.arraycopy(columnarKeyStoreDataHolder[blockIndex].getKeyBlockData(), rowNumber
-                    * columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                    .getEachRowSize(), input, 0,
-                    columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                    .getEachRowSize());
-        }
-        
-        ByteBuffer byteArray = ByteBuffer.wrap(input);
-        int dataLength = byteArray.getInt();
-        dataOutputStream.writeInt(dataLength);
-        if(dataLength == 0)
-        {
-//            b.putInt(0);
-        }
-        else
-        {
-            int columnIndex = byteArray.getInt();
-            for(int i=0;i<dataLength;i++)
-            {
-                children.parseBlocksAndReturnComplexColumnByteArray(columnarKeyStoreDataHolder, columnIndex++, dataOutputStream);
-            }
-        }
-    }
-    
-    @Override
-    public void parseAndGetResultBytes(ByteBuffer complexData, DataOutputStream dataOutput) throws IOException
-    {
-        int dataLength = complexData.getInt();
-        dataOutput.writeInt(dataLength);
-        for(int i=0;i<dataLength;i++)
-        {
-            children.parseAndGetResultBytes(complexData, dataOutput);
-        }
-    }
-
-    @Override
-    public void setKeySize(int[] keyBlockSize)
-    {
-        children.setKeySize(keyBlockSize);        
-    }
-
-    @Override
-    public Object getDataBasedOnDataTypeFromSurrogates(List<InMemoryCube> slices, ByteBuffer surrogateData, Dimension[] dimensions)
-    {
-        int dataLength = surrogateData.getInt();
-        Object[] data = new Object[dataLength];
-        for(int i=0;i<dataLength;i++)
-        {
-            data[i] = children.getDataBasedOnDataTypeFromSurrogates(slices, surrogateData, dimensions);
-        }
-        return new GenericArrayData(data);
-    }
-    
-    @Override
-    public DataType getSchemaType()
-    {
-        return new ArrayType(children.getSchemaType(), true);
-    }
-    
-    @Override
-    public void setKeyOrdinalForQuery(int keyOrdinalForQuery)
-    {
-        this.keyOrdinalForQuery = keyOrdinalForQuery;
-    }
-
-    @Override
-    public int getKeyOrdinalForQuery()
-    {
-        return keyOrdinalForQuery;
-    }
-    
-    @Override
-    public void fillRequiredBlockData(BlockDataHolder blockDataHolder)
-    {
-        if(null==blockDataHolder.getColumnarKeyStore()[blockIndex])
-        {
-            blockDataHolder.getColumnarKeyStore()[blockIndex] = blockDataHolder
-                    .getLeafDataBlock().getColumnarKeyStore(blockDataHolder.getFileHolder(),
-                            blockIndex,
-                            false);
-        }
-        else
-        {
-            if(!blockDataHolder.getColumnarKeyStore()[blockIndex]
-                    .getColumnarKeyStoreMetadata().isUnCompressed())
-            {
-                blockDataHolder.getColumnarKeyStore()[blockIndex].unCompress();
-            }
-        }
-        
-        children.fillRequiredBlockData(blockDataHolder);
-    }
-
-}
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/GenericQueryType.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/GenericQueryType.java
deleted file mode 100644
index 254edde..0000000
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/GenericQueryType.java
+++ /dev/null
@@ -1,55 +0,0 @@
-package com.huawei.unibi.molap.engine.complex.querytypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.List;
-
-import org.apache.spark.sql.types.DataType;
-
-import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
-import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
-import com.huawei.unibi.molap.engine.evaluators.BlockDataHolder;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
-
-public interface GenericQueryType {
-	
-	void setName(String name);
-	
-	String getName();
-
-	void setParentname(String parentname);
-	
-	String getParentname();
-	
-	void setBlockIndex(int blockIndex);
-	
-	int getBlockIndex();
-	
-	void addChildren(GenericQueryType children);
-	
-	void getAllPrimitiveChildren(List<GenericQueryType> primitiveChild);
-	
-	int getSurrogateIndex();
-	
-	void setSurrogateIndex(int surrIndex);
-	
-	int getColsCount();
-	
-	void setKeySize(int[] keyBlockSize);
-	
-	void setKeyOrdinalForQuery(int keyOrdinalForQuery);
-	
-	int getKeyOrdinalForQuery();
-	
-	void parseBlocksAndReturnComplexColumnByteArray(ColumnarKeyStoreDataHolder[] columnarKeyStoreDataHolder, int rowNumber, DataOutputStream dataOutputStream) throws IOException;
-	
-	DataType getSchemaType();
-	
-	Object getDataBasedOnDataTypeFromSurrogates(List<InMemoryCube> slices, ByteBuffer surrogateData, Dimension[] dimensions);
-	
-	void parseAndGetResultBytes(ByteBuffer complexData, DataOutputStream dataOutput) throws IOException;
-	
-	void fillRequiredBlockData(BlockDataHolder blockDataHolder);
-	
-}
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/PrimitiveQueryType.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/PrimitiveQueryType.java
deleted file mode 100644
index 699e79f..0000000
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/PrimitiveQueryType.java
+++ /dev/null
@@ -1,212 +0,0 @@
-package com.huawei.unibi.molap.engine.complex.querytypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.math.BigInteger;
-import java.nio.ByteBuffer;
-import java.nio.charset.Charset;
-import java.util.List;
-
-import org.apache.spark.sql.types.BooleanType;
-import org.apache.spark.sql.types.DataType;
-import org.apache.spark.sql.types.DoubleType;
-import org.apache.spark.sql.types.IntegerType;
-import org.apache.spark.sql.types.LongType;
-import org.apache.spark.sql.types.StringType;
-import org.apache.spark.sql.types.TimestampType;
-import org.apache.spark.unsafe.types.UTF8String;
-
-import com.huawei.unibi.molap.constants.MolapCommonConstants;
-import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
-import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
-import com.huawei.unibi.molap.engine.evaluators.BlockDataHolder;
-import com.huawei.unibi.molap.engine.util.DataTypeConverter;
-import com.huawei.unibi.molap.engine.util.QueryExecutorUtility;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
-import com.huawei.unibi.molap.olap.SqlStatement;
-
-public class PrimitiveQueryType implements GenericQueryType {
-
-	private int index;
-	
-	private String name;
-	private String parentname;
-	
-	private int keySize;
-	
-	private int blockIndex;
-	
-	private SqlStatement.Type dataType;
-	
-	public PrimitiveQueryType(String name, String parentname, int blockIndex, SqlStatement.Type dataType)
-	{
-		this.name = name;
-		this.parentname = parentname;
-		this.blockIndex = blockIndex;
-		this.dataType = dataType;
-	}
-	
-	@Override
-	public void addChildren(GenericQueryType children) {
-
-	}
-
-	@Override
-	public void setName(String name) {
-		this.name = name;
-	}
-	
-	@Override
-	public String getName() {
-		return name;
-	}
-
-	@Override
-	public void setParentname(String parentname) {
-		this.parentname = parentname;
-		
-	}
-
-	@Override
-	public String getParentname() {
-		return parentname;
-	}
-	
-	@Override
-	public void getAllPrimitiveChildren(List<GenericQueryType> primitiveChild) {
-
-	}
-
-	@Override
-	public int getSurrogateIndex() {
-		return index;
-	}
-
-	@Override
-	public void setSurrogateIndex(int surrIndex) {
-		index = surrIndex;
-	}
-	
-	@Override
-    public int getBlockIndex()
-    {
-        return blockIndex;
-    }
-    
-    @Override
-    public void setBlockIndex(int blockIndex)
-    {
-        this.blockIndex = blockIndex;
-    }
-
-	@Override
-	public int getColsCount() {
-		return 1;
-	}
-
-	@Override
-    public void parseBlocksAndReturnComplexColumnByteArray(ColumnarKeyStoreDataHolder[] columnarKeyStoreDataHolder, int rowNumber, DataOutputStream dataOutputStream) throws IOException
-    {
-        byte[] currentVal = new byte[columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata().getEachRowSize()];
-        if(!columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata().isSorted())
-        {
-            System.arraycopy(columnarKeyStoreDataHolder[blockIndex].getKeyBlockData(),
-                    columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                    .getColumnReverseIndex()[rowNumber]
-                            * columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata().
-                            getEachRowSize(), currentVal, 0, columnarKeyStoreDataHolder[blockIndex].
-                            getColumnarKeyStoreMetadata().getEachRowSize());
-        }
-        else
-        {
-            System.arraycopy(columnarKeyStoreDataHolder[blockIndex].getKeyBlockData(), rowNumber
-                    * columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata().getEachRowSize(), 
-                    currentVal, 0, columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata().getEachRowSize());
-        }
-        dataOutputStream.write(currentVal);
-    }
-	
-	@Override
-    public void setKeySize(int[] keyBlockSize)
-    {
-        this.keySize = keyBlockSize[this.blockIndex];        
-    }
-	
-	@Override
-    public Object getDataBasedOnDataTypeFromSurrogates(List<InMemoryCube> slices, ByteBuffer surrogateData, Dimension[] dimensions)
-    {
-	    byte[] data = new byte[keySize];
-        surrogateData.get(data);
-        String memberData = QueryExecutorUtility.getMemberBySurrogateKey(dimensions[blockIndex], new BigInteger(data).intValue(), slices).toString();
-        Object actualData = DataTypeConverter.getDataBasedOnDataType(
-                memberData.equals(MolapCommonConstants.MEMBER_DEFAULT_VAL) ? null : memberData,
-                        dimensions[blockIndex].getDataType());
-        if(dimensions[blockIndex].getDataType() == SqlStatement.Type.STRING)
-        {
-            byte[] dataBytes = ((String)actualData).getBytes(Charset.defaultCharset());
-            return UTF8String.fromBytes(dataBytes);
-        }
-        return actualData;
-    }
-	
-	@Override
-    public void parseAndGetResultBytes(ByteBuffer complexData, DataOutputStream dataOutput) throws IOException
-    {
-	    
-//	    dataOutput.write();
-    }
-	
-	@Override
-    public DataType getSchemaType()
-    {
-	    switch(dataType)
-        {
-            case INT:
-                return new IntegerType();
-            case DOUBLE:
-                return new DoubleType();
-            case LONG:
-                return new LongType();
-            case BOOLEAN:
-                return new BooleanType();
-            case TIMESTAMP:
-                return new TimestampType();
-            default:
-                return new StringType();
-        }
-    }
-
-    @Override
-    public void setKeyOrdinalForQuery(int keyOrdinalForQuery)
-    {
-        // TODO Auto-generated method stub
-        
-    }
-
-    @Override
-    public int getKeyOrdinalForQuery()
-    {
-        // TODO Auto-generated method stub
-        return 0;
-    }
-
-    @Override
-    public void fillRequiredBlockData(BlockDataHolder blockDataHolder)
-    {
-        if(null==blockDataHolder.getColumnarKeyStore()[blockIndex])
-        {
-            blockDataHolder.getColumnarKeyStore()[blockIndex] = blockDataHolder
-                    .getLeafDataBlock().getColumnarKeyStore(blockDataHolder.getFileHolder(),
-                            blockIndex,
-                            false);
-        }
-        else
-        {
-            if(!blockDataHolder.getColumnarKeyStore()[blockIndex]
-                    .getColumnarKeyStoreMetadata().isUnCompressed())
-            {
-                blockDataHolder.getColumnarKeyStore()[blockIndex].unCompress();
-            }
-        }
-    }
-}
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/StructQueryType.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/StructQueryType.java
deleted file mode 100644
index e6e7f91..0000000
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/complex/querytypes/StructQueryType.java
+++ /dev/null
@@ -1,241 +0,0 @@
-package com.huawei.unibi.molap.engine.complex.querytypes;
-
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.spark.sql.catalyst.expressions.GenericInternalRowWithSchema;
-import org.apache.spark.sql.types.DataType;
-import org.apache.spark.sql.types.Metadata;
-import org.apache.spark.sql.types.StructField;
-import org.apache.spark.sql.types.StructType;
-
-import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
-import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
-import com.huawei.unibi.molap.engine.evaluators.BlockDataHolder;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
-
-public class StructQueryType implements GenericQueryType {
-	
-	private List<GenericQueryType> children = new ArrayList<GenericQueryType>();
-	private String name;
-	private String parentname;
-	private int blockIndex;
-	private int keyOrdinalForQuery;
-	
-	@Override
-	public void addChildren(GenericQueryType newChild) {
-		if(this.getName().equals(newChild.getParentname()))
-		{
-			this.children.add(newChild);
-		}
-		else
-		{
-			for(GenericQueryType child : this.children)
-			{
-				child.addChildren(newChild);
-			}
-		}
-		
-	}
-	
-	public StructQueryType(String name, String parentname, int blockIndex)
-	{
-		this.name = name;
-		this.parentname = parentname;
-		this.blockIndex = blockIndex;
-	}
-	
-	@Override
-	public void setName(String name) {
-		this.name = name;
-	}
-	
-	@Override
-	public String getName() {
-		return name;
-	}
-	
-	@Override
-	public void setParentname(String parentname) {
-		this.parentname = parentname;
-		
-	}
-
-	@Override
-	public String getParentname() {
-		return parentname;
-	}
-	
-	@Override
-	public void getAllPrimitiveChildren(List<GenericQueryType> primitiveChild) {
-		for(int i=0;i<children.size();i++)
-		{
-		    GenericQueryType child = children.get(i);
-			if (child instanceof PrimitiveQueryType) 
-			{
-				primitiveChild.add(child);
-			}
-			else
-			{
-				child.getAllPrimitiveChildren(primitiveChild);
-			}
-		}
-	}
-	
-	@Override
-	public int getSurrogateIndex() {
-		return 0;
-	}
-
-	@Override
-	public void setSurrogateIndex(int surrIndex) {
-		
-	}
-	
-	@Override
-    public int getBlockIndex()
-    {
-        return blockIndex;
-    }
-    
-    @Override
-    public void setBlockIndex(int blockIndex)
-    {
-        this.blockIndex = blockIndex;
-    }
-	
-	@Override
-	public int getColsCount() {
-		int colsCount = 1;
-		for(int i=0;i<children.size();i++)
-		{
-			colsCount += children.get(i).getColsCount();
-		}
-		return colsCount;
-	}
-	
-	
-	@Override
-    public void parseBlocksAndReturnComplexColumnByteArray(ColumnarKeyStoreDataHolder[] columnarKeyStoreDataHolder, int rowNumber, DataOutputStream dataOutputStream) throws IOException
-    {
-        byte[] input = new byte[8];
-        if(!columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata().isSorted())
-        {
-            System.arraycopy(columnarKeyStoreDataHolder[blockIndex].getKeyBlockData(),
-                    columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                    .getColumnReverseIndex()[rowNumber]
-                            * columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                            .getEachRowSize(), input, 0,
-                            columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                            .getEachRowSize());
-        }
-        else
-        {
-            
-            System.arraycopy(columnarKeyStoreDataHolder[blockIndex].getKeyBlockData(), rowNumber
-                    * columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                    .getEachRowSize(), input, 0,
-                    columnarKeyStoreDataHolder[blockIndex].getColumnarKeyStoreMetadata()
-                    .getEachRowSize());
-        }
-        
-        ByteBuffer byteArray = ByteBuffer.wrap(input);
-        int childElement = byteArray.getInt();
-        dataOutputStream.writeInt(childElement);
-        if(childElement == 0)
-        {
-//            b.putInt(0);
-        }
-        else
-        {
-            for(int i=0;i<childElement;i++)
-            {
-                children.get(i).parseBlocksAndReturnComplexColumnByteArray(columnarKeyStoreDataHolder, rowNumber, dataOutputStream);
-            }
-        }
-    }
-	
-	@Override
-    public void parseAndGetResultBytes(ByteBuffer complexData, DataOutputStream dataOutput) throws IOException
-    {
-        int childElement = complexData.getInt();
-        dataOutput.writeInt(childElement);
-        for(int i=0;i<childElement;i++)
-        {
-            children.get(i).parseAndGetResultBytes(complexData, dataOutput);
-        }
-    }
-	
-	@Override
-    public void setKeySize(int[] keyBlockSize)
-    {
-	    for(int i=0;i<children.size();i++)
-	    {
-	        children.get(i).setKeySize(keyBlockSize);
-	    }
-    }
-	
-	@Override
-    public Object getDataBasedOnDataTypeFromSurrogates(List<InMemoryCube> slices, ByteBuffer surrogateData, Dimension[] dimensions)
-    {
-        int childLength = surrogateData.getInt();
-        Object[] fields = new Object[childLength];
-        for(int i=0;i<childLength;i++)
-        {
-            fields[i]  = children.get(i).getDataBasedOnDataTypeFromSurrogates(slices, surrogateData, dimensions);
-        }
-            
-        return new GenericInternalRowWithSchema(fields, (StructType)getSchemaType());
-    }
-	
-	@Override
-	public DataType getSchemaType()
-	{
-	    StructField[] fields = new StructField[children.size()];
-        for(int i=0;i<children.size();i++)
-        {
-            fields[i]  = new StructField(children.get(i).getName(), children.get(i).getSchemaType(), true, Metadata.empty());
-        }
-        return new StructType(fields);
-	}
-
-    @Override
-    public void setKeyOrdinalForQuery(int keyOrdinalForQuery)
-    {
-        this.keyOrdinalForQuery = keyOrdinalForQuery;
-    }
-
-    @Override
-    public int getKeyOrdinalForQuery()
-    {
-        return keyOrdinalForQuery;
-    }
-    
-    @Override
-    public void fillRequiredBlockData(BlockDataHolder blockDataHolder)
-    {
-        if(null==blockDataHolder.getColumnarKeyStore()[blockIndex])
-        {
-            blockDataHolder.getColumnarKeyStore()[blockIndex] = blockDataHolder
-                    .getLeafDataBlock().getColumnarKeyStore(blockDataHolder.getFileHolder(),
-                            blockIndex,
-                            false);
-        }
-        else
-        {
-            if(!blockDataHolder.getColumnarKeyStore()[blockIndex]
-                    .getColumnarKeyStoreMetadata().isUnCompressed())
-            {
-                blockDataHolder.getColumnarKeyStore()[blockIndex].unCompress();
-            }
-        }
-        
-        for(int i=0;i<children.size();i++)
-        {
-            children.get(i).fillRequiredBlockData(blockDataHolder);
-        }
-    }
-}
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/CubeDataStore.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/CubeDataStore.java
index c2a5048..9263482 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/CubeDataStore.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/CubeDataStore.java
@@ -14,9 +14,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Comparator;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
 
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
@@ -37,13 +35,13 @@ import com.huawei.unibi.molap.engine.util.MolapDataInputStreamFactory;
 //import com.huawei.unibi.molap.engine.scanner.impl.NonFilterTreeScanner;
 import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthEquiSplitGenerator;
+import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthVariableSplitGenerator;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Cube;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Measure;
 import com.huawei.unibi.molap.metadata.SliceMetaData;
 import com.huawei.unibi.molap.util.MolapProperties;
 import com.huawei.unibi.molap.util.MolapUtil;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 /**
  * @author K00900207
@@ -123,6 +121,8 @@ public class CubeDataStore
     private boolean[] aggKeyBlock;
     
     private int[] dimCardinality;
+
+    private HybridStoreModel hybridStoreModel;
     
 
     /**
@@ -147,8 +147,9 @@ public class CubeDataStore
         return factTableColumn != null && factTableColumn.length() > 0;
     }
 
-    public CubeDataStore(String table, Cube metaCube, SliceMetaData smd,KeyGenerator keyGenerator, int[] dimCardinality)
+    public CubeDataStore(String table, Cube metaCube, SliceMetaData smd,KeyGenerator keyGenerator, int[] dimCardinality,HybridStoreModel hybridStoreModel)
     {
+        this.hybridStoreModel =hybridStoreModel;
         factTableColumn = metaCube.getFactCountColMapping(table);
         tableName = table;
         this.metaCube = metaCube;
@@ -156,7 +157,6 @@ public class CubeDataStore
         boolean hasFactCount = hasFactCount();
         this.smd = smd;
         List<Measure> measures = metaCube.getMeasures(table);
-        prepareComplexDimensions(metaCube.getDimensions(table));
         aggregateNames = new ArrayList<String>(MolapCommonConstants.CONSTANT_SIZE_TEN);
         if(hasFactCount)
         {
@@ -183,35 +183,6 @@ public class CubeDataStore
         System.arraycopy(dimCardinality, 0, this.dimCardinality, 0, dimCardinality.length);
     }
 
-    private void prepareComplexDimensions(List<Dimension> currentDimTables)
-    {
-        Map<String, ArrayList<Dimension>> complexDimensions = new HashMap<String, ArrayList<Dimension>>();
-        for(int i = 0;i < currentDimTables.size();i++)
-        {
-            ArrayList<Dimension> dimensions = complexDimensions.get(currentDimTables.get(i).getHierName());
-            if(dimensions != null)
-            {
-                dimensions.add(currentDimTables.get(i));
-            }
-            else
-            {
-                dimensions = new ArrayList<Dimension>();
-                dimensions.add(currentDimTables.get(i));
-            }
-            complexDimensions.put(currentDimTables.get(i).getHierName(), dimensions);
-        }
-        
-        for (Map.Entry<String, ArrayList<Dimension>> entry : complexDimensions.entrySet())
-        {
-            int[] blockIndexsForEachComplexType = new int[entry.getValue().size()];
-            for(int i=0;i<entry.getValue().size();i++)
-            {
-                blockIndexsForEachComplexType[i] = entry.getValue().get(i).getDataBlockIndex();
-            }
-            entry.getValue().get(0).setAllApplicableDataBlockIndexs(blockIndexsForEachComplexType);
-        }
-    }
-    
     /**
      * Gets the DataStore
      * @param keyGen
@@ -245,7 +216,7 @@ public class CubeDataStore
                 + "as mode=" + (isFileStore?"file":"In-Memory"));
         if(isColumnar)
         {
-            return new CSBTree(keyGen, msrCount, tableName,isFileStore,keyblockSize,aggKeyBlock);
+            return new CSBTree(this.hybridStoreModel,keyGen, msrCount, tableName,isFileStore,keyblockSize,aggKeyBlock);
         }
         else
         {
@@ -253,7 +224,7 @@ public class CubeDataStore
         }
     }
 
-    public boolean loadDataFromFile(String filesLocaton, int startAndEndKeySize)
+    public boolean loadDataFromFile(String filesLocaton)
     {
         // added for get the MDKey size by liupeng 00204190.
         MolapFile file = FileFactory.getMolapFile(filesLocaton, FileFactory.getFileType(filesLocaton));
@@ -261,8 +232,7 @@ public class CubeDataStore
         int numberOfValues = metaCube.getMeasures(tableName).size() + (hasFactCount ? 1 : 0);
         StandardLogService.setThreadName(StandardLogService.getPartitionID(metaCube.getOnlyCubeName()), null);
         checkIsColumnar(numberOfValues);
-//        int keySize = keyGenerator.getKeySizeInBytes();
-        int keySize = startAndEndKeySize;
+        int keySize = keyGenerator.getKeySizeInBytes();
         int msrCount =  smd.getMeasures().length;
         List<DataInputStream> streams = new ArrayList<DataInputStream>(MolapCommonConstants.CONSTANT_SIZE_TEN);
         if(file.isDirectory())
@@ -459,32 +429,39 @@ public class CubeDataStore
             // if there is no single dims present (i.e only high card dims is present.)
             if(this.dimCardinality.length > 0)
             {
-                keyBlockSize = new MultiDimKeyVarLengthEquiSplitGenerator(
-                        MolapUtil.getIncrementedCardinalityFullyFilled(this.dimCardinality.clone()), (byte)dimSet)
+                keyBlockSize = new MultiDimKeyVarLengthVariableSplitGenerator(MolapUtil.getDimensionBitLength(this.hybridStoreModel.getHybridCardinality(),this.hybridStoreModel.getDimensionPartitioner()),this.hybridStoreModel.getColumnSplit())
                         .getBlockKeySize();
 
-                aggKeyBlock = new boolean[dimCardinality.length];
+           // aggKeyBlock = new boolean[dimCardinality.length];
                 boolean isAggKeyBlock = Boolean
                         .parseBoolean(MolapCommonConstants.AGGREAGATE_COLUMNAR_KEY_BLOCK_DEFAULTVALUE);
                 if(isAggKeyBlock)
                 {
                     int highCardinalityValue = Integer.parseInt(MolapProperties.getInstance().getProperty(
-                            MolapCommonConstants.HIGH_CARDINALITY_VALUE,
-                            MolapCommonConstants.HIGH_CARDINALITY_VALUE_DEFAULTVALUE));
-                    for(int i = 0;i < dimCardinality.length;i++)
+                        MolapCommonConstants.HIGH_CARDINALITY_VALUE,
+                        MolapCommonConstants.HIGH_CARDINALITY_VALUE_DEFAULTVALUE));
+                    int aggIndex=0;
+                    if(this.hybridStoreModel.isHybridStore())
+                    {
+                        this.aggKeyBlock=new boolean[this.hybridStoreModel.getColumnStoreOrdinals().length+1];
+                        this.aggKeyBlock[aggIndex++]=false;
+                    }
+                    else
+                    {
+                        this.aggKeyBlock=new boolean[this.hybridStoreModel.getColumnStoreOrdinals().length]; 
+                    }
+                    
+                    for(int i=hybridStoreModel.getRowStoreOrdinals().length;i<dimCardinality.length;i++)
                     {
-						//Array or Struct column will not be compressed using run-length as cardinality does not apply
-	                    if(dimCardinality[i] == 0)
-						{
-                        	aggKeyBlock[i] = false;
-						}
-                        else if(dimCardinality[i] < highCardinalityValue)
+                        if(dimCardinality[i]<highCardinalityValue)
                         {
-                            aggKeyBlock[i] = true;
+                            this.aggKeyBlock[aggIndex++]=true;
+                            continue;
                         }
+                        aggIndex++;
                     }
+                   
                 }
-
             }
             else
             {
@@ -500,19 +477,6 @@ public class CubeDataStore
         }
     }
 
-    private int[] getKeyBlockSizeWithComplexTypes(int[] dimCardinality)
-    {
-        int[] keyBlockSize = new int[dimCardinality.length];
-        for(int i=0;i<dimCardinality.length;i++)
-        {
-            if(dimCardinality[i] == 0)
-                keyBlockSize[i] = 8;
-            else
-                keyBlockSize[i] = new MultiDimKeyVarLengthEquiSplitGenerator(new int[]{dimCardinality[i]}, (byte)1)
-                  .getBlockKeySize()[0];
-        }
-        return keyBlockSize;
-    }
 //    public void loadDataFromSlices(List<CubeDataStore> dataStores, String fileStore)
 //    {
 //        List<Scanner> scanners = new ArrayList<Scanner>(MolapCommonConstants.CONSTANT_SIZE_TEN);
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCube.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCube.java
index 3aabfaa..3806c05 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCube.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCube.java
@@ -33,10 +33,12 @@ import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.keygenerator.factory.KeyGeneratorFactory;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Cube;
+import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.metadata.MolapSchemaReader;
 import com.huawei.unibi.molap.olap.MolapDef;
 import com.huawei.unibi.molap.util.MolapUtil;
 import com.huawei.unibi.molap.util.MolapUtilException;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 /**
  * @author K00900207
@@ -139,8 +141,8 @@ public class InMemoryCube implements Comparable<InMemoryCube>
     private MolapLRULevelCache levelCache;
     
     private Cube metaCube;
-    
-    /**
+
+    private HybridStoreModel hybridStoreModel;    /**
      * Attribute for Molap LOGGER
      */
     private static final LogService LOGGER = LogServiceFactory.getLogService(InMemoryCube.class.getName());
@@ -251,10 +253,25 @@ public class InMemoryCube implements Comparable<InMemoryCube>
         if(file.isDirectory())
         {
             getDimensionCardinality(file, tableName);
-//            keyGenerator = KeyGeneratorFactory.getKeyGenerator(dimensionCardinality);
-            keyGenerator = KeyGeneratorFactory.getKeyGenerator(findRequiredDimensionForStartAndEndKey());
-            int startAndEndKeySizeWithPrimitives = KeyGeneratorFactory.getKeyGenerator(findRequiredDimensionForStartAndEndKey()).getKeySizeInBytes();
-            keyGenerator.setStartAndEndKeySizeWithOnlyPrimitives(startAndEndKeySizeWithPrimitives);
+            List<Dimension> dimensions=metaCube.getDimensions(tableName);
+            
+            boolean[] dimensionStoreType=new boolean[dimensionCardinality.length];
+            List<Integer> highCardDimOrdinals=new ArrayList<Integer>();
+            for(Dimension dimension:dimensions)
+            {
+                if(dimension.isHighCardinalityDim())
+                {
+                    highCardDimOrdinals.add(dimension.getOrdinal());
+                    continue;
+                }
+                if(dimension.isColumnar())
+                {
+                    dimensionStoreType[dimension.getOrdinal()]=dimension.isColumnar();    
+                }
+            }
+            hybridStoreModel= MolapUtil.getHybridStoreMeta(dimensionCardinality, dimensionStoreType,highCardDimOrdinals);
+          
+            keyGenerator = KeyGeneratorFactory.getKeyGenerator(hybridStoreModel.getHybridCardinality(),hybridStoreModel.getDimensionPartitioner());
         }
         // Process fact and aggregate data cache
         if(!loadOnlyLevelFiles)
@@ -265,9 +282,8 @@ public class InMemoryCube implements Comparable<InMemoryCube>
                 {
                     continue;
                 }
-                CubeDataStore dataCache = new CubeDataStore(table, metaCube, rsStore.getSliceMetaCache(table),keyGenerator, dimensionCardinality);
-                //add start and end key size with only primitives
-                if(dataCache.loadDataFromFile(fileStore, keyGenerator.getStartAndEndKeySizeWithOnlyPrimitives()))
+                CubeDataStore dataCache = new CubeDataStore(table, metaCube, rsStore.getSliceMetaCache(table),keyGenerator, dimensionCardinality, hybridStoreModel);
+                if(dataCache.loadDataFromFile(fileStore))
                 {
                     dataCacheMap.put(table, dataCache);
                 }
@@ -316,24 +332,6 @@ public class InMemoryCube implements Comparable<InMemoryCube>
         this.tableName=tableName;
     }
     
-    
-    private int[] findRequiredDimensionForStartAndEndKey()
-    {
-        List<Integer> dimCardinalities = new ArrayList<Integer>();
-        for(int dimCard : dimensionCardinality)
-        {
-            if(dimCard != 0)
-                dimCardinalities.add(dimCard);
-            else
-                break;
-        }
-        int[] primitiveDimsForKey = new int[dimCardinalities.size()];
-        for(int i=0;i<dimCardinalities.size();i++)
-        {
-            primitiveDimsForKey[i] = dimCardinalities.get(i);
-        }
-        return primitiveDimsForKey;
-    }
     /**
      * @param file
      */
@@ -524,16 +522,7 @@ public class InMemoryCube implements Comparable<InMemoryCube>
         int loadNumber = -1;
         try
         {
-            if(isLoadMerged(loadName))
-            {
-                String loadNum = loadName.substring(loadName.indexOf('_') + 1,
-                        loadName.indexOf(MolapCommonConstants.MERGERD_EXTENSION));
-                loadNumber = Integer.parseInt(loadNum);
-            }
-            else
-            {
-                loadNumber = Integer.parseInt(loadName.substring(lastIndexOf + 5));
-            }
+            loadNumber= Integer.parseInt(loadName.substring(lastIndexOf + 5));
         }
         catch(NumberFormatException e)
         {
@@ -548,33 +537,17 @@ public class InMemoryCube implements Comparable<InMemoryCube>
     public int compareTo(InMemoryCube memCubeInstance)
     {
         String loadNameOfCurrntObj = this.getLoadName();
-        String loadNameCurrntObj;
-        
-        if(isLoadMerged(loadNameOfCurrntObj))
-        {
-             loadNameCurrntObj = loadNameOfCurrntObj.substring(loadNameOfCurrntObj.indexOf('_')+1,loadNameOfCurrntObj.indexOf(MolapCommonConstants.MERGERD_EXTENSION));
-        }
-        else
-        {
-         loadNameCurrntObj = loadNameOfCurrntObj.substring(loadNameOfCurrntObj.lastIndexOf('_')+1,
+        String loadNameCurrntObj = loadNameOfCurrntObj.substring(loadNameOfCurrntObj.lastIndexOf('_')+1,
                 loadNameOfCurrntObj.length());
-        }
         int idOfCurrentObj = Integer.parseInt(loadNameCurrntObj);
         String loadNameOfComparableObj = memCubeInstance.getLoadName();
-        
-        if(isLoadMerged(loadNameOfComparableObj))
-        {
-            loadNameOfComparableObj = loadNameOfComparableObj.substring(loadNameOfComparableObj.indexOf('_')+1,loadNameOfComparableObj.indexOf(MolapCommonConstants.MERGERD_EXTENSION));
-        }
-        else
-        {
         loadNameOfComparableObj = loadNameOfComparableObj.substring(loadNameOfComparableObj.lastIndexOf('_')+1,
                 loadNameOfComparableObj.length());
-        }
         int idOfCompObj = Integer.parseInt(loadNameOfComparableObj);
         return idOfCurrentObj - idOfCompObj;
     }
     
+      
     @Override
     public boolean equals(Object obj) 
     {
@@ -611,17 +584,8 @@ public class InMemoryCube implements Comparable<InMemoryCube>
         return dimensionCardinality;
     }
     
-    /**
-     * To check if this is a merged load or not.
-     * @param loadName
-     * @return
-     */
-    private boolean isLoadMerged(String loadName)
+    public HybridStoreModel getHybridStoreModel()
     {
-         if(loadName.contains(MolapCommonConstants.MERGERD_EXTENSION))
-         {
-             return true;
-         }
-        return false;
+        return this.hybridStoreModel;
     }
 }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCubeStore.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCubeStore.java
index 636ca09..91b442c 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCubeStore.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/InMemoryCubeStore.java
@@ -772,7 +772,7 @@ public final class InMemoryCubeStore
                     while(itrForSliceList.hasNext())
                     {
                         InMemoryCube slice = itrForSliceList.next();
-                        String sliceName = slice.getLoadName().substring(slice.getLoadName().indexOf('_') + 1,
+                        String sliceName = slice.getLoadName().substring(slice.getLoadName().lastIndexOf('_') + 1,
                                 slice.getLoadName().length());
                         if(listLoadFolders.contains(slice.getLoadName()) && null != sliceUpdatedLoadPaths
                                 && !sliceUpdatedLoadPaths.contains(sliceName))
@@ -1193,29 +1193,8 @@ public final class InMemoryCubeStore
                         String firstFolder = o1.getAbsolutePath().substring(firstFolderIndex);
                         String secondFolder = o2.getAbsolutePath().substring(secondFolderIndex);
                         //
-                        int f1 = -1;
-                        int f2 = -1;
-                        try
-                        {
-                         f1 = Integer.parseInt(firstFolder.split("_")[1]);
-                        }
-                        catch(NumberFormatException e)
-                        {
-                            String loadName = (firstFolder.split("_")[1]);
-                          f1 =  Integer.parseInt(loadName.substring(0, loadName.indexOf(MolapCommonConstants.MERGERD_EXTENSION)));
-                            
-                        }
-                        try
-                        {
-                         f2 = Integer.parseInt(secondFolder.split("_")[1]);
-                        }
-                        catch(NumberFormatException e)
-                        {
-                            String loadName = (secondFolder.split("_")[1]);
-                          f2 =  Integer.parseInt(loadName.substring(0, loadName.indexOf(MolapCommonConstants.MERGERD_EXTENSION)));
-                            
-                        }
-//                        int f2 = Integer.parseInt(secondFolder.split("_")[1]);
+                        int f1 = Integer.parseInt(firstFolder.split("_")[1]);
+                        int f2 = Integer.parseInt(secondFolder.split("_")[1]);
                         return (f1 < f2) ? -1 : (f1 == f2 ? 0 : 1);
                     }
                     catch(Exception e)
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTree.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTree.java
index faff41e..a2b4fd7 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTree.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTree.java
@@ -29,6 +29,7 @@ import com.huawei.unibi.molap.metadata.LeafNodeInfo;
 import com.huawei.unibi.molap.metadata.LeafNodeInfoColumnar;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Cube;
 import com.huawei.unibi.molap.util.MolapProperties;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 /**
  * Cache Sensitive B+-Tree to implement a search structure that is stored
@@ -145,6 +146,8 @@ public class CSBTree implements DataStore
     private int[] keyBlockSize;
     
     private boolean [] aggKeyBlock;
+
+    private HybridStoreModel hybridStoreModel;
     
     // private String dataFolderLoc;
     /**
@@ -155,13 +158,14 @@ public class CSBTree implements DataStore
     
 
     // Constructor
-    public CSBTree(KeyGenerator keyGenerator, int valueCount, String tableName , boolean isFileStore,int[] keyBlockSize,boolean [] aggKeyBlock)
+    public CSBTree(HybridStoreModel hybridStoreModel,KeyGenerator keyGenerator, int valueCount, String tableName , boolean isFileStore,int[] keyBlockSize,boolean [] aggKeyBlock)
     {
         super();
 
        // this.valueCount = valueCount;
         this.keyGenerator = keyGenerator;
         this.tableName = tableName;
+        this.hybridStoreModel = hybridStoreModel;
 
         // TODO Need to account for page headers and other fields
         upperMaxEntry = Integer.parseInt(MolapProperties.getInstance().getProperty(
@@ -328,7 +332,7 @@ private void setRangeSplitvalue()
                             fileHolder = FileFactory.getFileHolder(FileFactory.getFileType(leafNodeInfo.getFileName()));
                         }
                         curNode = new CSBTreeColumnarLeafNode(leafNodeInfo.getNumberOfKeys(), keyBlockSize, isFileStore, fileHolder,
-                                leafNodeInfo, compressionModel,nodeNumber++,metaCube);
+                                leafNodeInfo, compressionModel,nodeNumber++,metaCube,hybridStoreModel);
                         nLeaf++;
     
                         if(prevNode != null)
@@ -363,8 +367,7 @@ private void setRangeSplitvalue()
 //        rangeVals = caclulateRanges(num, nodeGroups, rangeVals, fileHolder);
         if(num == 0)
         {
-//            root = new CSBInternalNode(upperMaxEntry, keyGenerator.getKeySizeInBytes(), tableName);
-            root = new CSBInternalNode(upperMaxEntry, keyGenerator.getStartAndEndKeySizeWithOnlyPrimitives(), tableName);
+            root = new CSBInternalNode(upperMaxEntry, keyGenerator.getKeySizeInBytes(), tableName);
             return;
         }
         findCurrentNode(nInternal, curNode, nodeGroups, currentGroup, interNSKeyList);
@@ -490,9 +493,7 @@ private void setRangeSplitvalue()
             for(int i = 0;i < nHigh;i++)
             {
                 // Create a new internal node
-//                curNode = new CSBInternalNode(upperMaxEntry, keyGenerator.getKeySizeInBytes(), tableName);
-                curNode = new CSBInternalNode(upperMaxEntry, keyGenerator.getStartAndEndKeySizeWithOnlyPrimitives(), tableName);
-                
+                curNode = new CSBInternalNode(upperMaxEntry, keyGenerator.getKeySizeInBytes(), tableName);
 
                 // Allocate a new node group if current node group is full
                 groupCounter = i % (upperMaxChildren);
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTreeColumnarLeafNode.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTreeColumnarLeafNode.java
index 4bc1529..6dfa2bc 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTreeColumnarLeafNode.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/datastorage/tree/CSBTreeColumnarLeafNode.java
@@ -15,6 +15,7 @@ import com.huawei.unibi.molap.metadata.LeafNodeInfoColumnar;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Cube;
 import com.huawei.unibi.molap.olap.MolapDef.CubeDimension;
 import com.huawei.unibi.molap.util.MolapUtil;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 public class CSBTreeColumnarLeafNode extends CSBNode
 {
@@ -54,10 +55,10 @@ public class CSBTreeColumnarLeafNode extends CSBNode
     private byte[][] columnMaxData;
     
     public CSBTreeColumnarLeafNode(int maxKeys, int[] eachBlockSize, boolean isFileStore, FileHolder fileHolder,
-            LeafNodeInfoColumnar leafNodeInfo, ValueCompressionModel compressionModel, long nodeNumber,Cube metaCube)
+            LeafNodeInfoColumnar leafNodeInfo, ValueCompressionModel compressionModel, long nodeNumber,Cube metaCube,HybridStoreModel hybridStoreModel)
     {
         nKeys = leafNodeInfo.getNumberOfKeys();
-        keyStore = StoreFactory.createColumnarKeyStore(MolapUtil.getColumnarKeyStoreInfo(leafNodeInfo, eachBlockSize), fileHolder,isFileStore);
+        keyStore = StoreFactory.createColumnarKeyStore(MolapUtil.getColumnarKeyStoreInfo(leafNodeInfo, eachBlockSize,hybridStoreModel), fileHolder,isFileStore);
         dataStore = StoreFactory.createDataStore(isFileStore,
                 compressionModel, leafNodeInfo.getMeasureOffset(), leafNodeInfo.getMeasureLength(),
                 leafNodeInfo.getFileName(),fileHolder);
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/AbstractConditionalEvalutor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/AbstractConditionalEvalutor.java
index 476ea28..9aebac7 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/AbstractConditionalEvalutor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/AbstractConditionalEvalutor.java
@@ -11,7 +11,7 @@ import com.huawei.unibi.molap.engine.expression.conditional.BinaryConditionalExp
 import com.huawei.unibi.molap.engine.expression.conditional.ConditionalExpression;
 import com.huawei.unibi.molap.engine.filters.measurefilter.util.FilterUtil;
 import com.huawei.unibi.molap.engine.schema.metadata.FilterEvaluatorInfo;
-import com.huawei.unibi.molap.olap.SqlStatement.Type;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 public abstract class AbstractConditionalEvalutor implements FilterEvaluator
 {
@@ -65,15 +65,16 @@ public abstract class AbstractConditionalEvalutor implements FilterEvaluator
                     }
                     else
                     {
-                        dimColumnEvaluatorInfo.setColumnIndex(columnExpression.getDim().getOrdinal());
+                        dimColumnEvaluatorInfo.setColumnIndex(getColumnStoreIndex(columnExpression.getDim().getOrdinal(), info.getHybridStoreModel()));
                         if(!columnExpression.getDim().isHighCardinalityDim())
                         {
                         dimColumnEvaluatorInfo.setNeedCompressedData(info.getSlices().get(info.getCurrentSliceIndex())
-                                .getDataCache(info.getFactTableName()).getAggKeyBlock()[columnExpression.getDim()
-                                .getOrdinal()]);
+                                .getDataCache(info.getFactTableName()).getAggKeyBlock()[getColumnStoreIndex(columnExpression.getDim()
+                                .getOrdinal(),info.getHybridStoreModel())]);
                         }
                         dimColumnEvaluatorInfo.setFilterValues(FilterUtil.getFilterList(info, rightExp, columnExpression,
                                 this.isIncludeFilter));
+                        dimColumnEvaluatorInfo.setDims(columnExpression.getDim());
                     }
                 }
             }
@@ -104,6 +105,7 @@ public abstract class AbstractConditionalEvalutor implements FilterEvaluator
                         }
                         dimColumnEvaluatorInfo.setFilterValues(FilterUtil.getFilterList(info, leftExp, columnExpression,
                                 isIncludeFilter));
+                        dimColumnEvaluatorInfo.setDims(columnExpression.getDim());
                     }
                 }
             }
@@ -127,15 +129,46 @@ public abstract class AbstractConditionalEvalutor implements FilterEvaluator
             {
                 dimColumnEvaluatorInfo.setFilterValues(FilterUtil.getFilterList(info, exp, columnList.get(0),isIncludeFilter));
             }
-            else if(!(columnList.get(0).getDim().getDataType() == Type.ARRAY || columnList.get(0).getDim().getDataType() == Type.STRUCT))
+            else
             {
-            	dimColumnEvaluatorInfo.setFilterValues(FilterUtil.getFilterListForAllMembers(info, exp, columnList.get(0),isIncludeFilter));
+            dimColumnEvaluatorInfo.setFilterValues(FilterUtil.getFilterListForAllMembers(info, exp, columnList.get(0),isIncludeFilter));
             }
         }
         dimColEvaluatorInfoList.add(dimColumnEvaluatorInfo);
     }
 
- 
+    protected int getColumnStoreIndex(int ordinal, HybridStoreModel hybridStoreModel)
+    {
+        if(!hybridStoreModel.isHybridStore())
+        {
+            return ordinal;
+        }
+        return hybridStoreModel.getStoreIndex(ordinal);
+        
+    }
+  
+    /**
+     * This method will check if a given expression contains a column expression recursively.
+     * 
+     * @param right
+     * @return
+     */
+    private boolean checkIfExpressionContainsColumn(Expression expression)
+    {
+        if(expression instanceof ColumnExpression)
+        {
+            return true;
+        }
+        for(Expression child: expression.getChildren())
+        {
+            if(checkIfExpressionContainsColumn(child))
+            {
+                return true;
+            }
+        }
+        
+        return false;
+    }
 
     public FilterEvaluator getLeft()
     {
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/DimColumnEvaluatorInfo.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/DimColumnEvaluatorInfo.java
index fb2405d..bee68c9 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/DimColumnEvaluatorInfo.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/DimColumnEvaluatorInfo.java
@@ -1,9 +1,7 @@
 package com.huawei.unibi.molap.engine.evaluators;
 
 import java.util.List;
-import java.util.Map;
 
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 
@@ -39,8 +37,6 @@ public class DimColumnEvaluatorInfo
      * dims
      */
     private Dimension dims;
-
-    private Dimension[] dimensions;
     
     /**
      * rowIndex
@@ -53,28 +49,6 @@ public class DimColumnEvaluatorInfo
     
     private String defaultValue;
     
-    private Map<Integer, GenericQueryType> complexTypesWithBlockStartIndex; 
-
-    public Map<Integer, GenericQueryType> getComplexTypesWithBlockStartIndex()
-    {
-        return complexTypesWithBlockStartIndex;
-    }
-
-    public void setComplexTypesWithBlockStartIndex(Map<Integer, GenericQueryType> complexTypesWithBlockStartIndex)
-    {
-        this.complexTypesWithBlockStartIndex = complexTypesWithBlockStartIndex;
-    }
-    
-    public Dimension[] getDimensions()
-    {
-        return dimensions;
-    }
-
-    public void setDimensions(Dimension[] dimensions)
-    {
-        this.dimensions = dimensions;
-    }
-    
     public int getColumnIndex()
     {
         return columnIndex;
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/conditional/row/RowLevelFilterEvalutor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/conditional/row/RowLevelFilterEvalutor.java
index 55334ad..1855ff3 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/conditional/row/RowLevelFilterEvalutor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/evaluators/conditional/row/RowLevelFilterEvalutor.java
@@ -1,9 +1,5 @@
 package com.huawei.unibi.molap.engine.evaluators.conditional.row;
 
-import java.io.ByteArrayOutputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
 import java.util.BitSet;
 import java.util.List;
 
@@ -13,8 +9,6 @@ import com.huawei.unibi.molap.constants.MolapCommonConstants;
 import com.huawei.unibi.molap.datastorage.store.columnar.ColumnarKeyStoreDataHolder;
 import com.huawei.unibi.molap.engine.aggregator.MeasureAggregator;
 import com.huawei.unibi.molap.engine.aggregator.util.AggUtil;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
-import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.engine.datastorage.Member;
 import com.huawei.unibi.molap.engine.evaluators.AbstractConditionalEvalutor;
 import com.huawei.unibi.molap.engine.evaluators.BlockDataHolder;
@@ -31,9 +25,7 @@ import com.huawei.unibi.molap.engine.schema.metadata.FilterEvaluatorInfo;
 import com.huawei.unibi.molap.engine.util.DataTypeConverter;
 import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
 import com.huawei.unibi.molap.engine.util.QueryExecutorUtility;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Measure;
-import com.huawei.unibi.molap.olap.SqlStatement.Type;
 
 public class RowLevelFilterEvalutor extends AbstractConditionalEvalutor
 {
@@ -59,14 +51,12 @@ public class RowLevelFilterEvalutor extends AbstractConditionalEvalutor
                 if(columnExpression.isDimension())
                 {
                     dimColumnEvaluatorInfo = new DimColumnEvaluatorInfo();
-                    dimColumnEvaluatorInfo.setColumnIndex(columnExpression.getDim().getOrdinal());
+                    dimColumnEvaluatorInfo.setColumnIndex(getColumnStoreIndex(columnExpression.getDim().getOrdinal(),info.getHybridStoreModel()));
                     dimColumnEvaluatorInfo.setNeedCompressedData(false);
                     dimColumnEvaluatorInfo.setRowIndex(index++);
                     dimColumnEvaluatorInfo.setSlices(info.getSlices());
                     dimColumnEvaluatorInfo.setCurrentSliceIndex(info.getCurrentSliceIndex());
                     dimColumnEvaluatorInfo.setDims(columnExpression.getDim());
-                    dimColumnEvaluatorInfo.setComplexTypesWithBlockStartIndex(info.getComplexTypesWithBlockStartIndex());
-                    dimColumnEvaluatorInfo.setDimensions(info.getDimensions());
                     int newDimensionIndex = QueryExecutorUtility.isNewDimension(
                             info.getNewDimension(), columnExpression.getDim());
                     if(newDimensionIndex>-1)
@@ -108,33 +98,27 @@ public class RowLevelFilterEvalutor extends AbstractConditionalEvalutor
             }
         }
     }
+   
+
     @Override
     public BitSet applyFilter(BlockDataHolder blockDataHolder, FilterProcessorPlaceHolder placeHolder)
     {
         for(DimColumnEvaluatorInfo dimColumnEvaluatorInfo:dimColEvaluatorInfoList)
         {
-            if(dimColumnEvaluatorInfo.getDims().getDataType() != Type.ARRAY  && dimColumnEvaluatorInfo.getDims().getDataType() != Type.STRUCT)
+            if(null==blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()])
             {
-                if(null==blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()])
-                {
-                    blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()] = blockDataHolder
-                            .getLeafDataBlock().getColumnarKeyStore(blockDataHolder.getFileHolder(),
-                                    dimColumnEvaluatorInfo.getColumnIndex(),
-                                    false);
-                }
-                else
-                {
-                    if(!blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()]
-                            .getColumnarKeyStoreMetadata().isUnCompressed())
-                    {
-                        blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()].unCompress();
-                    }
-                }
+                blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()] = blockDataHolder
+                        .getLeafDataBlock().getColumnarKeyStore(blockDataHolder.getFileHolder(),
+                                dimColumnEvaluatorInfo.getColumnIndex(),
+                                false);
             }
             else
             {
-                GenericQueryType complexType = dimColumnEvaluatorInfo.getComplexTypesWithBlockStartIndex().get(dimColumnEvaluatorInfo.getColumnIndex());
-                complexType.fillRequiredBlockData(blockDataHolder);
+                if(!blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()]
+                        .getColumnarKeyStoreMetadata().isUnCompressed())
+                {
+                    blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()].unCompress();
+                }
             }
         }
         
@@ -183,25 +167,9 @@ public class RowLevelFilterEvalutor extends AbstractConditionalEvalutor
         String memberString= null;
         for(DimColumnEvaluatorInfo dimColumnEvaluatorInfo:dimColEvaluatorInfoList)
         {
-            if(dimColumnEvaluatorInfo.getDims().getDataType() != Type.ARRAY  && dimColumnEvaluatorInfo.getDims().getDataType() != Type.STRUCT)
+            if(!dimColumnEvaluatorInfo.isDimensionExistsInCurrentSilce())
             {
-                if(!dimColumnEvaluatorInfo.isDimensionExistsInCurrentSilce())
-                {
-                    record[dimColumnEvaluatorInfo.getRowIndex()]=dimColumnEvaluatorInfo.getDefaultValue();
-                }
-                Member member = QueryExecutorUtility.getMemberBySurrogateKey(dimColumnEvaluatorInfo
-                        .getDims(), blockDataHolder.getColumnarKeyStore()[dimColumnEvaluatorInfo.getColumnIndex()]
-                        .getSurrogateKey(index), dimColumnEvaluatorInfo.getSlices(),dimColumnEvaluatorInfo.getCurrentSliceIndex());
-                
-                if(null != member)
-                {
-                    memberString = member.toString();
-                    if(memberString.equals(MolapCommonConstants.MEMBER_DEFAULT_VAL))
-                    {
-                        memberString=null;
-                    }
-                }
-                record[dimColumnEvaluatorInfo.getRowIndex()] = DataTypeConverter.getDataBasedOnDataType(memberString,dimColumnEvaluatorInfo.getDims().getDataType());
+                record[dimColumnEvaluatorInfo.getRowIndex()]=dimColumnEvaluatorInfo.getDefaultValue();
             }
             if(dimColumnEvaluatorInfo.getDims().isHighCardinalityDim())
             {
@@ -232,23 +200,13 @@ public class RowLevelFilterEvalutor extends AbstractConditionalEvalutor
             
             if(null != member)
             {
-                try
-                {
-                    GenericQueryType complexType = dimColumnEvaluatorInfo.getComplexTypesWithBlockStartIndex().get(dimColumnEvaluatorInfo.getColumnIndex());
-                    ByteArrayOutputStream byteStream = new ByteArrayOutputStream();
-                    DataOutputStream dataOutputStream = new DataOutputStream(byteStream);
-                    complexType.parseBlocksAndReturnComplexColumnByteArray(blockDataHolder.getColumnarKeyStore(), index, dataOutputStream);
-                    record[dimColumnEvaluatorInfo.getRowIndex()] = complexType.getDataBasedOnDataTypeFromSurrogates(
-                            dimColumnEvaluatorInfo.getSlices(), ByteBuffer.wrap(byteStream.toByteArray()),
-                            dimColumnEvaluatorInfo.getDimensions());
-                    byteStream.close();
-                }
-                catch(IOException e)
+                memberString = member.toString();
+                if(memberString.equals(MolapCommonConstants.MEMBER_DEFAULT_VAL))
                 {
-                    LOGGER.info(MolapEngineLogEvent.UNIBI_MOLAPENGINE_MSG, e, e.getMessage());
+                    memberString=null;
                 }
-                
             }
+            record[dimColumnEvaluatorInfo.getRowIndex()] = DataTypeConverter.getDataBasedOnDataType(memberString,dimColumnEvaluatorInfo.getDims().getDataType());
         }
        }
         
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/MolapQueryExecutorModel.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/MolapQueryExecutorModel.java
index ad346c0..26641cc 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/MolapQueryExecutorModel.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/MolapQueryExecutorModel.java
@@ -15,12 +15,9 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import org.apache.spark.Accumulator;
-
 import com.huawei.datasight.molap.core.load.LoadMetadataDetails;
 import com.huawei.unibi.molap.engine.aggregator.CustomMolapAggregateExpression;
 import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInfo;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.directinterface.impl.MeasureSortModel;
 import com.huawei.unibi.molap.engine.expression.Expression;
 import com.huawei.unibi.molap.engine.filters.measurefilter.GroupMeasureFilterModel;
@@ -31,6 +28,8 @@ import com.huawei.unibi.molap.metadata.MolapMetadata.Cube;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Measure;
 
+import org.apache.spark.Accumulator;
+
 /**
  * Its a model object for MolapExecutor interface
  * @author R00900208
@@ -82,11 +81,6 @@ public class MolapQueryExecutorModel implements Serializable
     private Map<Dimension, MolapFilterInfo> constraintsAfterTopN;
 
     /**
-     * constraints 
-     */
-    private Map<String, GenericQueryType> complexDimensionsMap;
-
-    /**
      * msrFilterModels
      */
     private List<GroupMeasureFilterModel> msrFilterModelsTopN;
@@ -341,16 +335,6 @@ public class MolapQueryExecutorModel implements Serializable
         this.dims = dims;
     }
 
-    public Map<String, GenericQueryType> getComplexDimensionsMap()
-    {
-        return complexDimensionsMap;
-    }
-
-    public void setComplexDimensionsMap(Map<String, GenericQueryType> complexDimensionsMap)
-    {
-        this.complexDimensionsMap = complexDimensionsMap;
-    }
-    
     /**
      * @return the msrs
      */
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/AbstractQueryExecutor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/AbstractQueryExecutor.java
index 4affafc..a47fdb5 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/AbstractQueryExecutor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/AbstractQueryExecutor.java
@@ -57,7 +57,6 @@ public abstract class AbstractQueryExecutor implements QueryExecutor
         if(dimList != null)
         {
             executerProperties.dimTables = dimList.toArray(new Dimension[dimList.size()]);
-            executerProperties.complexDimensionsMap = QueryExecutorUtility.getComplexDimensionsMap(executerProperties.dimTables);
         }
         Long threadID = Thread.currentThread().getId();
         List<Long> sliceIds = QueryMapper.getSlicesForThread(threadID);
@@ -110,6 +109,7 @@ public abstract class AbstractQueryExecutor implements QueryExecutor
             {
                 executerProperties.globalKeyGenerator= executerProperties.slices.get(i)
                         .getKeyGenerator(queryModel.getFactTable());
+                executerProperties.hybridStoreModel=executerProperties.slices.get(i).getHybridStoreModel();
                 break;
             }
         }
@@ -203,8 +203,17 @@ public abstract class AbstractQueryExecutor implements QueryExecutor
             }
         }
         // get the mask byte range based on dimension present in the query
-        executerProperties.maskByteRanges = QueryExecutorUtil.getMaskedByte(queryModel.getDims(),
-                executerProperties.globalKeyGenerator);
+        if(executerProperties.hybridStoreModel.isHybridStore())
+        {
+            executerProperties.maskByteRanges = QueryExecutorUtil.getMaskedByte(queryModel.getDims(),
+                    executerProperties.globalKeyGenerator,executerProperties.hybridStoreModel);    
+        }
+        else
+        {
+            executerProperties.maskByteRanges = QueryExecutorUtil.getMaskedByte(queryModel.getDims(),
+                    executerProperties.globalKeyGenerator);
+        }
+        
 
         // creating a masked key
         executerProperties.maskedBytes = new int[executerProperties.globalKeyGenerator.getKeySizeInBytes()];
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/ColumnarSliceExecuter.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/ColumnarSliceExecuter.java
index d0eb9f4..b0efab2 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/ColumnarSliceExecuter.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/ColumnarSliceExecuter.java
@@ -125,9 +125,6 @@ public class ColumnarSliceExecuter implements Callable<Void>
         aggregatorInfo.setExpressionStartIndex(sliceInfo.getExpressionStartIndex());
         aggregatorInfo.setMsrDefaultValue(sliceInfo.getMsrDefaultValue());
         aggregatorInfo.setIsMeasureExistis(sliceInfo.getIsMeasureExistis());
-        aggregatorInfo.setQueryDimensionsLength(sliceInfo.getQueryDimensions().length);
-        aggregatorInfo.setComplexQueryDims(sliceInfo.getComplexQueryDimensions());
-        aggregatorInfo.setDimensions(sliceInfo.getDimensions());
         return aggregatorInfo;
     }
 
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecuterProperties.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecuterProperties.java
index 36e007a..4036d5c 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecuterProperties.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecuterProperties.java
@@ -1,13 +1,12 @@
 package com.huawei.unibi.molap.engine.executer.impl;
 
 import java.util.List;
-import java.util.Map;
 
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Measure;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 public class QueryExecuterProperties
 {
@@ -32,11 +31,6 @@ public class QueryExecuterProperties
     protected Dimension[] dimTables;
 
     /**
-     * dimension table array
-     */
-    protected Map<String,GenericQueryType> complexDimensionsMap;
-    
-    /**
      * list of active slices present for execution
      */
     protected List<InMemoryCube> slices;
@@ -134,4 +128,11 @@ public class QueryExecuterProperties
 
     protected boolean[] isHighCardinality;
     
+    
+    /**
+     * Hybrid store model, it will have detail about columnar and row stores
+     */
+    protected HybridStoreModel hybridStoreModel;
+
+    
 }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecutorImpl.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecutorImpl.java
index d5a6acb..2c3529d 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecutorImpl.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryExecutorImpl.java
@@ -1,13 +1,10 @@
 package com.huawei.unibi.molap.engine.executer.impl;
 
 import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Collections;
-import java.util.Set;
 
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
@@ -16,7 +13,6 @@ import com.huawei.unibi.molap.constants.MolapCommonConstants;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
 import com.huawei.unibi.molap.engine.aggregator.MeasureAggregator;
-import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInfo;
 import com.huawei.unibi.molap.engine.cache.QueryExecutorUtil;
 import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.engine.datastorage.Member;
@@ -42,13 +38,14 @@ import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
 import com.huawei.unibi.molap.engine.util.QueryExecutorUtility;
 import com.huawei.unibi.molap.iterator.MolapIterator;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthEquiSplitGenerator;
+import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthVariableSplitGenerator;
 import com.huawei.unibi.molap.metadata.MolapMetadata;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Measure;
 import com.huawei.unibi.molap.metadata.SliceMetaData;
 import com.huawei.unibi.molap.util.MolapProperties;
 import com.huawei.unibi.molap.util.MolapUtil;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 public class QueryExecutorImpl extends AbstractQueryExecutor
 {
@@ -303,7 +300,6 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         Dimension[] sortDims=getSelectedQueryDimensions(queryModel.getSortedDimensions(),queryDimensions);
         holder.metaData = sliceMataData;
         holder.setKeyGenerator(slice.getKeyGenerator(queryModel.getFactTable()));
-        holder.setQueryDimsCount(queryDimensions.length);
         if(!executerProperties.globalKeyGenerator.equals(slice.getKeyGenerator(queryModel.getFactTable())))
         {
             holder.updateRequired = true;
@@ -321,16 +317,14 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         }
         SliceExecutionInfo info = new SliceExecutionInfo();
         
-        FilterEvaluatorInfo filterInfo = getFilterInfo(queryModel, currentSliceIndex,sliceMataData);
-        filterInfo.setComplexTypesWithBlockStartIndex(QueryExecutorUtility.getAllComplexTypesBlockStartIndex(executerProperties.complexDimensionsMap));
-        QueryExecutorUtility.getComplexDimensionsKeySize(executerProperties.complexDimensionsMap, executerProperties.slices.get(currentSliceIndex).getDimensionCardinality());
-        filterInfo.setDimensions(executerProperties.dimTables);
+        FilterEvaluatorInfo filterInfo = getFilterInfo(queryModel, currentSliceIndex,sliceMataData,slice.getHybridStoreModel());
         if(null!=queryModel.getFilterExpression() && null!=slice.getDataCache(queryModel.getFactTable()))
         {
             info.setFilterEvaluatorTree(FilterUtil.getFilterEvaluator(queryModel.getFilterExpression(),
                     filterInfo));
         }
         info.setFileBasedQuery(queryModel.isDetailQuery());
+        info.setHybridStoreMeta(slice.getHybridStoreModel());
         info.setExecutionRequired(null!=slice.getDataCache(queryModel.getFactTable()));
         info.setCustomExpressions(queryModel.getExpressions());
         info.setCustomMeasure(queryModel.isAggTable());
@@ -343,8 +337,29 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         info.setSchemaName(executerProperties.schemaName);
         info.setQueryId(queryModel.getQueryId());
         info.setDetailQuery(queryModel.isDetailQuery());
-        int[] maskedByteRanges = QueryExecutorUtil.getMaskedByte(queryDimensions,
-                slice.getKeyGenerator(queryModel.getFactTable()));
+        //hybrid store related changes
+        int[] maskedByteRanges=null;
+        int[][] maskedByteRangeForSorting = null;
+        if(info.getHybridStoreMeta().isHybridStore())
+        {
+            info.setQueryDimOrdinal(QueryExecutorUtility.getSelectedDimensionStoreIndex(queryDimensions,info.getHybridStoreMeta()));
+            info.setAllSelectedDimensions(QueryExecutorUtility.getAllSelectedDiemnsionStoreIndex(queryDimensions,
+                    queryModel.getDimensionAggInfo(),executerProperties.aggExpDimensions,info.getHybridStoreMeta()));
+            maskedByteRanges = QueryExecutorUtil.getMaskedByte(queryDimensions,
+                    slice.getKeyGenerator(queryModel.getFactTable()),slice.getHybridStoreModel());
+            maskedByteRangeForSorting= QueryExecutorUtility.getMaskedByteRangeForSorting(sortDims,
+                    executerProperties.globalKeyGenerator, executerProperties.maskByteRanges,slice.getHybridStoreModel());
+        }
+        else
+        {
+            info.setQueryDimOrdinal(QueryExecutorUtility.getSelectedDimnesionIndex(queryDimensions));
+            info.setAllSelectedDimensions(QueryExecutorUtility.getAllSelectedDiemnsion(queryDimensions,
+                    queryModel.getDimensionAggInfo(),executerProperties.aggExpDimensions));
+            maskedByteRanges=QueryExecutorUtil.getMaskedByte(queryDimensions,
+                    slice.getKeyGenerator(queryModel.getFactTable()));
+            maskedByteRangeForSorting=QueryExecutorUtility.getMaskedByteRangeForSorting(sortDims,
+                    executerProperties.globalKeyGenerator, executerProperties.maskByteRanges);
+        }
         info.setMaskedKeyByteSize(maskedByteRanges.length);
         int[] maskedBytesLocal = new int[slice.getKeyGenerator(queryModel.getFactTable()).getKeySizeInBytes()];
         QueryExecutorUtil.updateMaskedKeyRanges(maskedBytesLocal, maskedByteRanges);
@@ -363,8 +378,7 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         info.setDimensionSortOrder(queryModel.getSortOrder());
         info.setUniqueValues(sliceUniqueValues);
         info.setOriginalDims(queryDimensions);
-        int[][] maskedByteRangeForSorting = QueryExecutorUtility.getMaskedByteRangeForSorting(sortDims,
-                executerProperties.globalKeyGenerator, executerProperties.maskByteRanges);
+       
         info.setMaskedByteRangeForSorting(maskedByteRangeForSorting);
         executerProperties.sortDimIndexes = QueryExecutorUtility.fillSortedDimensions(sortDims,queryModel.getDims());
         info.setSortedDimensionsIndex(executerProperties.sortDimIndexes);
@@ -372,8 +386,7 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
                 executerProperties.globalKeyGenerator, maskedByteRangeForSorting, executerProperties.maskByteRanges));
         if(slice.getDimensionCardinality().length > 0)
         {
-            info.setColumnarSplitter(new MultiDimKeyVarLengthEquiSplitGenerator(MolapUtil
-                    .getIncrementedCardinalityFullyFilled(slice.getDimensionCardinality()), (byte)1));
+            info.setColumnarSplitter(new MultiDimKeyVarLengthVariableSplitGenerator(MolapUtil.getDimensionBitLength(slice.getHybridStoreModel().getHybridCardinality(),slice.getHybridStoreModel().getDimensionPartitioner()),slice.getHybridStoreModel().getColumnSplit()));
         }
         info.setLimit(queryModel.getLimit());
         info.setDetailQuery(queryModel.isDetailQuery());
@@ -421,12 +434,7 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         {
             RestructureUtil.updateDimensionAggInfo(queryModel.getDimensionAggInfo(), sliceMataData.getDimensions());
         }
-        info.setQueryDimOrdinal(QueryExecutorUtility.getSelectedDimnesionIndex(queryDimensions));
-        info.setComplexQueryDimensions(QueryExecutorUtility.getAllComplexTypesBlockStartIndex(executerProperties.complexDimensionsMap));
-        info.setDimensions(executerProperties.dimTables);
-        getApplicableDataBlocksForAggDims(queryModel.getDimensionAggInfo(), currentDimTables);
-        info.setAllSelectedDimensions(QueryExecutorUtility.getAllSelectedDiemnsion(queryDimensions,
-                queryModel.getDimensionAggInfo(),executerProperties.aggExpDimensions));
+        
         info.setCurrentSliceIndex(currentSliceIndex);
         info.setMsrMinValue(executerProperties.msrMinValue);
         info.setAggType(executerProperties.aggTypes);
@@ -441,53 +449,20 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         return info;
     }
     
-    
-    private void getApplicableDataBlocksForAggDims(List<DimensionAggregatorInfo> dimensionAggInfo, Dimension[] currentDimTables)
-    {
-        List<Dimension> selectedQueryDimensions = new ArrayList<Dimension>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
-        for(int i = 0;i < dimensionAggInfo.size();i++)
-        {
-            Dimension dim = dimensionAggInfo.get(i).getDim();
-            for(int j = 0;j < currentDimTables.length;j++)
-            {
-                if(dim.equals(currentDimTables[j]))
-                {
-                    dim.setDataBlockIndex(currentDimTables[j].getDataBlockIndex());
-                    dim.setAllApplicableDataBlockIndexs(currentDimTables[j].getAllApplicableDataBlockIndexs());
-                    selectedQueryDimensions.add(dim);
-                    break;
-                }
-            }
-        }
-    }
-        
     private Dimension[] getSelectedQueryDimensions(Dimension[] dims, Dimension[] currentDimTables)
     {
-//            Map<String, ArrayList<Dimension>> complexTypesMap = prepareComplexDimensions(currentDimTables);
         List<Dimension> selectedQueryDimensions = new ArrayList<Dimension>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
-        Set<String> dimensionGroup = new LinkedHashSet<String>();
         for(int i = 0;i < dims.length;i++)
         {
-            dimensionGroup.add(dims[i].getHierName());
             for(int j = 0;j < currentDimTables.length;j++)
             {
                 if(dims[i].getTableName().equals(currentDimTables[j].getTableName()) && dims[i].getDimName().equals(currentDimTables[j].getDimName()))
                 {
-                    dims[i].setDataBlockIndex(currentDimTables[j].getDataBlockIndex());
-                    dims[i].setAllApplicableDataBlockIndexs(currentDimTables[j].getAllApplicableDataBlockIndexs());
                     selectedQueryDimensions.add(dims[i]);
                     break;
                 }
             }
         }
-//        for(String dimension : dimensionGroup)
-//        {
-//            for(Dimension d : complexTypesMap.get(dimension))
-//            {
-//                
-//                selectedQueryDimensions.add(d);
-//            }
-//        }
         return selectedQueryDimensions.toArray(new Dimension[selectedQueryDimensions.size()]);
     }
     
@@ -599,7 +574,7 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         }
     }
     
-    private FilterEvaluatorInfo getFilterInfo(MolapQueryExecutorModel queryModel,int currentSliceIndex, SliceMetaData sliceMetaData)
+    private FilterEvaluatorInfo getFilterInfo(MolapQueryExecutorModel queryModel,int currentSliceIndex, SliceMetaData sliceMetaData, HybridStoreModel hybridStoreModel)
     {
         FilterEvaluatorInfo info = new FilterEvaluatorInfo();
         info.setCurrentSliceIndex(currentSliceIndex);
@@ -612,6 +587,7 @@ public class QueryExecutorImpl extends AbstractQueryExecutor
         info.setNewDefaultValues(sliceMetaData.getNewMsrDfts());
         info.setNewDimensionDefaultValue(sliceMetaData.getNewDimsDefVals());
         info.setNewDimensionSurrogates(sliceMetaData.getNewDimsSurrogateKeys());
+        info.setHybridStoreModel(hybridStoreModel);
         return info;
     }
     
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryResultPreparator.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryResultPreparator.java
index 3a78691..391558d 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryResultPreparator.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/QueryResultPreparator.java
@@ -1,6 +1,5 @@
 package com.huawei.unibi.molap.engine.executer.impl;
 
-import java.nio.ByteBuffer;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
@@ -15,7 +14,6 @@ import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInf
 import com.huawei.unibi.molap.engine.aggregator.impl.CountAggregator;
 import com.huawei.unibi.molap.engine.aggregator.impl.DistinctCountAggregator;
 import com.huawei.unibi.molap.engine.aggregator.impl.DistinctStringCountAggregator;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.datastorage.Member;
 import com.huawei.unibi.molap.engine.executer.MolapQueryExecutorModel;
 import com.huawei.unibi.molap.engine.executer.pagination.impl.QueryResult;
@@ -88,9 +86,7 @@ public class QueryResultPreparator
         {
             return getEmptyChunkResult(result.size());
         }
-        queryModel.setComplexDimensionsMap(QueryExecutorUtility.getComplexDimensionsMap(executerProperties.dimTables));
-        QueryExecutorUtility.getComplexDimensionsKeySize(queryModel.getComplexDimensionsMap(), executerProperties.slices.get(currentSliceIndex).getDimensionCardinality());
-        Map<String, Integer> complexQueryIndexes = QueryExecutorUtility.getComplexQueryIndexes(queryModel.getDims(), executerProperties.dimTables);
+        
         while(iterator.hasNext())
         {
             ByteArrayWrapper keyWrapper = iterator.getKey();
@@ -98,7 +94,6 @@ public class QueryResultPreparator
                     executerProperties.maskedBytes);
             
             //CHECKSTYLE:OFF Approval No:Approval-V1R2C10_006
-            int index = 0;
             for(int i = 0;i < dimensionCount;i++)
             {
                 if(dims[i].isHighCardinalityDim() && null != keyWrapper.getDirectSurrogateKeyList())
@@ -111,15 +106,7 @@ public class QueryResultPreparator
                     {
                         continue;
                     }
-                    GenericQueryType complexType = queryModel.getComplexDimensionsMap().get(queryModel.getDims()[i].getColName());
-	                if(complexType == null)
-	                {
-	                    resultData[currentRow][i] = (int)keyArray[queryModel.getDims()[i].getOrdinal()];
-	                }
-	                else
-	                {
-	                    resultData[currentRow][i] = keyWrapper.getComplexTypeData(complexQueryIndexes.get(queryModel.getDims()[i].getColName()));
-	                }
+                    resultData[currentRow][i] = (int)keyArray[executerProperties.hybridStoreModel.getMdKeyOrdinal(queryModel.getDims()[i].getOrdinal())];
                 }
             }
             //CHECKSTYLE:ON
@@ -222,10 +209,7 @@ public class QueryResultPreparator
             row = new Object[recordSize];
             for(int i = 0;i < dimensionCount;i++)
             {
-                boolean isComplexType = false;
-                Object complexData = null;
-                GenericQueryType complexType = queryModel.getComplexDimensionsMap().get(queryModel.getDims()[i].getColName());
-                if(surrogateResult[i][columnIndex] instanceof byte[] && complexType == null)
+                if(surrogateResult[i][columnIndex] instanceof byte[])
                 {
                     member = new Member((byte[])surrogateResult[i][columnIndex]);
                 }
@@ -235,30 +219,15 @@ public class QueryResultPreparator
                 }
                 else
                 {
-                    if(complexType == null)
-                    {
-                        member = QueryExecutorUtility.getMemberBySurrogateKey(queryModel.getDims()[i],(Integer)surrogateResult[i][columnIndex], executerProperties.slices);
-                    }
-                    else
-                    {
-                        
-                        isComplexType = true;
-                        complexData = complexType.getDataBasedOnDataTypeFromSurrogates(executerProperties.slices, 
-                                ByteBuffer.wrap((byte[])surrogateResult[i][columnIndex]), executerProperties.dimTables);
-                    }
+                    member = QueryExecutorUtility.getMemberBySurrogateKey(queryModel.getDims()[i],(Integer)surrogateResult[i][columnIndex], executerProperties.slices);
                 }
 
-                if(!isComplexType)
-                {
                     memString = member.toString();
                     row[queryModel.getDims()[i].getQueryOrder()] = DataTypeConverter.getDataBasedOnDataType(
                             memString.equals(MolapCommonConstants.MEMBER_DEFAULT_VAL) ? null : memString,
                             queryModel.getDims()[i].getDataType());
-                }
-                else
-                {
-                    row[queryModel.getDims()[i].getQueryOrder()] = complexData;
-                }
+                
+
             }
             MeasureAggregator[] msrAgg = new MeasureAggregator[executerProperties.aggTypes.length];
             fillMeasureValueForAggGroupByQuery(queryModel, surrogateResult, dimensionCount, columnIndex,msrAgg);
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureHolder.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureHolder.java
index cefddc4..7f4e77f 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureHolder.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureHolder.java
@@ -41,21 +41,6 @@ public class RestructureHolder
     public int[] maskedByteRanges;
     
     /**
-     * maskedByteRanges
-     */
-    private int queryDimsCount;
-    
-    public int getQueryDimsCount()
-    {
-        return queryDimsCount;
-    }
-
-    public void setQueryDimsCount(int queryDimsCount)
-    {
-        this.queryDimsCount = queryDimsCount;
-    }
-
-    /**
      * holder keyGenerator;
      */
     private KeyGenerator keyGenerator;
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureUtil.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureUtil.java
index 70ca21d..ad938bc 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureUtil.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/impl/RestructureUtil.java
@@ -1,10 +1,8 @@
 package com.huawei.unibi.molap.engine.executer.impl;
 
-import java.util.ArrayList;
 import java.util.Iterator;
-import java.util.LinkedHashSet;
 import java.util.List;
-import java.util.Set;
+import java.util.ArrayList;
 
 import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInfo;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
@@ -34,11 +32,6 @@ public final class RestructureUtil
         boolean found/* = false*/;
         int len = 0;
         String[] sMetaDims = sliceMataData.getDimensions();
-//        Set<String> queryDimGroup = new LinkedHashSet<String>();
-//        for(Dimension dim : queryDims)
-//        {
-//            queryDimGroup.add(dim.getHierName());
-//        }
 //        Dimension[] currentDimTables = new Dimension[sMetaDims.length];
         List<Dimension> crntDims= new ArrayList<Dimension>();
         for(int i = 0;i < executerProperties.dimTables.length;i++)
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/processor/ScannedResultProcessorImpl.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/processor/ScannedResultProcessorImpl.java
index ee8b136..7b12399 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/processor/ScannedResultProcessorImpl.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/executer/processor/ScannedResultProcessorImpl.java
@@ -114,9 +114,8 @@ public class ScannedResultProcessorImpl implements ScannedResultProcessor
     {
         if(!info.isDetailQuery())
         {
-//            mergedScannedResult = new TrieBasedResult(info.getColumnarSplitter().getKeySizeByBlock(
-//                    info.getQueryDimOrdinal()));
             mergedScannedResult = new MapBasedResult();
+//            mergedScannedResult = new MapBasedResult();
         }
         else
         {
@@ -241,14 +240,7 @@ public class ScannedResultProcessorImpl implements ScannedResultProcessor
                 processor.initialise(dataProcessorInfo);
                 for(int i = 0;i < sortedResult.length;i++)
                 {
-                    if(sortedResult[i].key.getCompleteComplexTypeData() == null)
-                    {
-                        processor.processRow(sortedResult[i].key.getMaskedKey(), sortedResult[i].value);
-                    }
-                    else
-                    {
-                        processor.processRow(sortedResult[i].key, sortedResult[i].value);
-                    }
+                    processor.processRow(sortedResult[i].key, sortedResult[i].value);
                 }
             }
             catch(DataProcessorException e)
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/expression/DataType.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/expression/DataType.java
index d4711c1..84c0b27 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/expression/DataType.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/expression/DataType.java
@@ -1,7 +1,7 @@
 package com.huawei.unibi.molap.engine.expression;
 
 public enum DataType {
-    StringType(0), DateType(1), TimestampType(2), BooleanType(1), IntegerType(3), FloatType(4), LongType(5), DoubleType(6), NullType(7), ArrayType(8), StructType(9);
+    StringType(0), DateType(1), TimestampType(2), BooleanType(1), IntegerType(3), FloatType(4), LongType(5), DoubleType(6), NullType(7);
     private int presedenceOrder;
     public int getPresedenceOrder()
     {
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/filters/measurefilter/util/FilterUtil.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/filters/measurefilter/util/FilterUtil.java
index 9217641..b9839d0 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/filters/measurefilter/util/FilterUtil.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/filters/measurefilter/util/FilterUtil.java
@@ -44,7 +44,7 @@ import com.huawei.unibi.molap.keygenerator.KeyGenException;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.keygenerator.factory.KeyGeneratorFactory;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
-import com.huawei.unibi.molap.olap.SqlStatement.Type;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 import com.huawei.unibi.molap.engine.datastorage.MemberStore;
 
 
@@ -119,9 +119,7 @@ public final class FilterUtil
         {
         case EQUALS:
             currentCondExpression = (BinaryConditionalExpression)expression;
-            if(currentCondExpression.isSingleDimension() && 
-                    currentCondExpression.getColumnList().get(0).getDim().getDataType() != Type.ARRAY && 
-                    currentCondExpression.getColumnList().get(0).getDim().getDataType() != Type.STRUCT)
+            if(currentCondExpression.isSingleDimension())
             {
                 
                 int newDimensionIndex=QueryExecutorUtility.isNewDimension(info.getNewDimension(), currentCondExpression.getColumnList().get(0).getDim());
@@ -146,7 +144,7 @@ public final class FilterUtil
                         }
                     return new NonUniqueBlockEqualsEvalutor(expression, isExpressionResolve,true);
                 }
-                else if(dataCache.getAggKeyBlock()[currentCondExpression.getColumnList().get(0).getDim().getOrdinal()])
+                else if(dataCache.getAggKeyBlock()[getDimensionStoreOrdinal(currentCondExpression.getColumnList().get(0).getDim().getOrdinal(),info.getHybridStoreModel())])
                 {
                     return new UniqueBlockEqualsEvalutor(expression, isExpressionResolve,true);
                 }
@@ -165,9 +163,7 @@ public final class FilterUtil
         case NOT_EQUALS:
             
             currentCondExpression = (BinaryConditionalExpression)expression;
-            if(currentCondExpression.isSingleDimension() && 
-                    currentCondExpression.getColumnList().get(0).getDim().getDataType() != Type.ARRAY && 
-                    currentCondExpression.getColumnList().get(0).getDim().getDataType() != Type.STRUCT)
+            if(currentCondExpression.isSingleDimension())
             {
                 int newDimensionIndex=QueryExecutorUtility.isNewDimension(info.getNewDimension(), currentCondExpression.getColumnList().get(0).getDim());
                 if(newDimensionIndex==-1)
@@ -207,10 +203,7 @@ public final class FilterUtil
                 }
             }
         default:
-            condExpression = (ConditionalExpression)expression;
-            if(condExpression.isSingleDimension() && 
-                    condExpression.getColumnList().get(0).getDim().getDataType() != Type.ARRAY && 
-                    condExpression.getColumnList().get(0).getDim().getDataType() != Type.STRUCT)
+            if(expression instanceof ConditionalExpression)
             {
                 condExpression = (ConditionalExpression)expression;
                 if(condExpression.isSingleDimension())
@@ -261,6 +254,12 @@ public final class FilterUtil
         }
     }
     
+    private static int getDimensionStoreOrdinal(int ordinal, HybridStoreModel hybridStoreModel)
+    {
+        return hybridStoreModel.getStoreIndex(ordinal);
+        
+    }
+
     /**
      * This method will check if a given expression contains a column expression recursively.
      * 
@@ -341,14 +340,9 @@ public final class FilterUtil
 
     {
         List<byte[]> filterValuesList = new ArrayList<byte[]>(20);
-//        if(columnExpression.getDim().getDataType() == Type.ARRAY || 
-//                columnExpression.getDim().getDataType() == Type.STRUCT)
-//        {
-//            return filterValuesList;
-//        }
         int[] keys = new int[info.getKeyGenerator().getDimCount()];
         Arrays.fill(keys, 0);
-        int[] rangesForMaskedByte = getRangesForMaskedByte(columnExpression.getDim().getOrdinal(),
+        int[] rangesForMaskedByte = getRangesForMaskedByte(info.getHybridStoreModel().getMdKeyOrdinal(columnExpression.getDim().getOrdinal()),
                 info.getKeyGenerator());
         List<Integer> surrogates = new ArrayList<Integer>(20);
         for(String result : evaluateResultList)
@@ -368,7 +362,7 @@ public final class FilterUtil
         {
             try
             {
-                keys[columnExpression.getDim().getOrdinal()]=surrogate;
+                keys[info.getHybridStoreModel().getMdKeyOrdinal(columnExpression.getDim().getOrdinal())]=surrogate;
                 filterValuesList.add(getMaskedKey(rangesForMaskedByte, info.getKeyGenerator().generateKey(keys)));
             }
             catch(KeyGenException e)
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/DataProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/DataProcessor.java
index 6320fc0..9cf5f6f 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/DataProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/DataProcessor.java
@@ -4,7 +4,6 @@ import com.huawei.unibi.molap.engine.aggregator.MeasureAggregator;
 import com.huawei.unibi.molap.engine.executer.pagination.impl.QueryResult;
 import com.huawei.unibi.molap.engine.processor.exception.DataProcessorException;
 import com.huawei.unibi.molap.engine.schema.metadata.DataProcessorInfo;
-import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
 import com.huawei.unibi.molap.iterator.MolapIterator;
 
 
@@ -16,8 +15,6 @@ public interface DataProcessor
     
     //void processRow(ByteArrayWrapper key, MeasureAggregator[] value) throws DataProcessorException;
 
-    void processRow(ByteArrayWrapper key, MeasureAggregator[] value) throws DataProcessorException;
-
     void finish() throws DataProcessorException;
 
     MolapIterator<QueryResult> getQueryResultIterator();
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/FileBasedLimitProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/FileBasedLimitProcessor.java
index d4f3df9..087c0f7 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/FileBasedLimitProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/FileBasedLimitProcessor.java
@@ -36,7 +36,7 @@ public class FileBasedLimitProcessor implements DataProcessorExt
             counter++;
         }
     }
-    
+
     @Override
     public void finish() throws DataProcessorException
     {
@@ -49,7 +49,6 @@ public class FileBasedLimitProcessor implements DataProcessorExt
         // TODO Auto-generated method stub
         return processor.getQueryResultIterator();
     }
-    
     @Override
     public void processRow(ByteArrayWrapper key, MeasureAggregator[] value) throws DataProcessorException
     {
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/MemoryBasedLimitProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/MemoryBasedLimitProcessor.java
index 2afdb73..5e85502 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/MemoryBasedLimitProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/MemoryBasedLimitProcessor.java
@@ -54,7 +54,7 @@ public class MemoryBasedLimitProcessor implements DataProcessorExt
         }
         
     }
-    
+
     /**
      * While processing the row the direct surrogate key values will be added directly as byte[] to
      * ByteArrayWrapper instance, Internally list will be maintaned in each ByteArrayWrapper instance
@@ -69,18 +69,10 @@ public class MemoryBasedLimitProcessor implements DataProcessorExt
             List<byte []> listOfDirectKey=key.getDirectSurrogateKeyList();
             if(null!=listOfDirectKey)
             {
-                for(byte[] byteArray:listOfDirectKey)
-                {
-                    arrayWrapper.addToDirectSurrogateKeyList(byteArray);
-                }
-            }
-            List<byte []> listOfComplexTypes=key.getCompleteComplexTypeData();
-            if(null!=listOfComplexTypes)
+            for(byte[] byteArray:listOfDirectKey)
             {
-                for(byte[] byteArray:listOfComplexTypes)
-                {
-                    arrayWrapper.addComplexTypeData(byteArray);
-                }
+                arrayWrapper.addToDirectSurrogateKeyList(byteArray);
+            }
             }
             result.add(arrayWrapper, value);
         }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/sort/SortMeasureProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/sort/SortMeasureProcessor.java
index 5c1f1c3..deac1bd 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/sort/SortMeasureProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/sort/SortMeasureProcessor.java
@@ -26,7 +26,6 @@ import com.huawei.unibi.molap.engine.processor.DataProcessor;
 import com.huawei.unibi.molap.engine.processor.exception.DataProcessorException;
 import com.huawei.unibi.molap.engine.schema.metadata.DataProcessorInfo;
 import com.huawei.unibi.molap.engine.util.ScannedResultProcessorUtil;
-import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
 import com.huawei.unibi.molap.engine.writer.HeapBasedDataFileWriterThread;
 import com.huawei.unibi.molap.iterator.MolapIterator;
 
@@ -109,12 +108,7 @@ public class SortMeasureProcessor implements DataProcessor
     {
         addRow(key, value);
     }
-    
-    @Override
-    public void processRow(ByteArrayWrapper key, MeasureAggregator[] value) throws DataProcessorException
-    {
-        processRow(key.getMaskedKey(), value);
-    }
+
     /*
      * (non-Javadoc)
      * 
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/BlockWriterProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/BlockWriterProcessor.java
index 545d2b7..0648afd 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/BlockWriterProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/BlockWriterProcessor.java
@@ -171,7 +171,7 @@ public class BlockWriterProcessor implements DataProcessorExt
         entryCount++;
         rowCount++;
     }
-    
+
     /**
      *  This method is for closing the streams.
      */
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/RowWriterProcessor.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/RowWriterProcessor.java
index 8345e53..338de24 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/RowWriterProcessor.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/processor/writer/RowWriterProcessor.java
@@ -14,7 +14,6 @@ import com.huawei.unibi.molap.engine.processor.DataProcessor;
 import com.huawei.unibi.molap.engine.processor.exception.DataProcessorException;
 import com.huawei.unibi.molap.engine.schema.metadata.DataProcessorInfo;
 import com.huawei.unibi.molap.engine.util.MolapEngineLogEvent;
-import com.huawei.unibi.molap.engine.wrappers.ByteArrayWrapper;
 import com.huawei.unibi.molap.iterator.MolapIterator;
 import com.huawei.unibi.molap.util.MolapUtil;
 
@@ -111,13 +110,7 @@ public class RowWriterProcessor implements DataProcessor
         }
         entryCount++;
     }
-    
-    @Override
-    public void processRow(ByteArrayWrapper key, MeasureAggregator[] value) throws DataProcessorException
-    {
-        processRow(key.getMaskedKey(), value);
-    }
-    
+
     @Override
     public void finish() throws DataProcessorException
     {
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/FilterEvaluatorInfo.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/FilterEvaluatorInfo.java
index 1c74d72..2613986 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/FilterEvaluatorInfo.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/FilterEvaluatorInfo.java
@@ -1,13 +1,11 @@
 package com.huawei.unibi.molap.engine.schema.metadata;
 
 import java.util.List;
-import java.util.Map;
 
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.engine.executer.impl.QueryFilterInfo;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 public class FilterEvaluatorInfo
 {
@@ -23,8 +21,6 @@ public class FilterEvaluatorInfo
     
     private String[] newDimension;
     
-    private Dimension[] dimensions;
-    
     private String[] newMeasures;
     
     private double[] newDefaultValues;
@@ -32,28 +28,8 @@ public class FilterEvaluatorInfo
     private int[] newDimensionSurrogates;
     
     private String[] newDimensionDefaultValue;
-    
-    private Map<Integer, GenericQueryType> complexTypesWithBlockStartIndex; 
-
-    public Dimension[] getDimensions()
-    {
-        return dimensions;
-    }
 
-    public void setDimensions(Dimension[] dimensions)
-    {
-        this.dimensions = dimensions;
-    }
-    
-    public Map<Integer, GenericQueryType> getComplexTypesWithBlockStartIndex()
-    {
-        return complexTypesWithBlockStartIndex;
-    }
-
-    public void setComplexTypesWithBlockStartIndex(Map<Integer, GenericQueryType> complexTypesWithBlockStartIndex)
-    {
-        this.complexTypesWithBlockStartIndex = complexTypesWithBlockStartIndex;
-    }
+    private HybridStoreModel hybridStoreModel;
 
     public List<InMemoryCube> getSlices()
     {
@@ -154,4 +130,15 @@ public class FilterEvaluatorInfo
     {
         this.newDimensionDefaultValue = newDimensionDefaultValue;
     }
+
+    public void setHybridStoreModel(HybridStoreModel hybridStoreModel)
+    {
+        this.hybridStoreModel=hybridStoreModel;
+        
+    }
+    
+    public HybridStoreModel getHybridStoreModel()
+    {
+        return this.hybridStoreModel;
+    }
 }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/SliceExecutionInfo.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/SliceExecutionInfo.java
index d5c8d66..7d93c25 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/SliceExecutionInfo.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/schema/metadata/SliceExecutionInfo.java
@@ -22,11 +22,8 @@ import java.util.List;
 //import java.util.Set;
 
 
-import java.util.Map;
-
 import com.huawei.unibi.molap.engine.aggregator.CustomMolapAggregateExpression;
 import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInfo;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
 import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.engine.datastorage.storeInterfaces.DataStoreBlock;
 import com.huawei.unibi.molap.engine.directinterface.impl.MeasureSortModel;
@@ -37,6 +34,7 @@ import com.huawei.unibi.molap.engine.filters.measurefilter.GroupMeasureFilterMod
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
 import com.huawei.unibi.molap.keygenerator.columnar.ColumnarSplitter;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 /**
  * 
@@ -76,7 +74,6 @@ public class SliceExecutionInfo
      */
     private Dimension[] queryDimensions;
 
-    
     /**
      * 
      */
@@ -334,29 +331,8 @@ public class SliceExecutionInfo
 
     private boolean[] highCardinalityTypes;
     
-    private Dimension[] dimensions;
-    
-    public Dimension[] getDimensions()
-    {
-        return dimensions;
-    }
-
-    public void setDimensions(Dimension[] dimensions)
-    {
-        this.dimensions = dimensions;
-    }
-
-    private Map<Integer, GenericQueryType> complexQueryDimensions;
-    
-    public Map<Integer, GenericQueryType> getComplexQueryDimensions()
-    {
-        return complexQueryDimensions;
-    }
 
-    public void setComplexQueryDimensions(Map<Integer, GenericQueryType> complexQueryDimensions)
-    {
-        this.complexQueryDimensions = complexQueryDimensions;
-    }
+    private HybridStoreModel hybridStoreMeta;
 
     /**
      * 
@@ -1149,6 +1125,16 @@ public class SliceExecutionInfo
         this.isFileBasedQuery = isFileBasedQuery;
     }
 
+    public void setHybridStoreMeta(HybridStoreModel hybridStoreMeta)
+    {
+       this.hybridStoreMeta=hybridStoreMeta;
+        
+    }
+    
+    public HybridStoreModel getHybridStoreMeta()
+    {
+        return this.hybridStoreMeta;
+    }
     /**
      * setHighCardinalityType.
      * @param highCardinalityTypes
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/util/QueryExecutorUtility.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/util/QueryExecutorUtility.java
index 3c484c8..27f8ae8 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/util/QueryExecutorUtility.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/util/QueryExecutorUtility.java
@@ -2,7 +2,6 @@ package com.huawei.unibi.molap.engine.util;
 
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
@@ -13,10 +12,7 @@ import java.util.TreeSet;
 
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
 import com.huawei.unibi.molap.engine.aggregator.dimension.DimensionAggregatorInfo;
-import com.huawei.unibi.molap.engine.complex.querytypes.ArrayQueryType;
-import com.huawei.unibi.molap.engine.complex.querytypes.GenericQueryType;
-import com.huawei.unibi.molap.engine.complex.querytypes.PrimitiveQueryType;
-import com.huawei.unibi.molap.engine.complex.querytypes.StructQueryType;
+import com.huawei.unibi.molap.engine.cache.QueryExecutorUtil;
 import com.huawei.unibi.molap.engine.datastorage.CubeDataStore;
 import com.huawei.unibi.molap.engine.datastorage.InMemoryCube;
 import com.huawei.unibi.molap.engine.datastorage.Member;
@@ -25,20 +21,11 @@ import com.huawei.unibi.molap.engine.executer.exception.QueryExecutionException;
 import com.huawei.unibi.molap.engine.schema.metadata.SliceUniqueValueInfo;
 import com.huawei.unibi.molap.keygenerator.KeyGenException;
 import com.huawei.unibi.molap.keygenerator.KeyGenerator;
-import com.huawei.unibi.molap.keygenerator.columnar.impl.MultiDimKeyVarLengthEquiSplitGenerator;
 import com.huawei.unibi.molap.metadata.MolapMetadata;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Dimension;
 import com.huawei.unibi.molap.metadata.MolapMetadata.Measure;
 import com.huawei.unibi.molap.metadata.SliceMetaData;
-import com.huawei.unibi.molap.olap.MolapDef;
-import com.huawei.unibi.molap.olap.MolapDef.Cube;
-import com.huawei.unibi.molap.olap.MolapDef.CubeDimension;
-import com.huawei.unibi.molap.olap.MolapDef.Hierarchy;
-import com.huawei.unibi.molap.olap.MolapDef.Level;
-import com.huawei.unibi.molap.olap.MolapDef.Schema;
-import com.huawei.unibi.molap.olap.SqlStatement.Type;
-import com.huawei.unibi.molap.olap.SqlStatement;
-import com.huawei.unibi.molap.util.MolapUtil;
+import com.huawei.unibi.molap.vo.HybridStoreModel;
 
 public final class QueryExecutorUtility
 {
@@ -340,6 +327,56 @@ public final class QueryExecutorUtility
         
         return dimensionCompareIndex;
     }
+    public static int[][] getMaskedByteRangeForSorting(Dimension[] queryDimensions, KeyGenerator generator,int[] maskedRanges,HybridStoreModel hybridStoreModel)
+    {
+      
+            int[][] dimensionCompareIndex= new int[queryDimensions.length][];
+            int index=0;
+            for(int i = 0;i < queryDimensions.length;i++)
+            {
+                if(queryDimensions[i].isHighCardinalityDim())
+                {
+                    continue;
+                }
+                Set<Integer> integers = new TreeSet<Integer>();
+                
+                int[] range = generator.getKeyByteOffsets(hybridStoreModel.getMdKeyOrdinal(queryDimensions[i].getOrdinal()));
+                
+                for(int j = range[0];j <= range[1];j++)
+                {
+                    integers.add(j);
+                }
+                dimensionCompareIndex[index]=new int[integers.size()];
+                int j = 0;
+                for(Iterator<Integer> iterator = integers.iterator();iterator.hasNext();)
+                {
+                    Integer integer = (Integer)iterator.next();
+                     dimensionCompareIndex[index][j++] = integer.intValue();
+                }
+                index++;
+            }
+            
+            for(int i = 0;i < dimensionCompareIndex.length;i++)
+            {
+                int[] range = dimensionCompareIndex[i];
+                for(int j = 0;j < range.length;j++)
+                {
+                    for(int k = 0;k < maskedRanges.length;k++)
+                    {
+                        if(range[j] == maskedRanges[k])
+                        {
+                            range[j] = k;
+                            break;
+                        }
+                    }
+                }
+            }
+            return dimensionCompareIndex;
+       
+        
+        
+       
+    }
     
     public static byte[][] getMaksedKeyForSorting(Dimension[] queryDimensions, KeyGenerator generator,
             int[][] dimensionCompareIndex, int[] maskedRanges) throws QueryExecutionException
@@ -385,188 +422,89 @@ public final class QueryExecutorUtility
     //@TODO need to handle for restructuring scenario 
     public static int[] getSelectedDimnesionIndex(Dimension[] queryDims)
     {
-//        int[] selectedDimsIndex= new int[queryDims.length];
-//        for(int i = 0;i < queryDims.length;i++)
-//        {
-//            selectedDimsIndex[i]=queryDims[i].getOrdinal();
-//        }
-//        Arrays.sort(selectedDimsIndex);
-//        return selectedDimsIndex;
-        // updated for block index size with complex types
-        Set<Integer> allQueryDimension = new HashSet<Integer>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
+        int[] selectedDimsIndex= new int[queryDims.length];
         for(int i = 0;i < queryDims.length;i++)
         {
-            if(queryDims[i].getAllApplicableDataBlockIndexs().length > 1)
-            {
-                for(int eachBlockIndex : queryDims[i].getAllApplicableDataBlockIndexs())
-                {
-                    allQueryDimension.add(eachBlockIndex);
-                }
-            }
-            else
-            {
-                allQueryDimension.add(queryDims[i].getOrdinal());
-            }
-        }
-        return convertIntegerArrayToInt(allQueryDimension.toArray(new Integer[allQueryDimension.size()]));
-    }
-    
-    public static Map<Integer, GenericQueryType> getQueryComplexTypes(
-            Dimension[] queryDimensions, Map<String, GenericQueryType> complexDimensionsMap)
-    {
-        Map<Integer, GenericQueryType> queryComplexMap = new HashMap<Integer, GenericQueryType>();
-        for(Dimension d : queryDimensions)
-        {
-            GenericQueryType complexType = complexDimensionsMap.get(d.getHierName());
-            if(complexType != null)
-            {
-                queryComplexMap.put(d.getDataBlockIndex(), complexDimensionsMap.get(d.getHierName()));
-            }
+            selectedDimsIndex[i]=queryDims[i].getOrdinal();
         }
-        return queryComplexMap;
+        Arrays.sort(selectedDimsIndex);
+        return selectedDimsIndex;
     }
-    
-    public static Map<Integer, GenericQueryType> getAllComplexTypesBlockStartIndex(
-           Map<String, GenericQueryType> complexDimensionsMap)
-    {
-        Map<Integer, GenericQueryType> queryComplexMap = new HashMap<Integer, GenericQueryType>();
-        for(Map.Entry<String, GenericQueryType> d : complexDimensionsMap.entrySet())
-        {
-                queryComplexMap.put(d.getValue().getBlockIndex(), d.getValue());
-        }
-        return queryComplexMap;
-    }
-    
     /**
-     * @param cube
+     * This method will get store index for each ordinal
+     * by default all dimension part of row store, their index will be 0
+     * 
+     * @param queryDims
+     * @param hybridStoreModel
      * @return
      */
-    public static Map<String,GenericQueryType> getComplexDimensionsMap(Dimension[] currentDimTables)
-    {  
-        Map<String,GenericQueryType> complexTypeMap = new HashMap<String,GenericQueryType>();
-        
-        Map<String, ArrayList<Dimension>> complexDimensions = new HashMap<String, ArrayList<Dimension>>();
-        for(int i = 0;i < currentDimTables.length;i++)
+    public static int[] getSelectedDimensionStoreIndex(Dimension[] queryDims,HybridStoreModel hybridStoreModel)
+    {
+        //it can be possible that multiple queryDim will be part of row store and hence .if row store index is already added then its not required to add again.
+        Set<Integer> selectedDimensionList=new HashSet<Integer>(queryDims.length);
+        int highCardStartIndex=hybridStoreModel.getColumnStoreOrdinals().length+1;
+        for(Dimension dimension:queryDims)
         {
-            ArrayList<Dimension> dimensions = complexDimensions.get(currentDimTables[i].getHierName());
-            if(dimensions != null)
+            if(dimension.isHighCardinalityDim())
             {
-                dimensions.add(currentDimTables[i]);
+                selectedDimensionList.add(highCardStartIndex++);
             }
             else
             {
-                dimensions = new ArrayList<Dimension>();
-                dimensions.add(currentDimTables[i]);
+                int storeIndex=hybridStoreModel.getStoreIndex(dimension.getOrdinal());
+                selectedDimensionList.add(storeIndex);
             }
-            complexDimensions.put(currentDimTables[i].getHierName(), dimensions);
         }
-        for (Map.Entry<String, ArrayList<Dimension>> entry : complexDimensions.entrySet())
+        for(int i = 0;i < queryDims.length;i++)
         {
-            if(entry.getValue().size() > 1)
-            {
-                Dimension dimZero = entry.getValue().get(0);
-                GenericQueryType g = dimZero.getDataType().equals(SqlStatement.Type.ARRAY)?
-                        new ArrayQueryType(dimZero.getColName(), "", dimZero.getDataBlockIndex()):new StructQueryType(dimZero.getColName(), "", dimZero.getDataBlockIndex());
-                complexTypeMap.put(dimZero.getColName(), g);
-                for(int i=1;i<entry.getValue().size();i++)
-                {
-                    Dimension dim = entry.getValue().get(i);
-                    switch(dim.getDataType())
-                    {
-                        case ARRAY : 
-                            g.addChildren(new ArrayQueryType(dim.getColName(), dim.getParentName(), dim.getDataBlockIndex()));
-                            break;
-                        case STRUCT : 
-                            g.addChildren(new StructQueryType(dim.getColName(), dim.getParentName(), dim.getDataBlockIndex()));
-                            break;
-                        default :
-                            g.addChildren(new PrimitiveQueryType(dim.getColName(), dim.getParentName(), dim.getDataBlockIndex(), dim.getDataType()));
-                    }
-                }
-            }
+            int storeIndex=hybridStoreModel.getStoreIndex(queryDims[i].getOrdinal());
+            selectedDimensionList.add(storeIndex);
         }
-        
-        return complexTypeMap;
+        int[] selectedDimsIndex=QueryExecutorUtil.convertIntegerListToIntArray(selectedDimensionList);
+        Arrays.sort(selectedDimsIndex);
+        return selectedDimsIndex;
     }
     
-    public static void getComplexDimensionsKeySize(Map<String, GenericQueryType> complexDimensionsMap, int[] dimensionCardinality)
+    public static int[] getAllSelectedDiemnsion(Dimension[] queryDims, List<DimensionAggregatorInfo> dimAggInfo, List<Dimension> fromCustomExps)
     {
-        int keyBlockSize[] = new MultiDimKeyVarLengthEquiSplitGenerator(
-                MolapUtil.getIncrementedCardinalityFullyFilled(dimensionCardinality), (byte)1)
-                .getBlockKeySize();
-        for (Map.Entry<String, GenericQueryType> entry : complexDimensionsMap.entrySet())
+        Set<Integer> allQueryDimension = new HashSet<Integer>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
+        for(int i = 0;i < queryDims.length;i++)
         {
-            entry.getValue().setKeySize(keyBlockSize);
+            allQueryDimension.add(queryDims[i].getOrdinal());
         }
-    }
-    
-    public static Map<String, Integer> getComplexQueryIndexes(Dimension[] queryDims, Dimension[] currentDimTables)
-    {
-        Map<String, Integer> colToDataMap = new HashMap<String, Integer>();
-        boolean[] dimPresent = new boolean[currentDimTables.length];
-        for(Dimension queryDim : queryDims)
+        for(int i=0;i<dimAggInfo.size();i++)
         {
-            for(int i=0;i<currentDimTables.length;i++)
+            if(dimAggInfo.get(i).isDimensionPresentInCurrentSlice())
             {
-                if(currentDimTables[i].getColName().equals(queryDim.getColName()) && 
-                        (currentDimTables[i].getDataType() == Type.ARRAY || 
-                        currentDimTables[i].getDataType() == Type.STRUCT))
-                {
-                    dimPresent[i] = true;
-                    break;
-                }
+                allQueryDimension.add(dimAggInfo.get(i).getDim().getOrdinal());
             }
         }
-        int index=0;
-        for(int i=0;i<dimPresent.length;i++)
+        
+        for(int i=0;i<fromCustomExps.size();i++)
         {
-            if(dimPresent[i] == true)
-            {
-                colToDataMap.put(currentDimTables[i].getColName(), index++);
-            }
+            allQueryDimension.add(fromCustomExps.get(i).getOrdinal());
         }
-        return colToDataMap;
+        return convertIntegerArrayToInt(allQueryDimension.toArray(new Integer[allQueryDimension.size()]));
     }
     
-    public static int[] getAllSelectedDiemnsion(Dimension[] queryDims, List<DimensionAggregatorInfo> dimAggInfo, List<Dimension> fromCustomExps)
+    public static int[] getAllSelectedDiemnsionStoreIndex(Dimension[] queryDims, List<DimensionAggregatorInfo> dimAggInfo, List<Dimension> fromCustomExps,HybridStoreModel hybridStoreModel)
     {
-        //Updated to get multiple column blocks for complex types
         Set<Integer> allQueryDimension = new HashSet<Integer>(MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
         for(int i = 0;i < queryDims.length;i++)
         {
-            if(queryDims[i].getAllApplicableDataBlockIndexs().length > 1)
-            {
-                for(int eachBlockIndex : queryDims[i].getAllApplicableDataBlockIndexs())
-                {
-                    allQueryDimension.add(eachBlockIndex);
-                }
-            }
-            else
-            {
-                allQueryDimension.add(queryDims[i].getOrdinal());
-            }
+            allQueryDimension.add(hybridStoreModel.getStoreIndex(queryDims[i].getOrdinal()));
         }
         for(int i=0;i<dimAggInfo.size();i++)
         {
             if(dimAggInfo.get(i).isDimensionPresentInCurrentSlice())
             {
-                if(dimAggInfo.get(i).getDim().getAllApplicableDataBlockIndexs().length > 1)
-                {
-                    for(int eachBlockIndex : dimAggInfo.get(i).getDim().getAllApplicableDataBlockIndexs())
-                    {
-                        allQueryDimension.add(eachBlockIndex);
-                    }
-                }
-                else
-                {
-                    allQueryDimension.add(dimAggInfo.get(i).getDim().getOrdinal());
-                }
+                allQueryDimension.add(hybridStoreModel.getStoreIndex(dimAggInfo.get(i).getDim().getOrdinal()));
             }
         }
         
         for(int i=0;i<fromCustomExps.size();i++)
         {
-            allQueryDimension.add(fromCustomExps.get(i).getOrdinal());
+            allQueryDimension.add(hybridStoreModel.getStoreIndex(fromCustomExps.get(i).getOrdinal()));
         }
         return convertIntegerArrayToInt(allQueryDimension.toArray(new Integer[allQueryDimension.size()]));
     }
diff --git a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/wrappers/ByteArrayWrapper.java b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/wrappers/ByteArrayWrapper.java
index ea320bc..1008e35 100644
--- a/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/wrappers/ByteArrayWrapper.java
+++ b/Molap/Molap-Engine/src/com/huawei/unibi/molap/engine/wrappers/ByteArrayWrapper.java
@@ -58,32 +58,13 @@ public class ByteArrayWrapper implements Comparable<ByteArrayWrapper>,Serializab
     
     List<byte[]> listOfDirectSurrogateVal;
 
-    protected List<byte[]> complexTypesData;
-    
     public ByteArrayWrapper()
     {
-        this.complexTypesData = new ArrayList<byte[]>();
     }
     
     public ByteArrayWrapper(XXHash32 xxHash32)
     {
        this.xxHash32 = xxHash32;
-       this.complexTypesData = new ArrayList<byte[]>();
-    }
-    
-    public byte[] getComplexTypeData(int index)
-    {
-        return complexTypesData.get(index);
-    }
-    
-    public List<byte[]> getCompleteComplexTypeData()
-    {
-        return complexTypesData;
-    }
-    
-    public void addComplexTypeData(byte[] data)
-    {
-        complexTypesData.add(data);
     }
 
     /**
diff --git a/Molap/Molap-Interface/.settings/org.eclipse.jdt.core.prefs b/Molap/Molap-Interface/.settings/org.eclipse.jdt.core.prefs
deleted file mode 100644
index 8000cd6..0000000
--- a/Molap/Molap-Interface/.settings/org.eclipse.jdt.core.prefs
+++ /dev/null
@@ -1,11 +0,0 @@
-eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.6
-org.eclipse.jdt.core.compiler.codegen.unusedLocal=preserve
-org.eclipse.jdt.core.compiler.compliance=1.6
-org.eclipse.jdt.core.compiler.debug.lineNumber=generate
-org.eclipse.jdt.core.compiler.debug.localVariable=generate
-org.eclipse.jdt.core.compiler.debug.sourceFile=generate
-org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
-org.eclipse.jdt.core.compiler.problem.enumIdentifier=error
-org.eclipse.jdt.core.compiler.source=1.6
diff --git a/Molap/Molap-Logging-Service/src/com/huawei/iweb/platform/logging/impl/StandardLogService.java b/Molap/Molap-Logging-Service/src/com/huawei/iweb/platform/logging/impl/StandardLogService.java
index b837c9b..ed4b4b1 100644
--- a/Molap/Molap-Logging-Service/src/com/huawei/iweb/platform/logging/impl/StandardLogService.java
+++ b/Molap/Molap-Logging-Service/src/com/huawei/iweb/platform/logging/impl/StandardLogService.java
@@ -30,6 +30,7 @@ import com.huawei.iweb.platform.logging.Level;
 import com.huawei.iweb.platform.logging.LocaleLogMessageFinder;
 import com.huawei.iweb.platform.logging.LogEvent;
 import com.huawei.iweb.platform.logging.LogService;
+import org.apache.log4j.PropertyConfigurator;
 
 /**
  * Default Implementation of the <code>LogService</code>
@@ -124,7 +125,7 @@ public final class StandardLogService implements LogService
     	props.setProperty("log4j.logger.com.huawei", logLevel+",stdout");
     	props.setProperty("log4j.logger.com.huawei", logLevel+",AUDL");
     	
-    	/*PropertyConfigurator.configure(props);*/
+    	PropertyConfigurator.configure(props);
     	logger = Logger.getLogger(clazzName);
     	
     }
diff --git a/Molap/Molap-Spark-Interface/.classpath b/Molap/Molap-Spark-Interface/.classpath
index 1034594..e315367 100644
--- a/Molap/Molap-Spark-Interface/.classpath
+++ b/Molap/Molap-Spark-Interface/.classpath
@@ -3,7 +3,6 @@
 	<classpathentry kind="src" path="src/main/java"/>
 	<classpathentry kind="src" path="src/main/scala"/>
 	<classpathentry kind="con" path="org.scala-ide.sdt.launching.SCALA_CONTAINER"/>
-	<classpathentry exported="true" kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/JavaSE-1.8"/>
 	<classpathentry kind="lib" path="/libraries/TPJars/commons-vfs-1.0.jar"/>
 	<classpathentry kind="lib" path="/libraries/TPJars/eigenbase-properties-1.1.0.10924.jar"/>
 	<classpathentry kind="lib" path="/libraries/TPJars/eigenbase-resgen-1.3.0.13768.jar"/>
@@ -18,7 +17,6 @@
 	<classpathentry combineaccessrules="false" kind="src" path="/Molap-Data-Processor"/>
 	<classpathentry combineaccessrules="false" kind="src" path="/Molap-Engine"/>
 	<classpathentry combineaccessrules="false" kind="src" path="/Molap-Interface"/>
-	<classpathentry combineaccessrules="false" kind="src" path="/AutoAggregation"/>
 	<classpathentry kind="lib" path="/libraries/build_tools/datanucleus-api-jdo-3.2.1.jar"/>
 	<classpathentry kind="lib" path="/libraries/build_tools/datanucleus-core-3.2.2.jar"/>
 	<classpathentry kind="lib" path="/libraries/build_tools/datanucleus-rdbms-3.2.1.jar"/>
@@ -33,5 +31,6 @@
 	<classpathentry combineaccessrules="false" kind="src" path="/Molap-Logging-Service"/>
 	<classpathentry kind="lib" path="/libraries/Unibi_Prebuild/CryptProvider.jar-1.0.0-SNAPSHOT.jar"/>
 	<classpathentry kind="lib" path="/libraries/Unibi_Prebuild/spark-assembly-1.5.1-hadoop2.7.2.jar"/>
+	<classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
 	<classpathentry kind="output" path="classes"/>
 </classpath>
diff --git a/Molap/Molap-Spark-Interface/.settings/org.eclipse.jdt.core.prefs b/Molap/Molap-Spark-Interface/.settings/org.eclipse.jdt.core.prefs
deleted file mode 100644
index a698e59..0000000
--- a/Molap/Molap-Spark-Interface/.settings/org.eclipse.jdt.core.prefs
+++ /dev/null
@@ -1,12 +0,0 @@
-eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled
-org.eclipse.jdt.core.compiler.codegen.methodParameters=do not generate
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.8
-org.eclipse.jdt.core.compiler.codegen.unusedLocal=preserve
-org.eclipse.jdt.core.compiler.compliance=1.8
-org.eclipse.jdt.core.compiler.debug.lineNumber=generate
-org.eclipse.jdt.core.compiler.debug.localVariable=generate
-org.eclipse.jdt.core.compiler.debug.sourceFile=generate
-org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
-org.eclipse.jdt.core.compiler.problem.enumIdentifier=error
-org.eclipse.jdt.core.compiler.source=1.8
diff --git a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFolders.java b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFolders.java
index 3e269ef..f46c6f4 100644
--- a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFolders.java
+++ b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFolders.java
@@ -82,30 +82,16 @@ public final class DeleteLoadFolders
                             path = LoadMetadataUtil.createLoadFolderPath(
                                     loadModel, storeLocation, partitionId,
                                     restructureFolderNum);
-                            String loadFolderPath = "";
-                            // deleting merged load folder
-                            if(oneLoad.getMergedLoadName() != null)
-                            {
-                                loadFolderPath = path
-                                        + MolapCommonConstants.FILE_SEPARATOR
-                                        + MolapCommonConstants.LOAD_FOLDER
-                                        + oneLoad.getMergedLoadName();
-                                deletionStatus = physicalFactAndMeasureMetadataDeletion(loadFolderPath);
-                            }
-                            else
-                            {
-                                loadFolderPath = path
-                                        + MolapCommonConstants.FILE_SEPARATOR
-                                        + MolapCommonConstants.LOAD_FOLDER
-                                        + oneLoad.getLoadName();
-                                deletionStatus = physicalFactAndMeasureMetadataDeletion(loadFolderPath);
-                            }
+                            String loadFolderPath = path
+                                    + MolapCommonConstants.FILE_SEPARATOR
+                                    + MolapCommonConstants.LOAD_FOLDER
+                                    + oneLoad.getLoadName();
+                            deletionStatus = physicalFactAndMeasureMetadataDeletion(loadFolderPath);
                             if(deletionStatus)
                             {
                                 cleanDeletedFactFile(loadFolderPath);
                                 factFileRenaming(loadFolderPath);
-                                // if deletion status is True then there is no
-                                // need to traverse all the RS folders.
+                                // if deletion status is True then there is no need to traverse all the RS folders.
                                 break;
                             }
                         }
@@ -132,7 +118,7 @@ public final class DeleteLoadFolders
      * @param aggFiles
      * @param loadName
      */
-    public static void deleteAggLoadFolders(MolapFile[] aggFiles, String loadName) 
+    private static void deleteAggLoadFolders(MolapFile[] aggFiles, String loadName) 
     {
     	for(MolapFile file : aggFiles)
     	{
@@ -167,18 +153,17 @@ public final class DeleteLoadFolders
         {
             MolapFile[] files = loadFolder.listFiles();
             // deleting individual files
-            if(files != null)
+            if(files!=null){
+            for(MolapFile eachFile : files)
             {
-                for(MolapFile eachFile : files)
+                if(!eachFile.delete())
                 {
-                    if(!eachFile.delete())
-                    {
-                        LOGGER.warn(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG,
-                                "Unable to delete the file as per delete command "
-                                        + loadFolder.getAbsolutePath());
-                    }
+                    LOGGER.warn(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG,
+                            "Unable to delete the file as per delete command "
+                                    + loadFolder.getAbsolutePath());
                 }
             }
+            }
 
         }
 
@@ -364,10 +349,6 @@ public final class DeleteLoadFolders
 
     }
     
-    /**
-     * deletes the fact file which is marked as _deleted
-     * @param loadFolderPath
-     */
     private static void cleanDeletedFactFile(String loadFolderPath)
     {
         FileFactory.FileType fileType = FileFactory.getFileType(loadFolderPath);
diff --git a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFromMetadata.java b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFromMetadata.java
index f538889..372b2a2 100644
--- a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFromMetadata.java
+++ b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/DeleteLoadFromMetadata.java
@@ -23,9 +23,6 @@ import com.huawei.datasight.molap.spark.util.MolapSparkInterFaceLogEvent;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperations;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperationsImpl;
-import com.huawei.unibi.molap.datastorage.store.fileperations.FileWriteOperation;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
 import com.huawei.unibi.molap.locks.MetadataLock;
 import com.huawei.unibi.molap.locks.MolapLock;
@@ -52,6 +49,7 @@ public final class DeleteLoadFromMetadata
     {
         MolapLock molapLock = new MetadataLock(cubeFolderPath);
         BufferedWriter brWriter = null;
+        DataInputStream dataInputStream = null;
         List<String> invalidLoadIds = new ArrayList<String>(0);
         try
         {
@@ -92,17 +90,11 @@ public final class DeleteLoadFromMetadata
                                 "Load doesnt exist or it is already deleted , LoadSeqId-"+invalidLoadIds);
                     }
 
-                    AtomicFileOperations fileWrite = new AtomicFileOperationsImpl(dataLoadLocation, FileFactory.getFileType(dataLoadLocation));
-                    
                     // write the updated data into the metadata file.
-                    
-                    try
-                    {
-                    dataOutputStream = fileWrite.openForWrite(FileWriteOperation.OVERWRITE);
-                    
-                   /* dataOutputStream = FileFactory.getDataOutputStream(
+
+                    dataOutputStream = FileFactory.getDataOutputStream(
                             dataLoadLocation,
-                            FileFactory.getFileType(dataLoadLocation));*/
+                            FileFactory.getFileType(dataLoadLocation));
                     brWriter = new BufferedWriter(
                             new OutputStreamWriter(
                                     dataOutputStream,
@@ -111,18 +103,6 @@ public final class DeleteLoadFromMetadata
                     String metadataInstance = gsonObjectToWrite
                             .toJson(listOfLoadFolderDetailsArray);
                     brWriter.write(metadataInstance);
-                    }
-                    finally
-                    {
-                        if(null != brWriter)
-                        {
-                            brWriter.flush();
-                        }
-                        MolapUtil.closeStreams(brWriter);
-                    }
-                    
-                    fileWrite.close();
-                    
                 }
                 else
                 {
@@ -146,6 +126,24 @@ public final class DeleteLoadFromMetadata
         finally
         {
             fileUnlock(molapLock);
+
+            try
+            {
+                if(null != brWriter)
+                {
+                    brWriter.flush();
+                }
+            }
+            catch(IOException e)
+            {
+                LOGGER.info(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG,"errorn while  flushing");
+            }            
+            finally
+            {
+            	 MolapUtil.closeStreams(brWriter,dataInputStream);              
+            	
+            }
+        
         }
         
         return invalidLoadIds;
diff --git a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoadModel.java b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoadModel.java
index e5e7133..6bbd2cc 100644
--- a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoadModel.java
+++ b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoadModel.java
@@ -60,9 +60,6 @@ public class MolapLoadModel implements Serializable
 	private List<String> factFilesToProcess;
 	private String csvHeader;
 	private String csvDelimiter;
-	private String complexDelimiterLevel1;
-	private String complexDelimiterLevel2;
-	
 	private boolean isDirectLoad;
 	
 	public String getCsvDelimiter() {
@@ -72,22 +69,6 @@ public class MolapLoadModel implements Serializable
 	public void setCsvDelimiter(String csvDelimiter) {
 		this.csvDelimiter = csvDelimiter;
 	}
-	
-	public String getComplexDelimiterLevel1() {
-		return complexDelimiterLevel1;
-	}
-
-	public void setComplexDelimiterLevel1(String complexDelimiterLevel1) {
-		this.complexDelimiterLevel1 = complexDelimiterLevel1;
-	}
-
-	public String getComplexDelimiterLevel2() {
-		return complexDelimiterLevel2;
-	}
-
-	public void setComplexDelimiterLevel2(String complexDelimiterLevel2) {
-		this.complexDelimiterLevel2 = complexDelimiterLevel2;
-	}
 
 	public boolean isDirectLoad() {
 		return isDirectLoad;
@@ -293,8 +274,6 @@ public class MolapLoadModel implements Serializable
 		copy.aggLoadRequest = aggLoadRequest;
 		copy.loadMetadataDetails = loadMetadataDetails;
 		copy.isRetentionRequest = isRetentionRequest;
-		copy.complexDelimiterLevel1 = complexDelimiterLevel1;
-		copy.complexDelimiterLevel2 = complexDelimiterLevel2;
 		if(uniqueId != null && schema!=null)
         {
             String originalSchemaName = schema.name;
@@ -338,8 +317,6 @@ public class MolapLoadModel implements Serializable
 		copyObj.factFilesToProcess = filesForPartition;
 		copyObj.isDirectLoad = true;
 		copyObj.csvDelimiter = delimiter;
-		copyObj.complexDelimiterLevel1 = complexDelimiterLevel1;
-		copyObj.complexDelimiterLevel2 = complexDelimiterLevel2;
 		return copyObj;
 	}
 
diff --git a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoaderUtil.java b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoaderUtil.java
index 3bce11c..dfb97c5 100644
--- a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoaderUtil.java
+++ b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/load/MolapLoaderUtil.java
@@ -44,9 +44,6 @@ import com.huawei.unibi.molap.constants.MolapCommonConstants;
 import com.huawei.unibi.molap.csvload.DataGraphExecuter;
 import com.huawei.unibi.molap.dataprocessor.DataProcessTaskStatus;
 import com.huawei.unibi.molap.dataprocessor.IDataProcessStatus;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperations;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperationsImpl;
-import com.huawei.unibi.molap.datastorage.store.fileperations.FileWriteOperation;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFileFilter;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
@@ -174,8 +171,6 @@ public final class MolapLoaderUtil
     	info.setCubeName(cubeName);
     	info.setSchemaPath(loadModel.getSchemaPath());
     	info.setAutoAggregateRequest(loadModel.isAggLoadRequest());
-    	info.setComplexDelimiterLevel1(loadModel.getComplexDelimiterLevel1());
-    	info.setComplexDelimiterLevel2(loadModel.getComplexDelimiterLevel2());
     	
     	generateGraph(schmaModel, info, loadModel.getTableName(),loadModel.getPartitionId(), loadModel.getSchema(), loadModel.getFactStoreLocation(), currentRestructNumber);
     	
@@ -420,7 +415,7 @@ public final class MolapLoaderUtil
                     @Override
                     public boolean accept(MolapFile path)
                     {
-                        return !loadFolders.contains(path.getAbsolutePath().replace("\\", "/")) && !path.getName().contains(MolapCommonConstants.MERGERD_EXTENSION);
+                        return !loadFolders.contains(path.getAbsolutePath().replace("\\", "/"));
                     }
                 });
                 for(int k = 0;k < listFiles.length;k++)
@@ -521,20 +516,11 @@ public final class MolapLoaderUtil
                     || MolapCommonConstants.MARKED_FOR_UPDATE.equals(oneLoad
                             .getLoadStatus()))
             {
-                if(null != oneLoad.getMergedLoadName())
-                {
                 String loadName = MolapCommonConstants.LOAD_FOLDER
-                            + oneLoad.getMergedLoadName();
-                    activeSlices.add(loadName);
-                }
-                else
-                {
-                    String loadName = MolapCommonConstants.LOAD_FOLDER
                         + oneLoad.getLoadName();
                 activeSlices.add(loadName);
             }
         }
-        }
         return activeSlices;
     }
     
@@ -554,16 +540,9 @@ public final class MolapLoaderUtil
             if(MolapCommonConstants.MARKED_FOR_UPDATE.equals(oneLoad
                     .getLoadStatus()))
             {
-                if(null != oneLoad.getMergedLoadName())
-                {
-                    updatedSlices.add(oneLoad.getMergedLoadName());
-                }
-                else
-                {
                 updatedSlices.add(oneLoad.getLoadName());
             }
         }
-        }
         return updatedSlices;
     }
     
@@ -1196,7 +1175,11 @@ public final class MolapLoaderUtil
 			}
 			}
 			listOfLoadFolderDetails.add(loadMetadataDetails);
-			
+			writeLoadMetadata(
+					loadModel.getSchema(),
+					loadModel.getSchemaName(),
+					loadModel.getCubeName(),
+					listOfLoadFolderDetails);
 		} 
 
 		finally
@@ -1204,11 +1187,6 @@ public final class MolapLoaderUtil
 
 		   MolapUtil.closeStreams(dataInputStream);
 		}
-		writeLoadMetadata(
-		        loadModel.getSchema(),
-		        loadModel.getSchemaName(),
-		        loadModel.getCubeName(),
-		        listOfLoadFolderDetails);
 
 	}
 
@@ -1226,16 +1204,10 @@ public final class MolapLoaderUtil
 		DataOutputStream dataOutputStream;
 		Gson gsonObjectToWrite = new Gson();
 		BufferedWriter brWriter = null;
-		
-		AtomicFileOperations writeOperation = new AtomicFileOperationsImpl(dataLoadLocation, FileFactory.getFileType(dataLoadLocation) );
-		
 		try {
-		    
-		    dataOutputStream = writeOperation.openForWrite(FileWriteOperation.OVERWRITE);
-		    
-			/*dataOutputStream = FileFactory
+			dataOutputStream = FileFactory
 					.getDataOutputStream(dataLoadLocation,
-							FileFactory.getFileType(dataLoadLocation));*/
+							FileFactory.getFileType(dataLoadLocation));
 			brWriter = new BufferedWriter(new OutputStreamWriter(
 					dataOutputStream,
 					MolapCommonConstants.MOLAP_DEFAULT_STREAM_ENCODEFORMAT));
@@ -1249,13 +1221,12 @@ public final class MolapLoaderUtil
 					brWriter.flush();
 				}
 			} catch (Exception e) {
+//				e.printStackTrace();
 				LOGGER.error(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG,"error in  flushing ", e, e.getMessage());
 				  			
 			}
 			MolapUtil.closeStreams(brWriter);
-			
 		}
-		writeOperation.close();
 
 	}
 
@@ -1520,140 +1491,5 @@ public final class MolapLoaderUtil
         }
         return columnList;
     }
-	 public static void copyMergedLoadToHDFS(MolapLoadModel loadModel, int currentRestructNumber, String mergedLoadName)
-    {
-      //Copy the current load folder to HDFS
-        boolean copyStore = Boolean.valueOf(MolapProperties.getInstance().getProperty("dataload.hdfs.copy", "true"));
-        
-        String schemaName =  loadModel.getSchemaName();
-        String cubeName =  loadModel.getCubeName();
-        String factTable = loadModel.getTableName();
-        String aggTableName = loadModel.getAggTableName();
-        
-        if(copyStore)
-        {
-            String hdfsLocation = MolapProperties.getInstance().getProperty(MolapCommonConstants.STORE_LOCATION_HDFS);
-            
-            String localStore = MolapProperties.getInstance().getProperty(
-                    MolapCommonConstants.STORE_LOCATION, MolapCommonConstants.STORE_LOCATION_DEFAULT_VAL);
-            if(!loadModel.isAggLoadRequest())
-            {
-            copyMergeToHDFS(schemaName, cubeName, factTable, hdfsLocation,localStore, currentRestructNumber, mergedLoadName);
-            }
-            if(null != aggTableName) {
-//              for (int i = 0; i < aggTables.length; i++) {
-                copyMergeToHDFS(schemaName, cubeName, aggTableName, hdfsLocation, localStore, currentRestructNumber,mergedLoadName);
-//              }
-            }
-            try
-            {
-                 MolapUtil.deleteFoldersAndFiles(new File[] { 
-                          new File(localStore + File.separator + schemaName + File.separator + cubeName) });
-                // MolapUtil.getSlices(localStore + File.separator + schemaName + File.separator + cubeName, factTable, loadModel.)
-            } 
-            catch (MolapUtilException e) 
-            {
-//              e.printStackTrace();
-                LOGGER.error(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG, "Error while MolapUtil.deleteFoldersAndFiles ", e, e.getMessage());
-            }
-        }
-    }
-    
-    public static void copyMergeToHDFS(String schemaName, String cubeName,
-            String factTable, String hdfsLocation, String localStore, int currentRestructNumber, String mergedLoadName) {
-        try
-        {
-            //If the hdfs store and the local store configured differently, then copy
-            if(hdfsLocation!=null && !hdfsLocation.equals(localStore))
-            {
-                /**
-                 * Identify the Load_X folder from the local store folder
-                 */
-                String currentloadedStore = localStore;
-                currentloadedStore = currentloadedStore + File.separator + schemaName + File.separator
-                        + cubeName;
-
 
-                int rsCounter = currentRestructNumber/*MolapUtil.checkAndReturnNextRestructFolderNumber(currentloadedStore,"RS_")*/;
-
-           
-
-                if(rsCounter == -1)
-                {
-//                  System.out.println("Unable to find the local store details (RS_-1) " + currentloadedStore);
-                    LOGGER.info(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG,"Unable to find the local store details (RS_-1) " + currentloadedStore);
-                    return;
-                }
-                String localLoadedTable = currentloadedStore + File.separator
-                        + MolapCommonConstants.RESTRUCTRE_FOLDER + rsCounter + File.separator + factTable;
-
-                localLoadedTable = localLoadedTable.replace("\\", "/");
-                
-                int loadCounter = MolapUtil.checkAndReturnCurrentLoadFolderNumber(localLoadedTable);
-
-                if(loadCounter == -1)
-                {
-//                  System.out.println("Unable to find the local store details (Load_-1) " + currentloadedStore);
-                    LOGGER.info(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG,"Unable to find the local store details (Load_-1) " + currentloadedStore);
-                       
-                    return;
-                }
-
-                String localLoadName = MolapCommonConstants.LOAD_FOLDER
-                        + mergedLoadName;
-                String localLoadFolder = localLoadedTable + File.separator + MolapCommonConstants.LOAD_FOLDER
-                        + mergedLoadName;
-                
-                LOGGER.info(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG,"Local data loaded folder ... = " + localLoadFolder);                  
-//              System.out.println("Local data loaded folder ... = " + localLoadFolder);
-               
-                /**
-                 * Identify the Load_X folder in the HDFS store 
-                 */
-                
-                String hdfsStoreLocation= hdfsLocation;
-                hdfsStoreLocation = hdfsStoreLocation + File.separator + schemaName + File.separator
-                        + cubeName;
-
-                rsCounter = currentRestructNumber/*MolapUtil.checkAndReturnNextRestructFolderNumber(hdfsStoreLocation,"RS_")*/;
-                if(rsCounter == -1)
-                {
-                    rsCounter = 0;
-                }
-
-                String hdfsLoadedTable = hdfsStoreLocation + File.separator
-                        + MolapCommonConstants.RESTRUCTRE_FOLDER + rsCounter + File.separator + factTable;
-                
-                hdfsLoadedTable = hdfsLoadedTable.replace("\\", "/");
-
-                String hdfsStoreLoadFolder = hdfsLoadedTable + File.separator + localLoadName;
-
-                LOGGER.info(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG,"HDFS data load folder ... = " + hdfsStoreLoadFolder);
-                
-                /**
-                 * Copy the data created through latest ETL run, to the HDFS store 
-                 */
-                
-                LOGGER.info(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG,"Copying " + localLoadFolder + " --> " + hdfsStoreLoadFolder);
-                
-                hdfsStoreLoadFolder = hdfsStoreLoadFolder.replace("\\", "/");
-                Path path = new Path(hdfsStoreLocation);
-                
-               
-                FileSystem fs = path.getFileSystem(FileFactory.getConfiguration());
-                fs.copyFromLocalFile(true, true, new Path(localLoadFolder), new Path(hdfsStoreLoadFolder));
-                
-                LOGGER.info(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG,"Copying sliceMetaData from " + localLoadedTable + " --> " + hdfsLoadedTable);
-                
-            }
-            else
-            {
-                LOGGER.info(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG, "Separate molap.storelocation.hdfs is not configured for hdfs store path");
-            }
-        }
-        catch(Exception e)
-        {
-            LOGGER.info(MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG,e.getMessage());
-        }
-    }
 }
diff --git a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/merger/MolapDataMergerUtil.java b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/merger/MolapDataMergerUtil.java
index be71f32..1e1ebdc 100644
--- a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/merger/MolapDataMergerUtil.java
+++ b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/merger/MolapDataMergerUtil.java
@@ -1,741 +1,95 @@
 package com.huawei.datasight.molap.merger;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Date;
-import java.util.List;
-
-import com.huawei.datasight.molap.core.load.LoadMetadataDetails;
-import com.huawei.datasight.molap.load.DeleteLoadFolders;
 import com.huawei.datasight.molap.load.MolapLoadModel;
-import com.huawei.datasight.molap.load.MolapLoaderUtil;
-import com.huawei.datasight.molap.spark.util.LoadMetadataUtil;
-import com.huawei.iweb.platform.logging.LogService;
-import com.huawei.iweb.platform.logging.LogServiceFactory;
+//import com.huawei.iweb.platform.logging.LogService;
+//import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
-import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
-import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFileFilter;
-import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
-import com.huawei.unibi.molap.datastorage.store.impl.FileFactory.FileType;
 import com.huawei.unibi.molap.merger.MolapColumnarSliceMerger;
 import com.huawei.unibi.molap.merger.MolapSliceMergerInfo;
-import com.huawei.unibi.molap.util.MolapCoreLogEvent;
 import com.huawei.unibi.molap.util.MolapProperties;
-import com.huawei.unibi.molap.util.MolapUtil;
 
-/**
- * utility class for load merging.
- * @author R00903928
- *
- */
 public final class MolapDataMergerUtil 
 {
-    private static final LogService LOGGER = LogServiceFactory
-            .getLogService(MolapDataMergerUtil.class.getName());
-    
+//	private static final LogService LOGGER = LogServiceFactory.getLogService(MolapDataMergerUtil.class.getName());
 	private MolapDataMergerUtil()
 	{
 		
 	}
-	/**
-	 * 
-	 * @param molapLoadModel
-	 * @param storeLocation
-	 * @param hdfsStoreLocation
-	 * @param currentRestructNumber
-	 * @param metadataFilePath
-	 * @param loadsToMerge
-	 * @param mergedLoadName
-	 * @return
-	 * @throws Exception
-	 */
-	public static boolean executeMerging(MolapLoadModel molapLoadModel,String storeLocation, String hdfsStoreLocation, int currentRestructNumber , String metadataFilePath, List<String> loadsToMerge, String mergedLoadName) throws Exception
+	public static void executeMerging(MolapLoadModel molapLoadModel,String storeLocation, String hdfsStoreLocation, int currentRestructNumber) throws Exception
 	{
+		
 		MolapProperties.getInstance().addProperty(
 				MolapCommonConstants.STORE_LOCATION, storeLocation);
 		MolapProperties.getInstance().addProperty(
 				MolapCommonConstants.STORE_LOCATION_HDFS, hdfsStoreLocation);
 		MolapSliceMergerInfo molapSliceMergerInfo = new MolapSliceMergerInfo();
 		
-		
 		molapSliceMergerInfo.setCubeName(molapLoadModel.getCubeName());
 		molapSliceMergerInfo.setPartitionID(molapLoadModel.getPartitionId());
 		molapSliceMergerInfo.setSchema(molapLoadModel.getSchema());
 		molapSliceMergerInfo.setSchemaName(molapLoadModel.getSchemaName());
 		molapSliceMergerInfo.setSchemaPath(molapLoadModel.getSchemaPath());
 		molapSliceMergerInfo.setTableName(molapLoadModel.getTableName());
-		molapSliceMergerInfo.setMetadataPath(metadataFilePath);
-		molapSliceMergerInfo.setLoadsToBeMerged(loadsToMerge);
-		molapSliceMergerInfo.setMergedLoadName(mergedLoadName);
 		
 		MolapColumnarSliceMerger merger = new MolapColumnarSliceMerger(molapSliceMergerInfo);
-		return merger.fullMerge(currentRestructNumber);
+		merger.fullMerge(currentRestructNumber);
 		
 	}
 	
-	/**
-	 * 
-	 * @param storeLocation
-	 * @param fileType
-	 * @param metadataPath
-	 * @param molapLoadModel
-	 * @param currentRestructNumber
-	 * @param partitionCount
-	 * @return
-	 */
-	 public static List<String> getLoadsToMergeFromHDFS(String storeLocation, FileType fileType, String metadataPath, MolapLoadModel molapLoadModel,int currentRestructNumber,int partitionCount)
-    {
-        List<String> loadNames = new ArrayList<String>(
-                MolapCommonConstants.DEFAULT_COLLECTION_SIZE);
-
-        try
-        {
-            if(!FileFactory.isFileExist(storeLocation, fileType))
-            {
-                return null;
-            }
-        }
-        catch(IOException e)
-        {
-             LOGGER.error(
-             MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG ,
-             "Error occurred :: " + e.getMessage());
-        }
-
-        int toLoadMergeMaxSize;
-        try
-        {
-            toLoadMergeMaxSize = Integer
-                    .parseInt(MolapProperties
-                            .getInstance()
-                            .getProperty(
-                                    MolapCommonConstants.TO_LOAD_MERGE_MAX_SIZE,
-                                    MolapCommonConstants.TO_LOAD_MERGE_MAX_SIZE_DEFAULT));
-        }
-        catch(NumberFormatException e)
-        {
-            toLoadMergeMaxSize = Integer
-                    .parseInt(MolapCommonConstants.TO_LOAD_MERGE_MAX_SIZE_DEFAULT);
-        }
-
-        LoadMetadataDetails[] loadDetails = MolapUtil
-                .readLoadMetadata(metadataPath);
-
-        for(LoadMetadataDetails loadDetail : loadDetails)
-        {
-            if(loadNames.size() < 2)
-            {
-                // check if load is not deleted.
-                if(checkIfLoadIsNotDeleted(loadDetail))
-                {
-                    // check if load is merged
-                    if(checkIfLoadIsMergedAlready(loadDetail))
-                    {
-                        if(checkSizeOfloadToMerge(loadDetail,
-                                toLoadMergeMaxSize, molapLoadModel,
-                                partitionCount, storeLocation,
-                                currentRestructNumber,
-                                loadDetail.getMergedLoadName()))
-                        {
-                            if(!loadNames.contains(loadDetail.getMergedLoadName()))
-                            {
-                                loadNames.add(loadDetail.getMergedLoadName());
-                            }
-                        }
-                    }
-                    else
-                    // take this load as To Load.
-                    {
-                        if(checkSizeOfloadToMerge(loadDetail,
-                                toLoadMergeMaxSize, molapLoadModel,
-                                partitionCount, storeLocation,
-                                currentRestructNumber, loadDetail.getLoadName()))
-                        {
-                            loadNames.add(loadDetail.getLoadName());
-                        }
-                    }
-                }
-            }
-            else
-            {
-                break;
-            }
-        }
-        
-        return loadNames;
-
-    }
-	 
-	/**
-	 * 
-	 * @param loadDetail
-	 * @param toLoadMergeMaxSize
-	 * @param molapLoadModel
-	 * @param partitionCount
-	 * @param storeLocation 
-	 * @param currentRestructNumber 
-	 * @return
-	 */
-	 private static boolean checkSizeOfloadToMerge(
-            final LoadMetadataDetails loadDetail, int toLoadMergeMaxSize,MolapLoadModel molapLoadModel, int partitionCount, String storeLocation, int currentRestructNumber, final String loadNameToMatch)
-    {
-
-	     long factSizeAcrossPartition = 0;
-	     
-        for(int partition = 0;partition < partitionCount;partition++)
-        {
-            String loadPath = LoadMetadataUtil.createLoadFolderPath(
-                    molapLoadModel, storeLocation, partition,
-                    currentRestructNumber);
-
-            MolapFile parentLoadFolder = FileFactory.getMolapFile(loadPath,
-                    FileFactory.getFileType(loadPath));
-            MolapFile[] loadFiles = parentLoadFolder
-                    .listFiles(new MolapFileFilter()
-                    {
-                        @Override
-                        public boolean accept(MolapFile file)
-                        {
-                            if(file.getName()
-                                    .substring(file.getName().indexOf('_') + 1,
-                                            file.getName().length())
-                                    .equalsIgnoreCase(loadNameToMatch))
-                            {
-                                return true;
-                            }
-                            return false;
-                        }
-                    });
-            
-            // no found load folder in current RS
-            if(loadFiles.length == 0)
-            {
-                return false;
-            }
-            
-            // check if fact file is present or not. this is in case of Restructure folder.
-            if(!isFactFilePresent(loadFiles[0]))
-            {
-                return false;
-            }
-            
-            
-             factSizeAcrossPartition += getSizeOfFactFileInLoad(loadFiles[0]);
-            
-            // MolapFile loadFolder = new MolapFile()
-        }
-        // check avg fact size if less than configured max size of to load.
-        if(factSizeAcrossPartition < toLoadMergeMaxSize*1024*1024*1024)
-        {
-            return true;
-        }
-
-        // LoadMetadataUtil.createLoadFolderPath(model, hdfsStoreLocation,
-        // partitionId, currentRestructNumber);
-        return false;
-    }
-	 
-    /**
-	  * 
-	  * @param molapFile
-	  * @return
-	  */
-    private static long getSizeOfFactFileInLoad(MolapFile molapFile)
-    {
-        long factSize = 0;
-        
-        // check if update fact is present.
-        
-        MolapFile [] factFileUpdated = molapFile.listFiles(new MolapFileFilter()
-        {
-            
-            @Override
-            public boolean accept(MolapFile file)
-            {
-                if(file.getName().endsWith(MolapCommonConstants.FACT_UPDATE_EXTENSION))
-                {
-                    return true;
-                }
-                return false;
-            }
-        });
-        
-        if(factFileUpdated.length != 0)
-        {
-            for(MolapFile fact : factFileUpdated)
-            {
-                factSize += fact.getSize();
-            }
-            return factSize;
-        }
-        
-        // normal fact case.
-        MolapFile [] factFile = molapFile.listFiles(new MolapFileFilter()
-        {
-            
-            @Override
-            public boolean accept(MolapFile file)
-            {
-                if(file.getName().endsWith(MolapCommonConstants.FACT_FILE_EXT))
-                {
-                    return true;
-                }
-                return false;
-            }
-        });
-        
-        for(MolapFile fact  : factFile)
-        {
-            factSize +=  fact.getSize();
-        }
-        
-        return factSize;
-    }
-    /**
-	  * 
-	  * @param loadDetail
-	  * @return
-	  */
-	private static boolean checkIfLoadIsMergedAlready(
-            LoadMetadataDetails loadDetail)
-    {
-	    if(null != loadDetail.getMergedLoadName())
-	    {
-	        return true;
-	    }
-        return false;
-    }
-    /**
-	 *  
-	 * @param loadDetail
-	 */
-    private static boolean checkIfLoadIsNotDeleted(LoadMetadataDetails loadDetail)
-    {
-        if(!loadDetail.getLoadStatus().equalsIgnoreCase(MolapCommonConstants.MARKED_FOR_DELETE))
-        {
-            return true;
-        }
-        else
-        {
-            return false;
-        }
-    }
-    
-    /**
-     * 
-     * @param metadataFilePath
-     * @param molapLoadModel 
-     * @param storeLocation 
-     * @param partition 
-     * @param currentRestructNumber 
-     * @return
-     */
-    public static boolean checkIfLoadMergingRequired(String metadataFilePath, MolapLoadModel molapLoadModel, String storeLocation, int partition, int currentRestructNumber)
-    {
-        
-        
-        String loadPath = LoadMetadataUtil.createLoadFolderPath(
-                molapLoadModel, storeLocation, 0,
-                currentRestructNumber);
-
-        MolapFile parentLoadFolder = FileFactory.getMolapFile(loadPath,
-                FileFactory.getFileType(loadPath));
-        
-        // get all the load files in the current RS 
-        MolapFile[] loadFiles = parentLoadFolder
-                .listFiles(new MolapFileFilter()
-                {
-                    @Override
-                    public boolean accept(MolapFile file)
-                    {
-                        if(file.getName()
-                                .startsWith(MolapCommonConstants.LOAD_FOLDER ))
-                        {
-                            return true;
-                        }
-                        return false;
-                    }
-                });
-        
-        
-        String isLoadMergeEnabled = MolapProperties.getInstance().getProperty(
-                MolapCommonConstants.ENABLE_LOAD_MERGE,
-                MolapCommonConstants.DEFAULT_ENABLE_LOAD_MERGE);
-        
-        if(isLoadMergeEnabled.equalsIgnoreCase("false"))
-        {
-            return false;
-        }
-        
-        int mergeThreshold;
-        try
-        {
-             mergeThreshold = Integer.parseInt(MolapProperties.getInstance().getProperty(
-                MolapCommonConstants.MERGE_THRESHOLD_VALUE,
-                MolapCommonConstants.MERGE_THRESHOLD_DEFAULT_VAL));
-        }
-        catch(NumberFormatException e)
-        {
-            mergeThreshold = Integer.parseInt(MolapCommonConstants.MERGE_THRESHOLD_DEFAULT_VAL);
-        }
-        
-        LoadMetadataDetails [] details = MolapUtil.readLoadMetadata(metadataFilePath);
-        
-        int validLoadsNumber = getNumberOfValidLoads(details,loadFiles);
-        
-        if(validLoadsNumber > mergeThreshold+1)
-        {
-            return true;
-        }
-        else
-        {
-            return false;
-        }
-    }
-    
-    /**
-     * 
-     * @param details
-     * @param loadFiles 
-     * @return
-     */
-    private static int getNumberOfValidLoads(LoadMetadataDetails[] details, MolapFile[] loadFiles)
-    {
-        int validLoads = 0;
-        
-        for(LoadMetadataDetails load : details)
-        {
-            if(load.getLoadStatus().equalsIgnoreCase(MolapCommonConstants.STORE_LOADSTATUS_SUCCESS)
-                    || load.getLoadStatus().equalsIgnoreCase(MolapCommonConstants.STORE_LOADSTATUS_PARTIAL_SUCCESS)
-                    || load.getLoadStatus().equalsIgnoreCase(MolapCommonConstants.MARKED_FOR_UPDATE))
-            {
-                
-                if(isLoadMetadataPresentInRsFolders(loadFiles,load.getLoadName()))
-                {
-                    validLoads++;
-                }
-            }
-        }
-        
-        return validLoads;
-    
-    }
-    
-    /**
-     * 
-     * @param loadFiles
-     * @param loadName
-     * @return
-     */
-    private static boolean isLoadMetadataPresentInRsFolders(
-            MolapFile[] loadFiles, String loadName)
-    {
-        for(MolapFile load : loadFiles)
-        {
-            String nameOfLoad = load.getName().substring(load.getName().indexOf(MolapCommonConstants.UNDERSCORE)+1, load.getName().length());
-            if(nameOfLoad.equalsIgnoreCase(loadName))
-            {
-                // check if it is a RS load or not.
-                MolapFile [] factFiles = load.listFiles(new MolapFileFilter()
-                {
-                    @Override
-                    public boolean accept(MolapFile file)
-                    {
-                        if (file.getName().endsWith(MolapCommonConstants.FACT_FILE_EXT ) || file.getName().endsWith(MolapCommonConstants.FACT_UPDATE_EXTENSION ))
-                        {
-                            return true;
-                        }
-                        return false;
-                    }
-                });
-                
-                if(factFiles.length > 0)
-                {
-                    return true;
-                }
-                else
-                {
-                    return false;
-                }
-            }
-            
-        }
-        return false;
-    }
-    /**
-     * 
-     * @param loadName
-     * @return
-     */
-    public static String getMergedLoadName(List<String> loadName)
-    {
-         String mergeLoadName = loadName.get(0); 
-        String timeStamp = new Date().getTime()+"";
-        
-        if(mergeLoadName.contains(MolapCommonConstants.MERGERD_EXTENSION))
-        {
-            String loadNum = mergeLoadName.substring(0, mergeLoadName.indexOf(MolapCommonConstants.MERGERD_EXTENSION));
-            return loadNum+MolapCommonConstants.MERGERD_EXTENSION+MolapCommonConstants.UNDERSCORE+timeStamp;
-        }
-        else
-        {
-            return mergeLoadName+MolapCommonConstants.MERGERD_EXTENSION+MolapCommonConstants.UNDERSCORE+timeStamp;
-        }
-        
-    }
-    
-    /**
-     * 
-     * @param loadsToMerge
-     * @param metaDataFilepath
-     * @param MergedLoadName
-     */
-    public static void updateLoadMetadataWithMergeStatus(List<String> loadsToMerge, String metaDataFilepath, String MergedLoadName,MolapLoadModel molapLoadModel)
-    {
-        LoadMetadataDetails[] loadDetails =  MolapUtil.readLoadMetadata(metaDataFilepath);
-        
-        boolean first = true;
-        
-        for(LoadMetadataDetails loadDetail : loadDetails)
-        {
-            
-            if(null != loadDetail.getMergedLoadName())
-            {
-                if(loadsToMerge.contains(loadDetail.getMergedLoadName()) && first)
-                {
-                    loadDetail.setMergedLoadName(MergedLoadName);
-                    first = false;
-                }
-                else
-                {/*
-                    loadDetail.setLoadStatus(MolapCommonConstants.MARKED_FOR_DELETE);
-                    loadDetail.setDeletionTimestamp(MolapLoaderUtil
-                            .readCurrentTime());
-                */
-                    continue;
-                }
-            }
-            
-            else if(loadsToMerge.contains(loadDetail.getLoadName()) )
-            {
-                if(first)
-                {
-                loadDetail.setMergedLoadName(MergedLoadName);
-                first = false;
-                }
-                else
-                {
-                    loadDetail.setLoadStatus(MolapCommonConstants.MARKED_FOR_DELETE);
-                    loadDetail.setDeletionTimestamp(MolapLoaderUtil
-                            .readCurrentTime());
-                }
-                
-            }
-           
-        }
-        
-        try
-        {
-            MolapLoaderUtil.writeLoadMetadata(molapLoadModel.getSchema(), molapLoadModel.getSchemaName(), molapLoadModel.getCubeName(), Arrays.asList(loadDetails));
-        }
-        catch(IOException e)
-        {
-            
-        }
-        
-    }
-    
-    /**
-     * 
-     * @param path
-     * @param loadModel
-     */
-    public static void cleanUnwantedMergeLoadFolder(
-            MolapLoadModel loadModel, int partitionCount, String storeLocation,
-            boolean isForceDelete, int currentRestructNumber)
-    {
-
-        String loadMetadataFilePath = MolapLoaderUtil
-                .extractLoadMetadataFileLocation(loadModel);
-
-        LoadMetadataDetails[] details = MolapUtil
-                .readLoadMetadata(loadMetadataFilePath);
-        
-        // for first time before any load , this will be null
-        if( null == details || details.length == 0  )
-        {
-            return;
-        }
-
-        for(int partitionId = 0;partitionId < partitionCount;partitionId++)
-        {
-
-            String path = LoadMetadataUtil.createLoadFolderPath(loadModel,
-                    storeLocation, partitionId, currentRestructNumber);
-
-            MolapFile loadFolder = FileFactory.getMolapFile(path,
-                    FileFactory.getFileType(path));
-
-            MolapFile[] loads = loadFolder.listFiles(new MolapFileFilter()
-            {
-                @Override
-                public boolean accept(MolapFile file)
-                {
-                    if(file.getName().startsWith(
-                            MolapCommonConstants.LOAD_FOLDER)
-                            && file.getName().contains(
-                                    MolapCommonConstants.MERGER_FOLDER_EXT))
-                    {
-                        return true;
-                    }
-                    else
-                    {
-                        return false;
-                    }
-                }
-            });
-
-            for(int i = 0;i < loads.length;i++)
-            {
-                if(checkIfOldMergeLoadCanBeDeleted(loads[i], details))
-                {
-                    // delete merged load folder
-                    MolapFile[] files = loads[i].listFiles();
-                    // deleting individual files
-                    if(files != null)
-                    {
-                        for(MolapFile eachFile : files)
-                        {
-                            if(!eachFile.delete())
-                            {
-                                LOGGER.warn(
-                                        MolapCoreLogEvent.UNIBI_MOLAPCORE_MSG,
-                                        "Unable to delete the file."
-                                                + loadFolder.getAbsolutePath());
-                            }
-                        }
-
-                        loads[i].delete();
-
-                    }
-                    
-                    // delete corresponding aggregate table.
-                    
-                    MolapFile[] aggFiles = LoadMetadataUtil.getAggregateTableList(loadModel, storeLocation, partitionId, currentRestructNumber);
-                    DeleteLoadFolders.deleteAggLoadFolders(aggFiles,loads[i].getName());
-                    
-                }
-            }
-        }
-    }
-    
-    /**
-     * 
-     * @param eachMergeLoadFolder
-     * @param details
-     * @return
-     */
-    private static boolean checkIfOldMergeLoadCanBeDeleted(
-            MolapFile eachMergeLoadFolder, LoadMetadataDetails[] details)
-    {
-        boolean found = false;
-        for(LoadMetadataDetails loadDetail : details)
-        {
-            if(null != loadDetail.getMergedLoadName() && (MolapCommonConstants.LOAD_FOLDER+loadDetail.getMergedLoadName()).equalsIgnoreCase(eachMergeLoadFolder.getName()))
-            {
-                found = true;
-                break;
-            }
-        }
-        
-        if(!found)
-        {
-            // check the query execution time out and check the time stamp on load and delete.
-            
-            String loadName = eachMergeLoadFolder.getName();
-            long loadTime = Long.parseLong( loadName.substring( loadName.lastIndexOf(MolapCommonConstants.UNDERSCORE)+1,  loadName.length()));
-            long currentTime = new Date().getTime();
-            
-            long millis = getMaxQueryTimeOut();
-            
-            if ((currentTime-loadTime) > millis)
-            {
-                // delete that merge load folder
-                return true;
-            }
-        }
-        
-        return false;
-    }
-    /**
-     * 
-     * @return
-     */
-    private static long getMaxQueryTimeOut()
-    {
-        int maxTime; 
-        try
-        {
-            maxTime = Integer.parseInt(MolapProperties.getInstance().
-                    getProperty(MolapCommonConstants.MAX_QUERY_EXECUTION_TIME));
-        }
-        catch(NumberFormatException e)
-        {
-           maxTime = MolapCommonConstants.DEFAULT_MAX_QUERY_EXECUTION_TIME;
-        }
-        
-        return maxTime*60000;
-      
-    }
-    
-    /**
-     * 
-     * @param molapFile
-     * @return
-     */
-    private static boolean isFactFilePresent(MolapFile molapFile)
-   {
-        
-        MolapFile [] factFileUpdated = molapFile.listFiles(new MolapFileFilter()
-        {
-            
-            @Override
-            public boolean accept(MolapFile file)
-            {
-                if(file.getName().endsWith(MolapCommonConstants.FACT_UPDATE_EXTENSION))
-                {
-                    return true;
-                }
-                return false;
-            }
-        });
-        
-        if(factFileUpdated.length != 0 )
-        {
-            return true;
-        }
-        
-        MolapFile [] factFile = molapFile.listFiles(new MolapFileFilter()
-        {
-            
-            @Override
-            public boolean accept(MolapFile file)
-            {
-                if(file.getName().endsWith(MolapCommonConstants.FACT_FILE_EXT))
-                {
-                    return true;
-                }
-                return false;
-            }
-        });
-        
-        if(factFile.length != 0 )
-        {
-            return true;
-        }
-        
-       return false;
-   }
-    
+//	 public static void copyCurrentLoadToHDFS(MolapLoadModel loadModel)
+//	    {
+//	      //Copy the current load folder to HDFS
+//	        boolean copyStore = Boolean.valueOf(MolapProperties.getInstance().getProperty("dataload.hdfs.copy", "true"));
+//	        
+//	        String schemaName =  loadModel.getSchemaName();
+//	        String cubeName =  loadModel.getCubeName();
+//	        String factTable = loadModel.getTableName();
+//	        if(copyStore)
+//	        {
+//	            String hdfsLocation = MolapProperties.getInstance().getProperty(MolapCommonConstants.STORE_LOCATION_HDFS);
+//	            
+//	            String localStore = MolapProperties.getInstance().getProperty(
+//	            		MolapCommonConstants.STORE_LOCATION, MolapCommonConstants.STORE_LOCATION_DEFAULT_VAL);
+//	            MolapLoaderUtil.copyToHDFS(schemaName, cubeName, factTable, hdfsLocation,
+//						localStore);
+//	        }
+//	    }
+
+//		public static void deleteOlderSlices(MolapLoadModel loadModel)
+//		{
+//				String schemaName =  loadModel.getSchemaName();
+//		        String cubeName =  loadModel.getCubeName();
+//		        String factTable = loadModel.getTableName();
+//		        
+//		        String hdfsLocation = MolapProperties.getInstance().getProperty(MolapCommonConstants.STORE_LOCATION_HDFS);
+//		        
+//		        String hdfsStoreLocation= hdfsLocation;
+//		        hdfsStoreLocation = hdfsStoreLocation + File.separator + schemaName + File.separator
+//		                + cubeName;
+//
+//		        int rsCounter = MolapUtil.checkAndReturnNextRestructFolderNumber(hdfsStoreLocation,"RS_");
+//		        if(rsCounter == -1)
+//		        {
+//		            rsCounter = 0;
+//		        }
+//		        String hdfsLoadedTable = hdfsStoreLocation + File.separator
+//		                + MolapCommonConstants.RESTRUCTRE_FOLDER + rsCounter;
+//		        
+//		        List<MolapSliceAndFiles> slicesFromHDFS = MolapUtil.getSlicesFromHDFS(
+//		        		hdfsLoadedTable, factTable, FileFactory.getFileType(hdfsLoadedTable));
+//		        try
+//		        {
+//			        for (int i = 0; i < slicesFromHDFS.size()-1; i++) 
+//			        {
+//			        	MolapFile molapFile = FileFactory.getMolapFile(slicesFromHDFS.get(i).getPath(), FileFactory.getFileType(slicesFromHDFS.get(i).getPath()));
+//			        	MolapUtil.deleteFoldersAndFiles(molapFile);
+//					}
+//		        }
+//		        catch(Exception e)
+//		        {
+////		        	e.printStackTrace();
+//		        	LOGGER.error(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG, e, e.getMessage());
+//		        }
+//		        
+//		}
 }
diff --git a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/spark/util/MolapQueryUtil.java b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/spark/util/MolapQueryUtil.java
index f1832b9..212d43c 100644
--- a/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/spark/util/MolapQueryUtil.java
+++ b/Molap/Molap-Spark-Interface/src/main/java/com/huawei/datasight/molap/spark/util/MolapQueryUtil.java
@@ -38,8 +38,6 @@ import com.huawei.datasight.molap.spark.splits.TableSplit;
 import com.huawei.iweb.platform.logging.LogService;
 import com.huawei.iweb.platform.logging.LogServiceFactory;
 import com.huawei.unibi.molap.constants.MolapCommonConstants;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperations;
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperationsImpl;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile;
 import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFileFilter;
 import com.huawei.unibi.molap.datastorage.store.impl.FileFactory;
@@ -168,15 +166,12 @@ public final class MolapQueryUtil
 		String dataPath = executerModel.getCube().getMetaDataFilepath() + File.separator + MolapCommonConstants.LOADMETADATA_FILENAME + MolapCommonConstants.MOLAP_METADATA_EXTENSION;
 		DataInputStream dataInputStream = null;
 		Gson gsonObjectToRead = new Gson();
-		AtomicFileOperations fileOperation = new AtomicFileOperationsImpl(dataPath, FileFactory.getFileType(dataPath));
 		try {
 			if (FileFactory.isFileExist(dataPath,
 					FileFactory.getFileType(dataPath))) {
 
-			    dataInputStream = fileOperation.openForRead();
-			    
-			/*	dataInputStream = FileFactory.getDataInputStream(dataPath,
-						FileFactory.getFileType(dataPath));*/
+				dataInputStream = FileFactory.getDataInputStream(dataPath,
+						FileFactory.getFileType(dataPath));
 
 				BufferedReader buffReader = new BufferedReader(
 						new InputStreamReader(dataInputStream, "UTF-8"));
@@ -195,25 +190,6 @@ public final class MolapQueryUtil
 												.getLoadStatus()) || MolapCommonConstants.STORE_LOADSTATUS_PARTIAL_SUCCESS
 												.equalsIgnoreCase(loadMetadataDetails
 														.getLoadStatus())) {
-						    // check for merged loads.
-						    if(null != loadMetadataDetails.getMergedLoadName()){
-	                            
-	                            if(!listOfValidSlices.contains(loadMetadataDetails.getMergedLoadName() ))
-	                            {
-	                                listOfValidSlices.add(loadMetadataDetails
-	                                    .getMergedLoadName());
-	                            }
-	                            // if merged load is updated then put it in updated list
-	                            if(MolapCommonConstants.MARKED_FOR_UPDATE
-                                        .equalsIgnoreCase(loadMetadataDetails
-                                                .getLoadStatus()))
-	                            {
-	                                listOfValidUpdatedSlices.add(loadMetadataDetails
-	                                        .getMergedLoadName());
-	                            }
-	                            continue;
-	                        }
-						    
 							if(MolapCommonConstants.MARKED_FOR_UPDATE
 										.equalsIgnoreCase(loadMetadataDetails
 												.getLoadStatus())){
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/KeyVal.scala b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/KeyVal.scala
index 05f84cd..1845516 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/KeyVal.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/KeyVal.scala
@@ -1,11 +1,11 @@
 
 /**
- * It is just Key value class. I don't get any other alternate to make the RDD class to work with my minimum knowledge in scala.
- * May be I will remove later once I gain good knowledge :)
+  * It is just Key value class. I don't get any other alternate to make the RDD class to work with my minimum knowledge in scala.
+  * May be I will remove later once I gain good knowledge :)
   *
- * @author R00900208
- *
- */
+  * @author R00900208
+  *
+  */
 
 package com.huawei.datasight.spark
 
@@ -43,20 +43,8 @@ class PartitionResultImpl extends PartitionResult[Int, Boolean] {
   override def getKey(key: Int, value: Boolean) = (key, value)
 }
 
-trait MergeResult[K,V] extends Serializable
-{
-  def getKey(key : Int,value : Boolean ) : (K,V) 
-    
-}
-
-class MergeResultImpl extends MergeResult[Int,Boolean]
-{
-  override def getKey(key : Int,value : Boolean) = (key,value)
-}
-
-trait DeletedLoadResult[K,V] extends Serializable
-{
-  def getKey(key : String,value : String) : (K,V) 
+trait DeletedLoadResult[K, V] extends Serializable {
+  def getKey(key: String, value: String): (K, V)
 }
 
 class DeletedLoadResultImpl extends DeletedLoadResult[String, String] {
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/agg/MolapAggregates.scala b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/agg/MolapAggregates.scala
index f6eb9c9..01f5103 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/agg/MolapAggregates.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/agg/MolapAggregates.scala
@@ -673,3 +673,10 @@ case class PositionLiteral(expr: Expression, intermediateDataType: DataType) ext
   }
 }
 
+  override def eval(input: InternalRow): Any = {
+    val output =
+      if (currentAgg == null) base.newInstance.eval(input)
+      else currentAgg.getValueObject
+    output
+  }
+}
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/processors/MolapScalaUtil.scala b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/processors/MolapScalaUtil.scala
index fc22c49..8e34967 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/processors/MolapScalaUtil.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/processors/MolapScalaUtil.scala
@@ -3,7 +3,6 @@ package com.huawei.datasight.spark.processors
 import org.apache.spark.sql.types._
 import com.huawei.unibi.molap.engine.expression.{DataType => MolapDataType}
 import com.huawei.unibi.molap.constants.MolapCommonConstants
-import org.apache.spark.sql.cubemodel.Level
 
 object MolapScalaUtil {
   def convertSparkToMolapDataType(dataType: org.apache.spark.sql.types.DataType): MolapDataType =
@@ -17,8 +16,6 @@ object MolapScalaUtil {
       case DateType => MolapDataType.DateType
       case BooleanType => MolapDataType.BooleanType
       case TimestampType => MolapDataType.TimestampType
-      case ArrayType(_,_) => MolapDataType.ArrayType
-      case StructType(_) => MolapDataType.StructType
       case NullType => MolapDataType.NullType
     }
 
@@ -36,26 +33,9 @@ object MolapScalaUtil {
       case MolapCommonConstants.DATE_TYPE => MolapCommonConstants.STRING
       case MolapCommonConstants.BOOLEAN_TYPE => MolapCommonConstants.STRING
       case MolapCommonConstants.TIMESTAMP_TYPE => MolapCommonConstants.TIMESTAMP
-      case anyType => anyType
+      case _ => MolapCommonConstants.NUMERIC
     }
-  
-  def convertSparkColumnToMolapLevel(field : (String,String)): Seq[Level] = 
-    field._2 match {
-      case MolapCommonConstants.STRING_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.STRING))
-      case MolapCommonConstants.INTEGER_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.INTEGER))
-      case MolapCommonConstants.BYTE_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.INTEGER))
-      case MolapCommonConstants.SHORT_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.INTEGER))
-      case MolapCommonConstants.LONG_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.NUMERIC))
-      case MolapCommonConstants.DOUBLE_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.NUMERIC))
-      case MolapCommonConstants.FLOAT_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.NUMERIC))
-      case MolapCommonConstants.DECIMAL_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.NUMERIC))
-      case MolapCommonConstants.DATE_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.STRING))
-      case MolapCommonConstants.BOOLEAN_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.STRING))
-      case MolapCommonConstants.TIMESTAMP_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.TIMESTAMP))
-//      case MolapCommonConstants.ARRAY_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.ARRAY))
-//      case MolapCommonConstants.STRUCT_TYPE => Seq(Level(field._1, field._1, Int.MaxValue, MolapCommonConstants.STRUCT))
-//      case _ => MolapCommonConstants.NUMERIC
-  	}
+
   //  def toSparkType(obj : Any): Any = obj match {
   //      case s: String => UTF8String(s)
   //      case i: Integer=> IntegerType(i)
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDD.scala b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDD.scala
index 78d0b33..553076e 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDD.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDD.scala
@@ -168,6 +168,7 @@ class MolapDataRDD[K, V](
       }
       catch {
         case e: Exception =>
+          e.printStackTrace()
           LOGGER.error(MolapSparkInterFaceLogEvent.UNIBI_MOLAP_SPARK_INTERFACE_MSG, e)
           updateCubeAndLevelCacheStatus(levelCacheKeys)
           if (null != e.getMessage)
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDDFactory.scala b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDDFactory.scala
index 2ddd321..9aa926a 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDDFactory.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapDataRDDFactory.scala
@@ -1,6 +1,6 @@
 /**
- *
- */
+  *
+  */
 package com.huawei.datasight.spark.rdd
 
 import scala.collection.JavaConversions.asScalaBuffer
@@ -21,7 +21,6 @@ import com.huawei.datasight.molap.spark.util.LoadMetadataUtil
 import com.huawei.datasight.spark.DeletedLoadResultImpl
 import com.huawei.datasight.spark.KeyVal
 import com.huawei.datasight.spark.KeyValImpl
-import com.huawei.datasight.spark.MergeResultImpl
 import com.huawei.datasight.spark.RestructureResultImpl
 import com.huawei.datasight.spark.ResultImpl
 import com.huawei.datasight.spark.processors.OlapUtil
@@ -43,23 +42,21 @@ import scala.collection.mutable.{ArrayBuffer, ListBuffer}
 import com.huawei.datasight.molap.core.load.LoadMetadataDetails
 import com.huawei.datasight.spark.PartitionResultImpl
 import com.huawei.unibi.molap.util.MolapDataProcessorUtil
-import com.huawei.datasight.molap.merger.MolapDataMergerUtil
-import com.huawei.unibi.molap.datastorage.store.impl.FileFactory
 
 /**
- * This is the factory class which can create different RDD depends on user needs.
+  * This is the factory class which can create different RDD depends on user needs.
   *
- * @author R00900208
- */
+  * @author R00900208
+  */
 object MolapDataRDDFactory extends Logging {
 
- val LOGGER = LogServiceFactory.getLogService(MolapDataRDDFactory.getClass().getName());
+  val LOGGER = LogServiceFactory.getLogService(MolapDataRDDFactory.getClass().getName());
 
 
   /**
-   * It creates the RDD which can access the Hbase file system directly and reads the region files and executes the query on it.
-   * It creates split for each region and reads the files. This RDD is best suitable if the result data is very big.
-   */
+    * It creates the RDD which can access the Hbase file system directly and reads the region files and executes the query on it.
+    * It creates split for each region and reads the files. This RDD is best suitable if the result data is very big.
+    */
   //  def newMolapDataDirectRDD(sc : SparkContext,molapQueryModel: MolapQueryPlan,
   //    conf: Configuration)  = {
   //
@@ -92,20 +89,20 @@ object MolapDataRDDFactory extends Logging {
   }
 
   def loadMolapData(sc: SQLContext,
-    molapLoadModel: MolapLoadModel,
-    storeLocation: String,
-    hdfsStoreLocation: String,
-    kettleHomePath: String,
-    partitioner: Partitioner,
-    columinar: Boolean,
-    isAgg: Boolean,
+                    molapLoadModel: MolapLoadModel,
+                    storeLocation: String,
+                    hdfsStoreLocation: String,
+                    kettleHomePath: String,
+                    partitioner: Partitioner,
+                    columinar: Boolean,
+                    isAgg: Boolean,
                     partitionStatus: String = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS) {
     val cube = MolapMetadata.getInstance().getCubeWithCubeName(molapLoadModel.getCubeName(), molapLoadModel.getSchemaName());
     var currentRestructNumber = -1
     //    val molapLock = new MetadataLock(cube.getMetaDataFilepath())
-   try {
+    try {
 
-     LOGGER.audit("The data load request has been received.");
+      LOGGER.audit("The data load request has been received.");
 
       //      if (molapLock.lock(MolapCommonConstants.NUMBER_OF_TRIES_FOR_LOAD_METADATA_LOCK, MolapCommonConstants.MAX_TIMEOUT_FOR_LOAD_METADATA_LOCK)) {
       //        logInfo("Successfully able to get the cube metadata file lock")
@@ -115,18 +112,18 @@ object MolapDataRDDFactory extends Logging {
       //        sys.error("Not able to acquire lock for data load.")
       //      }
 
-    currentRestructNumber = MolapUtil.checkAndReturnCurrentRestructFolderNumber(cube.getMetaDataFilepath(), "RS_", false)
+      currentRestructNumber = MolapUtil.checkAndReturnCurrentRestructFolderNumber(cube.getMetaDataFilepath(), "RS_", false)
       if (-1 == currentRestructNumber) {
-      currentRestructNumber = 0
-    }
+        currentRestructNumber = 0
+      }
 
-    //Check if any load need to be deleted before loading new data
+      //Check if any load need to be deleted before loading new data
       deleteLoadsAndUpdateMetadata(molapLoadModel, cube, partitioner, hdfsStoreLocation, false, currentRestructNumber)
       if (null == molapLoadModel.getLoadMetadataDetails) {
-      readLoadMetadataDetails(molapLoadModel, hdfsStoreLocation)
-    }
+        readLoadMetadataDetails(molapLoadModel, hdfsStoreLocation)
+      }
 
-    var currentLoadCount = -1
+      var currentLoadCount = -1
       if (molapLoadModel.getLoadMetadataDetails().size() > 0) {
         for (eachLoadMetaData <- molapLoadModel.getLoadMetadataDetails()) {
           val loadCount = Integer.parseInt(eachLoadMetaData.getLoadName())
@@ -140,9 +137,9 @@ object MolapDataRDDFactory extends Logging {
         currentLoadCount += 1;
       }
 
-    // reading the start time of data load.
-    val loadStartTime = MolapLoaderUtil.readCurrentTime();
-    val cubeCreationTime = CarbonEnv.getInstance(sc).carbonCatalog.getCubeCreationTime(molapLoadModel.getSchemaName, molapLoadModel.getCubeName)
+      // reading the start time of data load.
+      val loadStartTime = MolapLoaderUtil.readCurrentTime();
+      val cubeCreationTime = CarbonEnv.getInstance(sc).carbonCatalog.getCubeCreationTime(molapLoadModel.getSchemaName, molapLoadModel.getCubeName)
       val schemaLastUpdatedTime = CarbonEnv.getInstance(sc).carbonCatalog.getSchemaLastUpdatedTime(molapLoadModel.getSchemaName, molapLoadModel.getCubeName)
       val status = new MolapDataLoadRDD(sc.sparkContext, new ResultImpl(), molapLoadModel, storeLocation, hdfsStoreLocation, kettleHomePath, partitioner, columinar, currentRestructNumber, currentLoadCount, cubeCreationTime, schemaLastUpdatedTime).collect()
       val newStatusMap = scala.collection.mutable.Map.empty[String, String]
@@ -157,21 +154,21 @@ object MolapDataRDDFactory extends Logging {
         }
       }
 
-    var loadStatus = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
+      var loadStatus = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
       newStatusMap.foreach {
-      case (key, value) =>
+        case (key, value) =>
           if (value == MolapCommonConstants.STORE_LOADSTATUS_FAILURE) {
             loadStatus = MolapCommonConstants.STORE_LOADSTATUS_FAILURE
-        }
+          }
           else if (value == MolapCommonConstants.STORE_LOADSTATUS_PARTIAL_SUCCESS && !loadStatus.equals(MolapCommonConstants.STORE_LOADSTATUS_FAILURE)) {
-          loadStatus = MolapCommonConstants.STORE_LOADSTATUS_PARTIAL_SUCCESS
-        }
+            loadStatus = MolapCommonConstants.STORE_LOADSTATUS_PARTIAL_SUCCESS
+          }
       }
 
       if (loadStatus != MolapCommonConstants.STORE_LOADSTATUS_FAILURE &&
         partitionStatus == MolapCommonConstants.STORE_LOADSTATUS_PARTIAL_SUCCESS) {
-      loadStatus = partitionStatus
-    }
+        loadStatus = partitionStatus
+      }
 
       //      status.foreach {eachLoadStatus =>
       //        val state = eachLoadStatus._2.getLoadStatus
@@ -220,56 +217,25 @@ object MolapDataRDDFactory extends Logging {
         throw new Exception(message)
       }
       else {
-       val (result, metadataDetails) = status(0)
+        val (result, metadataDetails) = status(0)
         if (!isAgg) {
           MolapLoaderUtil.recordLoadMetadata(result, metadataDetails, molapLoadModel, loadStatus, loadStartTime)
         }
         else if (!molapLoadModel.isRetentionRequest()) {
           try {
-              CarbonEnv.getInstance(sc).carbonCatalog.updateCube(molapLoadModel.getSchema, false)(sc)
+            CarbonEnv.getInstance(sc).carbonCatalog.updateCube(molapLoadModel.getSchema, false)(sc)
           }
           catch {
-          case e: Exception =>
-            MolapLoaderUtil.deleteTable(partitioner.partitionCount, molapLoadModel.getSchemaName, molapLoadModel.getCubeName, molapLoadModel.getAggTableName, hdfsStoreLocation, currentRestructNumber)
-           val message = "Aggregation creation failure"
-            throw new Exception(message)
+            case e: Exception =>
+              MolapLoaderUtil.deleteTable(partitioner.partitionCount, molapLoadModel.getSchemaName, molapLoadModel.getCubeName, molapLoadModel.getAggTableName, hdfsStoreLocation, currentRestructNumber)
+              val message = "Aggregation creation failure"
+              throw new Exception(message)
           }
 
 
           logInfo("********schema updated**********")
         }
-       LOGGER.audit("The data loading is successfull.");
-      if(MolapDataMergerUtil.checkIfLoadMergingRequired(cube.getMetaDataFilepath(),molapLoadModel, hdfsStoreLocation,  partitioner.partitionCount, currentRestructNumber))
-      {
-
-          val loadsToMerge = MolapDataMergerUtil.getLoadsToMergeFromHDFS(
-            hdfsStoreLocation, FileFactory.getFileType(hdfsStoreLocation), cube.getMetaDataFilepath(), molapLoadModel, currentRestructNumber, partitioner.partitionCount);
-          
-          if(loadsToMerge.length == 2)
-          {
-          
-              var MergedLoadName = MolapDataMergerUtil.getMergedLoadName(loadsToMerge)
-          
-              var finalMergeStatus = true
-
-              val mergeStatus = new MolapMergerRDD(sc.sparkContext, new MergeResultImpl(), molapLoadModel, storeLocation, hdfsStoreLocation, partitioner, currentRestructNumber, cube.getMetaDataFilepath(), loadsToMerge, MergedLoadName,kettleHomePath,cubeCreationTime).collect
-          
-          
-              mergeStatus.foreach {eachMergeStatus =>
-              val state = eachMergeStatus._2
-              if (state == false)
-                  {
-                      finalMergeStatus=false
-      }
-              }
-          
-              if(finalMergeStatus == true)
-              {
-                  MolapDataMergerUtil.updateLoadMetadataWithMergeStatus(loadsToMerge,cube.getMetaDataFilepath(),MergedLoadName,molapLoadModel)
-              }
-          
-          }
-      }
+        LOGGER.audit("The data loading is successfull.");
       }
 
     }
@@ -301,25 +267,25 @@ object MolapDataRDDFactory extends Logging {
                          cubeName: String,
                          sourcePath: String,
                          targetFolder: String,
-      requiredColumns: Array[String],
-      headers: String,
-      delimiter: String,
-      quoteChar: String,
-      escapeChar: String,
-      multiLine: Boolean,
-      partitioner: Partitioner): String = {
+                         requiredColumns: Array[String],
+                         headers: String,
+                         delimiter: String,
+                         quoteChar: String,
+                         escapeChar: String,
+                         multiLine: Boolean,
+                         partitioner: Partitioner): String = {
     //     val kv:KeyVal[MolapKey,MolapValue] = new KeyValImpl();
 
     val status = new MolapDataPartitionRDD(sc, new PartitionResultImpl(), schemaName, cubeName, sourcePath, targetFolder, requiredColumns, headers, delimiter, quoteChar, escapeChar, multiLine, partitioner).collect
     MolapDataProcessorUtil.renameBadRecordsFromInProgressToNormal("partition/" + schemaName + '/' + cubeName);
-     var loadStatus = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
+    var loadStatus = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
     status.foreach {
       case (key, value) =>
         if (value == true) {
           loadStatus = MolapCommonConstants.STORE_LOADSTATUS_PARTIAL_SUCCESS
         }
-      }
-     loadStatus
+    }
+    loadStatus
   }
 
   def mergeMolapData(sc: SQLContext,
@@ -328,29 +294,29 @@ object MolapDataRDDFactory extends Logging {
                      hdfsStoreLocation: String,
                      partitioner: Partitioner) {
     val kv: KeyVal[MolapKey, MolapValue] = new KeyValImpl();
-      val cube = MolapMetadata.getInstance().getCubeWithCubeName(molapLoadModel.getCubeName(), molapLoadModel.getSchemaName());
+    val cube = MolapMetadata.getInstance().getCubeWithCubeName(molapLoadModel.getCubeName(), molapLoadModel.getSchemaName());
     val metaDataPath: String = cube.getMetaDataFilepath()
-      var currentRestructNumber = MolapUtil.checkAndReturnCurrentRestructFolderNumber(metaDataPath, "RS_", false)
+    var currentRestructNumber = MolapUtil.checkAndReturnCurrentRestructFolderNumber(metaDataPath, "RS_", false)
     if (-1 == currentRestructNumber) {
       currentRestructNumber = 0
     }
- //    new MolapMergerRDD(sc.sparkContext,kv,molapLoadModel,storeLocation,hdfsStoreLocation, partitioner, currentRestructNumber).collect
-     
+    new MolapMergerRDD(sc.sparkContext, kv, molapLoadModel, storeLocation, hdfsStoreLocation, partitioner, currentRestructNumber).collect
+
   }
 
-    def deleteLoadByDate(
-      sqlContext: SQLContext,
-    schema: Schema,
-    schemaName: String,
-    cubeName: String,
+  def deleteLoadByDate(
+                        sqlContext: SQLContext,
+                        schema: Schema,
+                        schemaName: String,
+                        cubeName: String,
                         tableName: String,
-    hdfsStoreLocation: String,
-      dateField: String,
+                        hdfsStoreLocation: String,
+                        dateField: String,
                         dateFieldActualName: String,
-      dateValue: String,
-      partitioner: Partitioner) {
+                        dateValue: String,
+                        partitioner: Partitioner) {
 
-      val sc = sqlContext;
+    val sc = sqlContext;
     //Delete the records based on data
     var cube = MolapMetadata.getInstance().getCube(schemaName + "_" + cubeName);
     if (null == cube) {
@@ -368,52 +334,46 @@ object MolapDataRDDFactory extends Logging {
       new DeletedLoadResultImpl(),
       schemaName,
       cube.getOnlyCubeName(),
-        dateField,
-        dateFieldActualName,
+      dateField,
+      dateFieldActualName,
       dateValue,
-        partitioner,
-        cube.getFactTableName,
-        tableName,
-        hdfsStoreLocation,
-        loadMetadataDetailsArray,
-        currentRestructNumber).collect.groupBy(_._1).toMap
+      partitioner,
+      cube.getFactTableName,
+      tableName,
+      hdfsStoreLocation,
+      loadMetadataDetailsArray,
+      currentRestructNumber).collect.groupBy(_._1).toMap
 
     //  var updatedLoadMetadataDetailsList = Seq[LoadMetadataDetails]() 
-      var updatedLoadMetadataDetailsList = new ListBuffer[LoadMetadataDetails]()
+    var updatedLoadMetadataDetailsList = new ListBuffer[LoadMetadataDetails]()
     //get list of updated or deleted load status and update load meta data file     
     if (!resultMap.isEmpty) {
 
       if (resultMap.size == 1) {
 
         if (resultMap.contains("")) {
-           logError("Delete by Date request is failed")
-           sys.error("Delete by Date request is failed, potential causes " + "Empty store or Invalid column type, For more details please refer logs.")
+          logError("Delete by Date request is failed")
+          sys.error("Delete by Date request is failed, potential causes " + "Empty store or Invalid column type, For more details please refer logs.")
 
-       }
+        }
       }
 
       val updatedloadMetadataDetails = loadMetadataDetailsArray.map { elem => {
-          var statusList = resultMap.get(elem.getLoadName())
-          // check for the merged load folder.
-          if(statusList == None && null != elem.getMergedLoadName()) 
-          {
-            statusList = resultMap.get(elem.getMergedLoadName())
-          }
-          
-          if (statusList != None) {
-            elem.setDeletionTimestamp(MolapLoaderUtil.readCurrentTime())
-            //if atleast on MolapCommonConstants.MARKED_FOR_UPDATE status exist, use MARKED_FOR_UPDATE
-            if (statusList.get.forall(status => status._2 == MolapCommonConstants.MARKED_FOR_DELETE)) {
-              elem.setLoadStatus(MolapCommonConstants.MARKED_FOR_DELETE)
-            } else {
-              elem.setLoadStatus(MolapCommonConstants.MARKED_FOR_UPDATE)
-            updatedLoadMetadataDetailsList += elem
-            }
-            elem
+        val statusList = resultMap.get(elem.getLoadName())
+        if (statusList != None) {
+          elem.setDeletionTimestamp(MolapLoaderUtil.readCurrentTime())
+          //if atleast on MolapCommonConstants.MARKED_FOR_UPDATE status exist, use MARKED_FOR_UPDATE
+          if (statusList.get.forall(status => status._2 == MolapCommonConstants.MARKED_FOR_DELETE)) {
+            elem.setLoadStatus(MolapCommonConstants.MARKED_FOR_DELETE)
           } else {
-            elem
+            elem.setLoadStatus(MolapCommonConstants.MARKED_FOR_UPDATE)
+            updatedLoadMetadataDetailsList += elem
           }
+          elem
+        } else {
+          elem
         }
+      }
 
       }
 
@@ -445,9 +405,9 @@ object MolapDataRDDFactory extends Logging {
       }
     }
     else {
-       logError("Delete by Date request is failed")
-       LOGGER.audit("The delete load by date is failed.");
-       sys.error("Delete by Date request is failed, potential causes " + "Empty store or Invalid column type, For more details please refer logs.")
+      logError("Delete by Date request is failed")
+      LOGGER.audit("The delete load by date is failed.");
+      sys.error("Delete by Date request is failed, potential causes " + "Empty store or Invalid column type, For more details please refer logs.")
     }
 
 
@@ -455,23 +415,23 @@ object MolapDataRDDFactory extends Logging {
 
   def alterCube(
                  hiveContext: HiveContext,
-    sc: SparkContext,
-    origUnModifiedSchema: MolapDef.Schema,
-    schema: MolapDef.Schema,
-    schemaName: String,
-    cubeName: String,
-    hdfsStoreLocation: String,
-    addedDimensions: Seq[MolapDef.CubeDimension],
-    addedMeasures: Seq[MolapDef.Measure],
-    validDropDimList: ArrayBuffer[String],
-    validDropMsrList: ArrayBuffer[String],
-    curTime: Long,
-    defaultVals: Map[String, String],
+                 sc: SparkContext,
+                 origUnModifiedSchema: MolapDef.Schema,
+                 schema: MolapDef.Schema,
+                 schemaName: String,
+                 cubeName: String,
+                 hdfsStoreLocation: String,
+                 addedDimensions: Seq[MolapDef.CubeDimension],
+                 addedMeasures: Seq[MolapDef.Measure],
+                 validDropDimList: ArrayBuffer[String],
+                 validDropMsrList: ArrayBuffer[String],
+                 curTime: Long,
+                 defaultVals: Map[String, String],
                  partitioner: Partitioner): Boolean = {
 
-      val cube = MolapMetadata.getInstance().getCubeWithCubeName(cubeName, schemaName);
+    val cube = MolapMetadata.getInstance().getCubeWithCubeName(cubeName, schemaName);
 
-      val metaDataPath: String = cube.getMetaDataFilepath()
+    val metaDataPath: String = cube.getMetaDataFilepath()
     //      val molapLock = new MetadataLock(metaDataPath)
     //      try {
     ////        if (molapLock.lock(MolapCommonConstants.NUMBER_OF_TRIES_FOR_LOAD_METADATA_LOCK, MolapCommonConstants.MAX_TIMEOUT_FOR_LOAD_METADATA_LOCK)) {
@@ -481,55 +441,55 @@ object MolapDataRDDFactory extends Logging {
     //          sys.error("Not able to acquire lock for altering cube.")
     //        }
 
-        //if there is no data loading done, no need to create RS folders
-        val loadMetadataDetailsArray = MolapUtil.readLoadMetadata(metaDataPath).toList
-        if (0 == loadMetadataDetailsArray.size) {
-          CarbonEnv.getInstance(hiveContext).carbonCatalog.updateCube(schema, false)(hiveContext)
-          return true
-        }
+    //if there is no data loading done, no need to create RS folders
+    val loadMetadataDetailsArray = MolapUtil.readLoadMetadata(metaDataPath).toList
+    if (0 == loadMetadataDetailsArray.size) {
+      CarbonEnv.getInstance(hiveContext).carbonCatalog.updateCube(schema, false)(hiveContext)
+      return true
+    }
 
-        var currentRestructNumber = MolapUtil.checkAndReturnCurrentRestructFolderNumber(metaDataPath, "RS_", false)
-        if (-1 == currentRestructNumber) {
-          currentRestructNumber = 0
-        }
+    var currentRestructNumber = MolapUtil.checkAndReturnCurrentRestructFolderNumber(metaDataPath, "RS_", false)
+    if (-1 == currentRestructNumber) {
+      currentRestructNumber = 0
+    }
 
-        val loadStartTime = MolapLoaderUtil.readCurrentTime();
-
-        val resultMap = new MolapAlterCubeRDD(sc,
-          origUnModifiedSchema,
-          schema,
-          schemaName,
-          cubeName,
-          hdfsStoreLocation,
-          addedDimensions,
-          addedMeasures,
-          validDropDimList,
-          validDropMsrList,
-          curTime,
-          defaultVals,
-          currentRestructNumber,
+    val loadStartTime = MolapLoaderUtil.readCurrentTime();
+
+    val resultMap = new MolapAlterCubeRDD(sc,
+      origUnModifiedSchema,
+      schema,
+      schemaName,
+      cubeName,
+      hdfsStoreLocation,
+      addedDimensions,
+      addedMeasures,
+      validDropDimList,
+      validDropMsrList,
+      curTime,
+      defaultVals,
+      currentRestructNumber,
       metaDataPath,
-          partitioner,
-          new RestructureResultImpl()).collect
-
-        var restructureStatus: Boolean = resultMap.forall(_._2)
-
-        if (restructureStatus) {
-          if (addedDimensions.length > 0 || addedMeasures.length > 0) {
-            val molapLoadModel: MolapLoadModel = new MolapLoadModel()
-            molapLoadModel.setCubeName(cubeName)
-            molapLoadModel.setSchemaName(schemaName)
-            molapLoadModel.setSchema(schema);
-            val metadataDetails: LoadMetadataDetails = new LoadMetadataDetails()
-            MolapLoaderUtil.recordLoadMetadata(resultMap(0)._1, metadataDetails, molapLoadModel, MolapCommonConstants.STORE_LOADSTATUS_SUCCESS, loadStartTime)
-            restructureStatus = MolapUtil.createRSMetaFile(metaDataPath, "RS_" + (currentRestructNumber + 1))
-          }
-          if (restructureStatus) {
-            CarbonEnv.getInstance(hiveContext).carbonCatalog.updateCube(schema, false)(hiveContext)
-          }
-        }
+      partitioner,
+      new RestructureResultImpl()).collect
+
+    var restructureStatus: Boolean = resultMap.forall(_._2)
+
+    if (restructureStatus) {
+      if (addedDimensions.length > 0 || addedMeasures.length > 0) {
+        val molapLoadModel: MolapLoadModel = new MolapLoadModel()
+        molapLoadModel.setCubeName(cubeName)
+        molapLoadModel.setSchemaName(schemaName)
+        molapLoadModel.setSchema(schema);
+        val metadataDetails: LoadMetadataDetails = new LoadMetadataDetails()
+        MolapLoaderUtil.recordLoadMetadata(resultMap(0)._1, metadataDetails, molapLoadModel, MolapCommonConstants.STORE_LOADSTATUS_SUCCESS, loadStartTime)
+        restructureStatus = MolapUtil.createRSMetaFile(metaDataPath, "RS_" + (currentRestructNumber + 1))
+      }
+      if (restructureStatus) {
+        CarbonEnv.getInstance(hiveContext).carbonCatalog.updateCube(schema, false)(hiveContext)
+      }
+    }
 
-        restructureStatus
+    restructureStatus
     //      } finally {
     //        if (molapLock != null) {
     //          if (molapLock.unlock()) {
@@ -539,28 +499,28 @@ object MolapDataRDDFactory extends Logging {
     //          }
     //        }
     //      }
-    }
+  }
 
-   def dropAggregateTable(
-      sc: SparkContext,
+  def dropAggregateTable(
+                          sc: SparkContext,
                           schema: String,
-      cube: String,
-      partitioner: Partitioner) {
+                          cube: String,
+                          partitioner: Partitioner) {
     val kv: KeyVal[MolapKey, MolapValue] = new KeyValImpl()
-     new MolapDropAggregateTableRDD(sc, kv, schema, cube, partitioner).collect
+    new MolapDropAggregateTableRDD(sc, kv, schema, cube, partitioner).collect
   }
 
   def dropCube(
-      sc: SparkContext,
+                sc: SparkContext,
                 schema: String,
-      cube: String,
-      partitioner: Partitioner) {
+                cube: String,
+                partitioner: Partitioner) {
     val kv: KeyVal[MolapKey, MolapValue] = new KeyValImpl()
-     new MolapDropCubeRDD(sc, kv, schema, cube, partitioner).collect
+    new MolapDropCubeRDD(sc, kv, schema, cube, partitioner).collect
   }
 
   def cleanFiles(
-      sc: SparkContext,
+                  sc: SparkContext,
                   molapLoadModel: MolapLoadModel,
                   hdfsStoreLocation: String,
                   partitioner: Partitioner) {
@@ -581,12 +541,12 @@ object MolapDataRDDFactory extends Logging {
       }
     }
     finally {
-        if (molapLock.unlock()) {
-          logInfo("unlock the cube metadata file successfully")
-        } else {
-          logError("Unable to unlock the metadata lock")
-        }
+      if (molapLock.unlock()) {
+        logInfo("unlock the cube metadata file successfully")
+      } else {
+        logError("Unable to unlock the metadata lock")
       }
+    }
   }
 
   //    /**
@@ -644,9 +604,9 @@ object MolapDataRDDFactory extends Logging {
 
   def main(args: Array[String]) {
 
-	    val d = SparkContext.jarOfClass(this.getClass)
-	    val ar = new Array[String](d.size)
-	    var i = 0
+    val d = SparkContext.jarOfClass(this.getClass)
+    val ar = new Array[String](d.size)
+    var i = 0
     d.foreach {
       p => ar(i) = p;
         i = i + 1
@@ -655,34 +615,34 @@ object MolapDataRDDFactory extends Logging {
     //	    val sc = new SparkContext("spark://master:7077", "Big Data Direct App", "/opt/spark-1.0.0-rc3/",ar)
 
 
-	        val confs = new SparkConf()
+    val confs = new SparkConf()
       //      .setMaster("spark://master:7077")
       .setMaster("local")
       .setJars(ar)
       .setAppName("Molap Spark Query")
       .setSparkHome("/opt/spark-1.0.0-rc3/")
       .set("spark.scheduler.mode", "FAIR")
-      val sc = new SparkContext(confs)
+    val sc = new SparkContext(confs)
     //	      val sc = new SparkContext("local", "Big Data App", "G:/spark-1.0.0-rc3",ar)
 
-	    val conf = new Configuration();
+    val conf = new Configuration();
 
     //        val schemaPath = "/opt/ravi/PCC_Java.xml"
     //        val schemaPath = "G:/mavenlib/PCC_Java.xml"
-        val schemaPath = "G:\\bibin issues\\SmokeData\\schema\\steelwheels.molap.xml"
+    val schemaPath = "G:\\bibin issues\\SmokeData\\schema\\steelwheels.molap.xml"
     val olapContext = new OlapContext(sc, schemaPath)
     //        val dataPath = "hdfs://master:54310/opt/ravi/store"
-        val dataPath = "F:/TRPSVN/store"
+    val dataPath = "F:/TRPSVN/store"
 
-        Thread.sleep(5000)
+    Thread.sleep(5000)
 
     //        intializeMolap(sc, schemaPath,dataPath,"ODM","PCC")
-        val schema = MolapSchemaParser.loadXML(schemaPath)
+    val schema = MolapSchemaParser.loadXML(schemaPath)
     intializeMolap(sc, schema, dataPath, "SteelWheelsSales", "MOLAPSteelWheels", null, false)
-	    import olapContext._
+    import olapContext._
 
     val holder = OlapUtil.createBaseRDD(olapContext, MolapMetadata.getInstance().getCubeWithCubeName("SteelWheelsSales", "MOLAPSteelWheels"))
-	//    var dd = holder.rdd.asInstanceOf[DataFrame].select('Territory,'Country,'City,'Quantity).groupBy('Territory,'Country)('Territory,'Country,'City,SumMolap('Quantity).as('Q1))
+    //    var dd = holder.rdd.asInstanceOf[DataFrame].select('Territory,'Country,'City,'Quantity).groupBy('Territory,'Country)('Territory,'Country,'City,SumMolap('Quantity).as('Q1))
     //
     //	    dd = dd.topN(3, 'Country, 'Q1)
 
@@ -702,17 +662,17 @@ object MolapDataRDDFactory extends Logging {
     //	    newMolapDataDirectSqlRDD(sc, sql, conf,schemaPath).foreach(println(_))
 
 
-    }
+  }
 
   def deleteLoadsAndUpdateMetadata(molapLoadModel: MolapLoadModel, cube: Cube, partitioner: Partitioner,
                                    hdfsStoreLocation: String, isForceDeletion: Boolean, currentRestructNumber: Integer) {
     if (LoadMetadataUtil.isLoadDeletionRequired(molapLoadModel)) {
 
       val loadMetadataFilePath = MolapLoaderUtil
-                .extractLoadMetadataFileLocation(molapLoadModel);
+        .extractLoadMetadataFileLocation(molapLoadModel);
 
       val details = MolapUtil
-                .readLoadMetadata(loadMetadataFilePath);
+        .readLoadMetadata(loadMetadataFilePath);
 
       //Delete marked loads
       val isUpdationRequired = DeleteLoadFolders.deleteLoadFoldersFromFileSystem(molapLoadModel, partitioner.partitionCount, hdfsStoreLocation, isForceDeletion, currentRestructNumber, details)
@@ -727,8 +687,6 @@ object MolapDataRDDFactory extends Logging {
 
     }
 
-    MolapDataMergerUtil.cleanUnwantedMergeLoadFolder(molapLoadModel, partitioner.partitionCount, hdfsStoreLocation, isForceDeletion, currentRestructNumber)
-    
   }
 
   def LoadAggregateTabAfterRetention(schemaName: String, cubeName: String, factTableName: String, sqlContext: SQLContext, schema: Schema, list: ListBuffer[LoadMetadataDetails]) {
@@ -742,32 +700,32 @@ object MolapDataRDDFactory extends Logging {
     molapLoadModel.setSchemaName(schemaName)
     val table = relation.cubeMeta.schema.cubes(0).fact.asInstanceOf[MolapDef.Table]
     //    if (table.getName == factTableName) {
-      val aggTables = schema.cubes(0).fact.asInstanceOf[MolapDef.Table].aggTables
-      if (null != aggTables && !aggTables.isEmpty) {
-        molapLoadModel.setRetentionRequest(true)
-        molapLoadModel.setLoadMetadataDetails(list)
-        molapLoadModel.setTableName(table.name)
-        molapLoadModel.setSchema(relation.cubeMeta.schema);
+    val aggTables = schema.cubes(0).fact.asInstanceOf[MolapDef.Table].aggTables
+    if (null != aggTables && !aggTables.isEmpty) {
+      molapLoadModel.setRetentionRequest(true)
+      molapLoadModel.setLoadMetadataDetails(list)
+      molapLoadModel.setTableName(table.name)
+      molapLoadModel.setSchema(relation.cubeMeta.schema);
       //        molapLoadModel.setAggLoadRequest(true)
       var storeLocation = MolapProperties.getInstance.getProperty(MolapCommonConstants.STORE_LOCATION_TEMP_PATH, System.getProperty("java.io.tmpdir"))
-        storeLocation = storeLocation + "/molapstore/" + System.currentTimeMillis()
-        val columinar = sqlContext.getConf("molap.is.columnar.storage", "true").toBoolean
-        var kettleHomePath = sqlContext.getConf("molap.kettle.home", null)
-        if (null == kettleHomePath) {
-          kettleHomePath = MolapProperties.getInstance.getProperty("molap.kettle.home");
-        }
-        if (kettleHomePath == null) sys.error(s"molap.kettle.home is not set")
-        //    val aggTableName = aggTableNames.get(0)
+      storeLocation = storeLocation + "/molapstore/" + System.currentTimeMillis()
+      val columinar = sqlContext.getConf("molap.is.columnar.storage", "true").toBoolean
+      var kettleHomePath = sqlContext.getConf("molap.kettle.home", null)
+      if (null == kettleHomePath) {
+        kettleHomePath = MolapProperties.getInstance.getProperty("molap.kettle.home");
+      }
+      if (kettleHomePath == null) sys.error(s"molap.kettle.home is not set")
+      //    val aggTableName = aggTableNames.get(0)
 
-	        MolapDataRDDFactory.loadMolapData(
-	          sqlContext,
-	          molapLoadModel,
-	          storeLocation,
-	          relation.cubeMeta.dataPath,
-	          kettleHomePath,
-	          relation.cubeMeta.partitioner, columinar, true);
+      MolapDataRDDFactory.loadMolapData(
+        sqlContext,
+        molapLoadModel,
+        storeLocation,
+        relation.cubeMeta.dataPath,
+        kettleHomePath,
+        relation.cubeMeta.partitioner, columinar, true);
 
-      }
+    }
 
     //    }
 
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapMergerRDD.scala b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapMergerRDD.scala
index a7919a6..d9f500f 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapMergerRDD.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/com/huawei/datasight/spark/rdd/MolapMergerRDD.scala
@@ -2,7 +2,6 @@ package com.huawei.datasight.spark.rdd
 
 import java.text.SimpleDateFormat
 import java.util.Date
-import java.util.List
 import org.apache.hadoop.conf.Configuration
 import org.apache.spark.Logging
 import org.apache.spark.Partition
@@ -11,7 +10,7 @@ import org.apache.spark.SparkContext
 import org.apache.spark.TaskContext
 import org.apache.spark.rdd.RDD
 import com.huawei.unibi.molap.engine.executer.MolapQueryExecutorModel
-import com.huawei.datasight.spark.{KeyVal,Result}
+import com.huawei.datasight.spark.KeyVal
 import com.huawei.datasight.molap.spark.util.MolapQueryUtil
 import com.huawei.datasight.molap.spark.splits.TableSplit
 import com.huawei.unibi.molap.util.MolapProperties
@@ -23,171 +22,69 @@ import com.huawei.datasight.molap.load.MolapLoadModel
 import com.huawei.datasight.molap.load.MolapLoaderUtil
 import org.apache.spark.sql.cubemodel.Partitioner
 import com.huawei.datasight.molap.merger.MolapDataMergerUtil
-import com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile
-import com.huawei.datasight.spark.MergeResult
-import com.huawei.unibi.molap.constants.MolapCommonConstants
-import com.huawei.unibi.molap.olap.MolapDef
-import com.huawei.unibi.molap.util.MolapUtil
 
 class MolapMergerRDD[K, V](
-  sc: SparkContext,
-  result: MergeResult[K,V],
-  molapLoadModel: MolapLoadModel,
-  storeLocation: String,
-  hdfsStoreLocation: String,
-  partitioner: Partitioner,
-  currentRestructNumber: Integer,
-  metadataFilePath:String,
-  loadsToMerge:List[String],
-  mergedLoadName:String,
-  kettleHomePath:String,
-  cubeCreationTime:Long)
+                            sc: SparkContext,
+                            keyClass: KeyVal[K, V],
+                            molapLoadModel: MolapLoadModel,
+                            storeLocation: String,
+                            hdfsStoreLocation: String,
+                            partitioner: Partitioner,
+                            currentRestructNumber: Integer)
   extends RDD[(K, V)](sc, Nil)
-  with Logging {
+    with Logging {
 
   sc.setLocalProperty("spark.scheduler.pool", "DDL")
   
   /**
-   * It fires the query of respective co-processor and get the data and form the iterator.So here all the will be present to iterator physically.So
-   * if co-processor returns big data then it may have memory issues.
-   */
+    * It fires the query of respective co-processor and get the data and form the iterator.So here all the will be present to iterator physically.So
+    * if co-processor returns big data then it may have memory issues.
+    */
   override def compute(theSplit: Partition, context: TaskContext) = {
-      val iter = new Iterator[(K, V)] {
-        var dataloadStatus = MolapCommonConstants.STORE_LOADSTATUS_FAILURE
-        val split = theSplit.asInstanceOf[MolapLoadPartition]
-        logInfo("Input split: " + split.serializableHadoopSplit.value)
-        val partitionId = split.serializableHadoopSplit.value.getPartition().getUniqueID()
-        val model = molapLoadModel.getCopyWithPartition(split.serializableHadoopSplit.value.getPartition().getUniqueID())
-        
-        val mergedLoadMetadataDetails = MolapDataMergerUtil.executeMerging(model, storeLocation, hdfsStoreLocation, currentRestructNumber, metadataFilePath,loadsToMerge,mergedLoadName)
-        
-        model.setLoadMetadataDetails(MolapUtil
-                .readLoadMetadata(metadataFilePath).toList);
-        
-        if(mergedLoadMetadataDetails == true)
-        {
-            MolapLoaderUtil.copyMergedLoadToHDFS(model, currentRestructNumber,mergedLoadName)
-            dataloadStatus = checkAndLoadAggregationTable
-            
-        }
-
-        // Register an on-task-completion callback to close the input stream.
-        context.addOnCompleteCallback(() => close())
-        var havePair = false
-        var finished = false
-
-        override def hasNext: Boolean = {
-          if (!finished && !havePair) {
-            finished = !false
-            havePair = !finished
-          }
-          !finished
+    val iter = new Iterator[(K, V)] {
+      val split = theSplit.asInstanceOf[MolapLoadPartition]
+      logInfo("Input split: " + split.serializableHadoopSplit.value)
+      val model = molapLoadModel.getCopyWithPartition(split.serializableHadoopSplit.value.getPartition().getUniqueID())
+      MolapDataMergerUtil.executeMerging(model, storeLocation, hdfsStoreLocation, currentRestructNumber);
+      MolapLoaderUtil.copyCurrentLoadToHDFS(model, currentRestructNumber, null, null, currentRestructNumber);
+
+      // Register an on-task-completion callback to close the input stream.
+      context.addOnCompleteCallback(() => close())
+      var havePair = false
+      var finished = false
+
+      override def hasNext: Boolean = {
+        if (!finished && !havePair) {
+          finished = !false
+          havePair = !finished
         }
+        !finished
+      }
 
-        override def next(): (K, V) = {
-          if (!hasNext) {
-            throw new java.util.NoSuchElementException("End of stream")
-          }
-          havePair = false
-        /*  val row = new MolapKey(null)
-          val value = new MolapValue(null)*/
-          result.getKey(0, mergedLoadMetadataDetails)
+      override def next(): (K, V) = {
+        if (!hasNext) {
+          throw new java.util.NoSuchElementException("End of stream")
         }
+        havePair = false
+        val row = new MolapKey(null)
+        val value = new MolapValue(null)
+        keyClass.getKey(row, value)
+      }
 
-        private def close() {
-          try {
-            //          reader.close()
-          } catch {
-            case e: Exception => logWarning("Exception in RecordReader.close()", e)
-          }
-        }
-        
-          def checkAndLoadAggregationTable():String = {
-          var dataloadStatus = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
-          val schema = model.getSchema
-          val aggTables = schema.cubes(0).fact.asInstanceOf[MolapDef.Table].aggTables
-          if(null != aggTables && !aggTables.isEmpty)
-          {
-            val details = model.getLoadMetadataDetails.toSeq.toArray
-            val newSlice = MolapCommonConstants.LOAD_FOLDER + mergedLoadName
-            var listOfLoadFolders = MolapLoaderUtil.getListOfValidSlices(details)
-            listOfLoadFolders = MolapLoaderUtil.addNewSliceNameToList(newSlice, listOfLoadFolders);
-            val listOfUpdatedLoadFolders = MolapLoaderUtil.getListOfUpdatedSlices(details)
-            val copyListOfLoadFolders = listOfLoadFolders.toList
-            val copyListOfUpdatedLoadFolders = listOfUpdatedLoadFolders.toList
-            loadCubeSlices(listOfLoadFolders,listOfUpdatedLoadFolders)
-            var loadFolders = Array[String]()
-            val loadFolder = MolapLoaderUtil.getAggLoadFolderLocation(newSlice, model.getSchemaName, model.getCubeName, model.getTableName, hdfsStoreLocation, currentRestructNumber)
-            if (null != loadFolder) {
-              loadFolders :+= loadFolder
-            }
-            dataloadStatus = iterateOverAggTables(aggTables, copyListOfLoadFolders, copyListOfUpdatedLoadFolders, loadFolders)
-            if (MolapCommonConstants.STORE_LOADSTATUS_FAILURE.equals(dataloadStatus)) {
-              // remove the current slice from memory not the cube
-              MolapLoaderUtil.removeSliceFromMemory(model.getSchemaName, model.getCubeName, newSlice)
-              logInfo(s"Aggregate table creation failed")
-            }
-            else {
-              logInfo("Aggregate tables creation successfull")
-            }
-          }
-          return dataloadStatus
-        }
-         
-          
-         def loadCubeSlices(listOfLoadFolders: java.util.List[String], listOfUpdatedLoadFolders: java.util.List[String]) = {
-          MolapProperties.getInstance().addProperty("molap.cache.used", "false");
-          MolapQueryUtil.createDataSource(currentRestructNumber, model.getSchema, null,partitionId, listOfLoadFolders, listOfUpdatedLoadFolders, model.getTableName, hdfsStoreLocation,cubeCreationTime)
-        } 
-          
-         def iterateOverAggTables(aggTables: Array[MolapDef.AggTable], listOfLoadFolders: java.util.List[String], listOfUpdatedLoadFolders: java.util.List[String], loadFolders: Array[String]):String = {
-          model.setAggLoadRequest(true)
-          aggTables.foreach { aggTable =>
-              val aggTableName = MolapLoaderUtil.getAggregateTableName(aggTable)
-              model.setAggTableName(aggTableName)
-              dataloadStatus = loadAggregationTable(listOfLoadFolders, listOfUpdatedLoadFolders, loadFolders)
-              if (MolapCommonConstants.STORE_LOADSTATUS_FAILURE.equals(dataloadStatus)) {
-                logInfo(s"Aggregate table creation failed :: $aggTableName")
-                return MolapCommonConstants.STORE_LOADSTATUS_FAILURE
-              }
-            }
-          return MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
+      private def close() {
+        try {
+          //          reader.close()
+        } catch {
+          case e: Exception => logWarning("Exception in RecordReader.close()", e)
         }
-          
-        def loadAggregationTable(listOfLoadFolders: java.util.List[String], listOfUpdatedLoadFolders: java.util.List[String], loadFolders: Array[String]): String = {
-          loadFolders.foreach { loadFolder =>
-            val restructNumber = MolapUtil.getRestructureNumber(loadFolder, model.getTableName)
-            try {
-              if (MolapLoaderUtil.isSliceValid(loadFolder, listOfLoadFolders, listOfUpdatedLoadFolders, model.getTableName)) {
-                model.setFactStoreLocation(loadFolder)
-                MolapLoaderUtil.executeGraph(model, storeLocation, hdfsStoreLocation, kettleHomePath, restructNumber)
-                dataloadStatus = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
-              } else {
-                MolapLoaderUtil.createEmptyLoadFolder(model, loadFolder, hdfsStoreLocation, restructNumber)
-              }
-            } catch {
-              case e: Exception => dataloadStatus = MolapCommonConstants.STORE_LOADSTATUS_FAILURE
-            } finally {
-              if (!MolapCommonConstants.STORE_LOADSTATUS_FAILURE.equals(dataloadStatus)) {
-                val loadName = loadFolder.substring(loadFolder.indexOf(MolapCommonConstants.LOAD_FOLDER))
-                MolapLoaderUtil.copyCurrentLoadToHDFS(model, restructNumber, loadName, listOfUpdatedLoadFolders,restructNumber)
-              } else {
-                logInfo(s"Load creation failed :: $loadFolder")
-                return MolapCommonConstants.STORE_LOADSTATUS_FAILURE
-              }
-            }
-          }
-          return MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
-        }  
-        
-        
       }
-      iter
     }
+    iter
+  }
 
   /**
-   * Get the preferred locations where to lauch this task.
-   */
+    * Get the preferred locations where to lauch this task.
+    */
   override def getPreferredLocations(split: Partition): Seq[String] = {
     val theSplit = split.asInstanceOf[MolapLoadPartition]
     val s = theSplit.serializableHadoopSplit.value.getLocations //.filter(_ != "localhost")
@@ -199,20 +96,19 @@ class MolapMergerRDD[K, V](
     val formatter = new SimpleDateFormat("yyyyMMddHHmm")
     formatter.format(new Date())
   }
-  
-  
+
   /**
-   * Create the split for each region server.
-   */
+    * Create the split for each region server.
+    */
   override def getPartitions: Array[Partition] = {
 
-      val splits = MolapQueryUtil.getTableSplits(molapLoadModel.getSchemaName(), molapLoadModel.getCubeName(), null, partitioner)
-      val result = new Array[Partition](splits.length)
-      for (i <- 0 until result.length) {
-        result(i) = new MolapLoadPartition(id, i, splits(i))
-      }
-      result
+    val splits = MolapQueryUtil.getTableSplits(molapLoadModel.getSchemaName(), molapLoadModel.getCubeName(), null, partitioner)
+    val result = new Array[Partition](splits.length)
+    for (i <- 0 until result.length) {
+      result(i) = new MolapLoadPartition(id, i, splits(i))
     }
+    result
+  }
 
   override def checkpoint() {
     // Do nothing. Hadoop RDD should not be checkpointed.
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/MolapSqlParser.scala b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/MolapSqlParser.scala
index 3176b93..0f84b3d 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/MolapSqlParser.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/MolapSqlParser.scala
@@ -118,11 +118,7 @@ class MolapSqlDDLParser
   protected val MAPPED = Keyword("MAPPED")
   protected val MEASURES = Keyword("MEASURES")
   protected val MULTILINE = Keyword("MULTILINE")
-  protected val COMPLEX_DELIMITER_LEVEL_1 = Keyword("COMPLEX_DELIMITER_LEVEL_1")
-  protected val COMPLEX_DELIMITER_LEVEL_2 = Keyword("COMPLEX_DELIMITER_LEVEL_2")
   protected val NUMERIC = Keyword("NUMERIC")
-  protected val ARRAY = Keyword("ARRAY")
-  protected val STRUCT = Keyword("STRUCT")
   protected val OPTIONS = Keyword("OPTIONS")
   protected val OUTPATH = Keyword("OUTPATH")
   override protected val OVERWRITE = Keyword("OVERWRITE")
@@ -306,7 +302,7 @@ class MolapSqlDDLParser
         }
 
         ShowCreateCubeCommand(CubeModel(exists.isDefined,
-          schemaName.getOrElse("default"), schemaName, cubeName, dimCols.map(f => normalizeType(f)).map(f => addParent(f)),
+          schemaName.getOrElse("default"), schemaName, cubeName, dimCols.map(f => normalizeType(f)),
           msrCols.map(f => normalizeType(f)), fromKeyword, withKeyword, source,
           factFieldsList, dimRelations, simpleDimRelations,None, aggregation, partitioner))
       }
@@ -336,7 +332,7 @@ class MolapSqlDDLParser
         }
 
         CreateCube(CubeModel(exists.isDefined,
-          schemaName.getOrElse("default"), schemaName, cubeName, dimCols.map(f => normalizeType(f)).map(f => addParent(f)),
+          schemaName.getOrElse("default"), schemaName, cubeName, dimCols.map(f => normalizeType(f)),
           msrCols.map(f => normalizeType(f)), "", withKeyword, "",
           None, Seq(), simpleDimRelations, highCard, aggregation,partitioner))
       }
@@ -421,9 +417,7 @@ class MolapSqlDDLParser
     }
 
   protected lazy val partitionOptions: Parser[(String, String)] =
-    ((DELIMITER ~ stringLit) | (QUOTECHAR ~ stringLit) | (FILEHEADER ~ stringLit) | 
-        (ESCAPECHAR ~ stringLit) | (MULTILINE ~ stringLit) | 
-        (COMPLEX_DELIMITER_LEVEL_1 ~ stringLit) | (COMPLEX_DELIMITER_LEVEL_2 ~ stringLit)) ^^ {
+    ((DELIMITER ~ stringLit) | (QUOTECHAR ~ stringLit) | (FILEHEADER ~ stringLit) | (ESCAPECHAR ~ stringLit) | (MULTILINE ~ stringLit)) ^^ {
       case opt ~ optvalue => (opt, optvalue)
       case _ => ("", "")
     }
@@ -503,45 +497,17 @@ class MolapSqlDDLParser
         DimensionRelation(tableName, "", relation, Some("INCLUDE"), Some(colList))
       }
     }
-  
+
   protected lazy val simpleDimRelations: Parser[Seq[DimensionRelation]] = repsep(simpleDimRelation, ",")
-  
-  protected lazy val dimCol: Parser[Field] = anyFieldDef 
- 
-  protected lazy val  primitiveTypes = STRING | INTEGER | TIMESTAMP | NUMERIC
-  protected lazy val nestedType: Parser[Field]  =  structFieldType | arrayFieldType | primitiveFieldType
-
-  protected lazy val anyFieldDef: Parser[Field]  = 
-    (ident | stringLit) ~ ((":").? ~> nestedType) ^^ {
-     case e1 ~ e2 => {
-    	 Field(e1, e2.dataType, Some(e1), e2.children)
-     }
-  }
-  
-  protected lazy val primitiveFieldType : Parser[Field]  = 
-    (primitiveTypes) ^^ {
-     case e1 => {
-    	 Field("unknown", Some(e1), Some("unknown"), Some(null))
-     } 
-  }
-  
-  protected lazy val arrayFieldType: Parser[Field]  = 
-    (ARRAY ~> "<" ~> nestedType <~ ">") ^^ {
-     case e1 => {
-        Field("unknown", Some("array"), Some("unknown"), Some(List(Field("val", e1.dataType, Some("val"), e1.children))))
-     }
-  }
-  
-  protected lazy val structFieldType: Parser[Field]  = 
-    (STRUCT ~> "<" ~> repsep(anyFieldDef, ",") <~ ">") ^^ {
-     case e1 => {
-    	 Field("unknown", Some("struct"), Some("unknown"), Some(e1))
-     }
-  }
-  
+
+  protected lazy val dimCol: Parser[Field] =
+    (ident | stringLit) ~ (STRING | INTEGER | TIMESTAMP | NUMERIC).? ~ (AS ~> (ident | stringLit)).? ~ (IN ~> (ident | stringLit)).? ^^ {
+      case e1 ~ e2 ~ e3 ~ e4 => Field(e1, e2, e3, e4)
+    }
+
   protected lazy val measureCol: Parser[Field] =
-    (ident | stringLit) ~ (INTEGER | NUMERIC).? ~ (AS ~> (ident | stringLit)).? ^^ {
-      case e1 ~ e2 ~ e3 => Field(e1, e2, e3, Some(null))
+    (ident | stringLit) ~ (INTEGER | NUMERIC).? ~ (AS ~> (ident | stringLit)).? ~ (WITH ~> (ident | stringLit)).? ^^ {
+      case e1 ~ e2 ~ e3 ~ e4 => Field(e1, e2, e3, e4)
     }
 
   protected lazy val dimCols: Parser[Seq[Field]] = rep1sep(dimCol, ",")
@@ -648,40 +614,14 @@ class MolapSqlDDLParser
 
   private def normalizeType(field: Field): Field = {
     field.dataType.getOrElse("NIL") match {
-      case "string" => Field(field.column, Some("String"), field.name, Some(null))
-      case "integer" => Field(field.column, Some("Integer"), field.name, Some(null))
-      case "long" => Field(field.column, Some("Long"), field.name, Some(null))
-      case "double" => Field(field.column, Some("Double"), field.name, Some(null))
-      case "timestamp" => Field(field.column, Some("Timestamp"), field.name, Some(null))
-      case "numeric" => Field(field.column, Some("Numeric"), field.name, Some(null))
-      case "array" => Field(field.column, Some("Array"), field.name, field.children.map(f => f.map(normalizeType(_))))
-      case "struct" => Field(field.column, Some("Struct"), field.name, field.children.map(f => f.map(normalizeType(_))))
-      case _ => field
-    }
-  }
-  
-  private def addParent(field: Field): Field = {
-    field.dataType.getOrElse("NIL") match {
-      case "Array" => Field(field.column, Some("Array"), field.name, field.children.map(f => f.map(appendParentForEachChild(_, field.column))))
-      case "Struct" => Field(field.column, Some("Struct"), field.name, field.children.map(f => f.map(appendParentForEachChild(_, field.column))))
-      case _ => field
-    }
-  }
-  
-  private def appendParentForEachChild(field: Field, parentName : String): Field = {
-    field.dataType.getOrElse("NIL") match {
-      case "String" => Field(parentName +"."+ field.column, Some("String"), Some(parentName +"."+ field.name.getOrElse(None)), Some(null), parentName)
-      case "Integer" => Field(parentName +"."+ field.column, Some("Integer"), Some(parentName +"."+ field.name.getOrElse(None)), Some(null), parentName)
-      case "Long" => Field(parentName +"."+ field.column, Some("Long"), Some(parentName +"."+ field.name.getOrElse(None)), Some(null), parentName)
-      case "Double" => Field(parentName +"."+ field.column, Some("Double"), Some(parentName +"."+ field.name.getOrElse(None)), Some(null), parentName)
-      case "Timestamp" => Field(parentName +"."+ field.column, Some("Timestamp"), Some(parentName +"."+ field.name.getOrElse(None)), Some(null), parentName)
-      case "Numeric" => Field(parentName +"."+ field.column, Some("Numeric"), Some(parentName +"."+ field.name.getOrElse(None)), Some(null), parentName)
-      case "Array" => Field(parentName +"."+ field.column, Some("Array"), Some(parentName +"."+ field.name.getOrElse(None)), 
-          field.children.map(f => f.map(appendParentForEachChild(_, parentName +"."+ field.column))), parentName)
-      case "Struct" => Field(parentName +"."+ field.column, Some("Struct"), Some(parentName +"."+ field.name.getOrElse(None)), 
-          field.children.map(f => f.map(appendParentForEachChild(_, parentName +"."+ field.column))), parentName)
-      case _ => field
-    }
+     case "string" => Field(field.column, Some("String"), field.name,field.storeType)
+     case "integer" => Field(field.column, Some("Integer"), field.name,field.storeType)
+     case "long" => Field(field.column, Some("Long"), field.name,field.storeType)
+     case "double" => Field(field.column, Some("Double"), field.name,field.storeType)
+     case "timestamp" => Field(field.column, Some("Timestamp"), field.name,field.storeType)
+     case "numeric" => Field(field.column, Some("Numeric"), field.name,field.storeType)
+     case _ => field
+   }
   }
 
   //  private lazy val others: Parser[LogicalPlan] =
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapMetastoreCatalog.scala b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapMetastoreCatalog.scala
index 40d8b5c..8f214cc 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapMetastoreCatalog.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapMetastoreCatalog.scala
@@ -48,7 +48,6 @@ import org.apache.spark.sql.types.ShortType
 import org.apache.spark.sql.types.StringType
 import org.apache.spark.sql.types.StructField
 import org.apache.spark.sql.types.StructType
-import org.apache.spark.sql.types.ArrayType
 import org.apache.spark.sql.types.TimestampType
 import org.apache.spark.sql.cubemodel.AggregateTableAttributes
 import org.eigenbase.xom.XOMUtil
@@ -70,13 +69,10 @@ import com.huawei.datasight.molap.load.MolapLoaderUtil
 import com.huawei.unibi.molap.util.MolapDataProcessorUtil
 import scala.collection.mutable.TreeSet
 import org.apache.spark.SparkContext
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperations
-import com.huawei.unibi.molap.datastorage.store.fileperations.AtomicFileOperationsImpl
-import com.huawei.unibi.molap.datastorage.store.fileperations.FileWriteOperation
 
 /**
- * Created by w00228970 on 2014/5/16.
- */
+  * Created by w00228970 on 2014/5/16.
+  */
 
 case class MetaData(var cubesMeta: ArrayBuffer[CubeMeta])
 
@@ -91,14 +87,14 @@ object OlapMetastoreCatalog {
     new MolapDef.Schema(defin)
   }
 
-      /**
-     * Gets content via Apache VFS and decrypt the content.
-     *  File must exist and have content.
-     *
-     * @param url String
-     * @return Apache VFS FileContent for further processing
-     * @throws FileSystemException
-     */
+  /**
+    * Gets content via Apache VFS and decrypt the content.
+    * File must exist and have content.
+    *
+    * @param url String
+    * @return Apache VFS FileContent for further processing
+    * @throws FileSystemException
+    */
   def readSchema(url: String, encrypted: Boolean): MolapDef.Schema = {
     val fileType = FileFactory.getFileType(url)
     val out = FileFactory.getDataInputStream(url, fileType)
@@ -129,8 +125,8 @@ object OlapMetastoreCatalog {
     catch {
       case s: Exception =>
         throw s
-      }
     }
+  }
 }
 
 class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
@@ -141,18 +137,18 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
 
    val cubeModifiedTimeStore = new HashMap[String, Long]()
    cubeModifiedTimeStore.put("default", System.currentTimeMillis())
-  
-  val metadata = loadMetadata(metadataPath)
+   
+   val metadata = loadMetadata(metadataPath)
   
   lazy val useUniquePath = if("true".equalsIgnoreCase(MolapProperties.getInstance().
       getProperty(
                 MolapCommonConstants.CARBON_UNIFIED_STORE_PATH, 
                 MolapCommonConstants.CARBON_UNIFIED_STORE_PATH_DEFAULT))){ true } else { false }
-    
+  
   def lookupRelation1(
-      databaseName: Option[String],
-      tableName: String,
-      alias: Option[String] = None)(sqlContext: SQLContext): LogicalPlan = {
+                       databaseName: Option[String],
+                       tableName: String,
+                       alias: Option[String] = None)(sqlContext: SQLContext): LogicalPlan = {
     val db = databaseName match {
       case Some(name) => name
       case _ => null
@@ -198,11 +194,11 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     val cubeMeta = metadata.cubesMeta.filter(c => (c.schemaName.equalsIgnoreCase(schemaName) && (c.cubeName.equalsIgnoreCase(cubeName))))
     val cubeCreationTime = cubeMeta.head.cubeCreationTime
     cubeCreationTime
-    }
+  }
   
 
-   def lookupRelation2(tableIdentifier: Seq[String],
-                     alias: Option[String] = None)(sqlContext: SQLContext): LogicalPlan = {
+  def lookupRelation2(tableIdentifier: Seq[String],
+                      alias: Option[String] = None)(sqlContext: SQLContext): LogicalPlan = {
     checkSchemasModifiedTimeAndReloadCubes()
     tableIdentifier match {
       case Seq(schemaName, cubeName) =>
@@ -233,9 +229,9 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     if (db.get == null || db.get == "") {
       cubeExists(Seq(tableName))(sqlContext)
     }
-      else {
-          cubeExists(Seq(db.get, tableName))(sqlContext)
-          }
+    else {
+      cubeExists(Seq(db.get, tableName))(sqlContext)
+    }
   }
 
   def cubeExists(tableIdentifier: Seq[String])(sqlContext: SQLContext): Boolean = {
@@ -323,96 +319,96 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
       try {
           
       if (FileFactory.isFileExist(schemasPath, fileType)) {
-	      val file = FileFactory.getMolapFile(schemasPath, fileType)
-	      val schemaFolders = file.listFiles();
+        val file = FileFactory.getMolapFile(schemasPath, fileType)
+        val schemaFolders = file.listFiles();
 
         schemaFolders.foreach(schemaFolder => {
           if (schemaFolder.isDirectory()) {
-	          val cubeFolders = schemaFolder.listFiles();
+            val cubeFolders = schemaFolder.listFiles();
 
             cubeFolders.foreach(cubeFolder => {
               if (cubeFolder.isDirectory()) {
-	            	val cubeMetadataFile = cubeFolder.getAbsolutePath() + "/metadata"
+                val cubeMetadataFile = cubeFolder.getAbsolutePath() + "/metadata"
 
                 if (FileFactory.isFileExist(cubeMetadataFile, fileType)) {
-		            	//load metadata
-		            	val in = FileFactory.getDataInputStream(cubeMetadataFile, fileType)
-		            	var len = 0
+                  //load metadata
+                  val in = FileFactory.getDataInputStream(cubeMetadataFile, fileType)
+                  var len = 0
                   try {
-		            		len = in.readInt()
-		            	}
+                    len = in.readInt()
+                  }
                   catch {
                     case others: EOFException => len = 0
-		            	}
+                  }
 
                   while (len > 0) {
-		            		val schemaNameBytes = new Array[Byte](len)
-					        in.readFully(schemaNameBytes)
+                    val schemaNameBytes = new Array[Byte](len)
+                    in.readFully(schemaNameBytes)
 
                     val schemaName = new String(schemaNameBytes, "UTF8")
-					        val cubeNameLen = in.readInt()
-					        val cubeNameBytes = new Array[Byte](cubeNameLen)
-					        in.readFully(cubeNameBytes)
+                    val cubeNameLen = in.readInt()
+                    val cubeNameBytes = new Array[Byte](cubeNameLen)
+                    in.readFully(cubeNameBytes)
                     val cubeName = new String(cubeNameBytes, "UTF8")
 
-		            		val dataPathLen = in.readInt()
-					        val dataPathBytes = new Array[Byte](dataPathLen)
-					        in.readFully(dataPathBytes)
+                    val dataPathLen = in.readInt()
+                    val dataPathBytes = new Array[Byte](dataPathLen)
+                    in.readFully(dataPathBytes)
                     val dataPath = new String(dataPathBytes, "UTF8")
 
-		            		val versionLength = in.readInt()
-					        val versionBytes = new Array[Byte](versionLength)
-					        in.readFully(versionBytes)
+                    val versionLength = in.readInt()
+                    val versionBytes = new Array[Byte](versionLength)
+                    in.readFully(versionBytes)
                     val version = new String(versionBytes, "UTF8")
 
-		            		val schemaLen = in.readInt()
-					        val schemaBytes = new Array[Byte](schemaLen)
-					        in.readFully(schemaBytes)
+                    val schemaLen = in.readInt()
+                    val schemaBytes = new Array[Byte](schemaLen)
+                    in.readFully(schemaBytes)
                     val schema = new String(schemaBytes, "UTF8")
 
-		            		val partitionLength = in.readInt()
-					        val partitionBytes = new Array[Byte](partitionLength)
-					        in.readFully(partitionBytes)
-				            val inStream = new ByteArrayInputStream(partitionBytes)
-				            val objStream = new ObjectInputStream(inStream)
-				            val partitioner = objStream.readObject().asInstanceOf[Partitioner]
-				            objStream.close
+                    val partitionLength = in.readInt()
+                    val partitionBytes = new Array[Byte](partitionLength)
+                    in.readFully(partitionBytes)
+                    val inStream = new ByteArrayInputStream(partitionBytes)
+                    val objStream = new ObjectInputStream(inStream)
+                    val partitioner = objStream.readObject().asInstanceOf[Partitioner]
+                    objStream.close
 
                     val cal = new GregorianCalendar(2011, 1, 1)
 				    var cubeCreationTime=cal.getTime().getTime()
                     try {
 				    cubeCreationTime = in.readLong()
-				            	len = in.readInt()
-		            		}
+                    len = in.readInt()
+                    }
                     catch {
                       case others: EOFException => len = 0
-		            		}
-				        	val mondSchema = OlapMetastoreCatalog.parseStringToSchema(schema)
-                  val cubeUniqueName = schemaName + "_" + cubeName
-		            		MolapMetadata.getInstance().loadSchema(mondSchema)
-		            		val cube = MolapMetadata.getInstance().getCube(cubeUniqueName)
+                    }
+                    val mondSchema = OlapMetastoreCatalog.parseStringToSchema(schema)
+                    val cubeUniqueName = schemaName + "_" + cubeName
+                    MolapMetadata.getInstance().loadSchema(mondSchema)
+                    val cube = MolapMetadata.getInstance().getCube(cubeUniqueName)
                     metaDataBuffer += CubeMeta(
-		            				schemaName,
-		            				cubeName,
-		            				dataPath,
-		            				mondSchema,
-		            				cube,
+                      schemaName,
+                      cubeName,
+                      dataPath,
+                      mondSchema,
+                      cube,
 				      updatePartitioner(partitioner, cube),
 				      cubeCreationTime)
-		            	}
-		            	in.close
-	            	}
-	            }
-	          })
-	        }
-	      })
+                  }
+                  in.close
+                }
+              }
+            })
+          }
+        })
       }
       else {
-	      //Create folders and files.
-	      FileFactory.mkdirs(schemasPath, fileType)
-	      //FileFactory.createNewFile(metadataPath+"/"+"metadata", fileType)
+        //Create folders and files.
+        FileFactory.mkdirs(schemasPath, fileType)
+        //FileFactory.createNewFile(metadataPath+"/"+"metadata", fileType)
         
-	    }
+      }
     }
     catch {
       case s: java.io.FileNotFoundException =>
@@ -424,8 +420,8 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
   }
 
   /**
-   * Add schema to the catalog and perisist to the metadata
-   */
+    * Add schema to the catalog and perisist to the metadata
+    */
   def createCube(schemaName: String, cubeName: String, schemaXML: String, partitioner: Partitioner, aggTablesGen: Boolean)
                 (sqlContext: SQLContext) : String =  {
     if (cubeExists(Seq(schemaName, cubeName))(sqlContext))
@@ -448,24 +444,19 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     } else {
       metadataPath + "/store"
     }
-    
+
     val cubeCreationTime = System.currentTimeMillis()
     val cubeMeta = CubeMeta(
-        schemaName,
-        cubeName,
+      schemaName,
+      cubeName,
       dataPath,
-        schema,
-        cube,
+      schema,
+      cube,
         updatePartitioner(partitioner, cube),
         cubeCreationTime)
 
     val fileType = FileFactory.getFileType(metadataPath)
-    //Debug code to print complexTypes
-//    val relation = CarbonEnv.getInstance(sqlContext).carbonCatalog.
-//    	lookupRelation2(Seq(cubeMeta.schemaName, cubeMeta.cubeName))(sqlContext).asInstanceOf[OlapRelation]
-//    val complexTypes = cubeMeta.schema.cubes(0).dimensions.filter(aDim => aDim.asInstanceOf[MolapDef.Dimension].hierarchies(0).levels.length > 1).map(dim => dim.name)
-//    val complexTypeStrings = relation.output.filter(attr => complexTypes.contains(attr.name)).map(attr => (attr.name, attr.dataType.simpleString))
-//    complexTypeStrings.map(a => println(a._1 +" "+a._2))
+
     if (!FileFactory.isFileExist(cubeMetaDataPath, fileType)) {
       FileFactory.mkdirs(cubeMetaDataPath, fileType)
     }
@@ -474,34 +465,34 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
 
     val out = FileFactory.getDataOutputStream(cubeMetaDataPath + "/" + "metadata", fileType)
 
-      val schemaNameBytes = cubeMeta.schemaName.getBytes()
-      val cubeNameBytes = cubeMeta.cubeName.getBytes()
-      val dataPathBytes = cubeMeta.dataPath.getBytes()
-      val schemaArray = cubeMeta.schema.toXML.getBytes()
-      val outStream = new ByteArrayOutputStream
-      val objStream = new ObjectOutputStream(outStream)
-      objStream.writeObject(cubeMeta.partitioner);
-      objStream.close
-      val partitionArray = outStream.toByteArray()
-      val partitionClass = cubeMeta.partitioner.partitionClass.getBytes()
+    val schemaNameBytes = cubeMeta.schemaName.getBytes()
+    val cubeNameBytes = cubeMeta.cubeName.getBytes()
+    val dataPathBytes = cubeMeta.dataPath.getBytes()
+    val schemaArray = cubeMeta.schema.toXML.getBytes()
+    val outStream = new ByteArrayOutputStream
+    val objStream = new ObjectOutputStream(outStream)
+    objStream.writeObject(cubeMeta.partitioner);
+    objStream.close
+    val partitionArray = outStream.toByteArray()
+    val partitionClass = cubeMeta.partitioner.partitionClass.getBytes()
     val versionNoBytes = MolapVersion.getCubeVersion().getBytes()
-      out.writeInt(schemaNameBytes.length)
-      out.write(schemaNameBytes)
-      out.writeInt(cubeNameBytes.length)
-      out.write(cubeNameBytes)
-      out.writeInt(dataPathBytes.length)
-      out.write(dataPathBytes)
-      out.writeInt(versionNoBytes.length)
-      out.write(versionNoBytes)
-      out.writeInt(schemaArray.length)
-      out.write(schemaArray)
-      out.writeInt(partitionArray.length)
-      out.write(partitionArray)
+    out.writeInt(schemaNameBytes.length)
+    out.write(schemaNameBytes)
+    out.writeInt(cubeNameBytes.length)
+    out.write(cubeNameBytes)
+    out.writeInt(dataPathBytes.length)
+    out.write(dataPathBytes)
+    out.writeInt(versionNoBytes.length)
+    out.write(versionNoBytes)
+    out.writeInt(schemaArray.length)
+    out.write(schemaArray)
+    out.writeInt(partitionArray.length)
+    out.write(partitionArray)
       out.writeLong(cubeCreationTime)
-      out.close
+    out.close
 
-      metadata.cubesMeta += cubeMeta
-      logInfo(s"Cube $cubeName for schema $schemaName created successfully.")
+    metadata.cubesMeta += cubeMeta
+    logInfo(s"Cube $cubeName for schema $schemaName created successfully.")
     LOGGER.info(MolapEngineLogEvent.UNIBI_MOLAPENGINE_MSG, "Cube " + cubeName + " for schema " + schemaName + " created successfully.")
     updateSchemasUpdatedTime(schemaName, cubeName)
     metadataPath + "/" + schemaName + "/" + cubeName
@@ -541,54 +532,54 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
   //}
   /*
    * This method will return the list of executers in the cluster.
- * For this we take the  memory status of all node with getExecutorMemoryStatus
+   * For this we take the  memory status of all node with getExecutorMemoryStatus
    * and extract the keys. getExecutorMemoryStatus also returns the driver memory also
- * In client mode driver will run in the localhost
+   * In client mode driver will run in the localhost
    * There can be executor spawn in same drive node. So we can remove first occurance of
- * localhost for retriving executor list
- */
+   * localhost for retriving executor list
+   */
   def getNodeList(): Array[String] = {
 
     val arr =
       sparkContext.getExecutorMemoryStatus.map {
         kv =>
-	    	  kv._1.split(":")(0)
-	    	//val addr = InetAddress.getByName( (kv._1.split(":")(0)) )
-	    	//addr.getHostName()
-		}.toSeq
+          kv._1.split(":")(0)
+        //val addr = InetAddress.getByName( (kv._1.split(":")(0)) )
+        //addr.getHostName()
+      }.toSeq
     val localhostIPs = getLocalhostIPs
- //   val ipcheck: List[(String,Boolean)] = localhostIPs.map( x=> (x,arr.contains(x))).filter()
+    //   val ipcheck: List[(String,Boolean)] = localhostIPs.map( x=> (x,arr.contains(x))).filter()
 
     val selectedLocalIPList = localhostIPs.filter(arr.contains(_))
 
     val nodelist: List[String] = withoutDriverIP(arr.toList)(selectedLocalIPList.contains(_))
-	val masterMode = sparkContext.getConf.get("spark.master")
+    val masterMode = sparkContext.getConf.get("spark.master")
     if (nodelist.length > 0) {
       //Specific for Yarn Mode
       if ("yarn-cluster".equals(masterMode) || "yarn-client".equals(masterMode)) {
         val nodeNames = nodelist.map { x =>
-				val addr = InetAddress.getByName(x)
-				addr.getHostName()
-		 	}
-			nodeNames.toSeq.toArray
-	    }
+          val addr = InetAddress.getByName(x)
+          addr.getHostName()
+        }
+        nodeNames.toSeq.toArray
+      }
       else {
-	      //For Standalone cluster, node IPs will be returned.
-	    	nodelist.toArray
-	}
+        //For Standalone cluster, node IPs will be returned.
+        nodelist.toArray
+      }
     }
-	else
-		Seq(InetAddress.getLocalHost().getHostName()).toArray
+    else
+      Seq(InetAddress.getLocalHost().getHostName()).toArray
   }
 
   def getLocalhostIPs() = {
-     val iface = NetworkInterface.getNetworkInterfaces()
+    val iface = NetworkInterface.getNetworkInterfaces()
     var addresses: List[InterfaceAddress] = List.empty
     while (iface.hasMoreElements()) {
-     	addresses = iface.nextElement().getInterfaceAddresses().toList ++ addresses
-     }
-     val inets = addresses.map(_.getAddress().getHostAddress())
-     inets
+      addresses = iface.nextElement().getInterfaceAddresses().toList ++ addresses
+    }
+    val inets = addresses.map(_.getAddress().getHostAddress())
+    inets
   }
 
   /*
@@ -598,36 +589,36 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
  * The resulting List containt List(slave1,Master,slave2,slave3)  
  *  
  */
-   def withoutDriverIP[A](xs: List[A])(p: A => Boolean): List[A] = xs.toList match {
-  	case x :: rest =>  if (p(x)) rest else x :: withoutDriverIP(rest)(p)
-  	case _ => Nil
+  def withoutDriverIP[A](xs: List[A])(p: A => Boolean): List[A] = xs.toList match {
+    case x :: rest => if (p(x)) rest else x :: withoutDriverIP(rest)(p)
+    case _ => Nil
   }
 
- /* def getLocalhosts() = {
-    val iface = NetworkInterface.getNetworkInterfaces()
-    val ifaces_list = new scala.collection.JavaConversions.JEnumerationWrapper(iface)
-    val ips = ifaces_list.toSeq.map(x=>new JEnumerationWrapper(x.getInetAddresses).map(_.getAddress()))
+  /* def getLocalhosts() = {
+     val iface = NetworkInterface.getNetworkInterfaces()
+     val ifaces_list = new scala.collection.JavaConversions.JEnumerationWrapper(iface)
+     val ips = ifaces_list.toSeq.map(x=>new JEnumerationWrapper(x.getInetAddresses).map(_.getAddress()))
 
-  }
+   }
    *
-  */
-	/*
-	val set = new TreeSet[String]
+   */
+  /*
+  val set = new TreeSet[String]
     olap.sparkContext.getExecutorMemoryStatus.foreach{kv=>
       set.add(kv._1.split(":")(0))
     }
-	if(set.size>0)
-	{
-	    if(!olap.sparkContext.getConf.get("spark.executor.at.driver","true").toBoolean) {
-	      val curHostName = InetAddress.getLocalHost().getHostName()
-	      set.filterNot(_.equalsIgnoreCase(curHostName)).toArray
-	    } else {
+  if(set.size>0)
+  {
+      if(!olap.sparkContext.getConf.get("spark.executor.at.driver","true").toBoolean) {
+        val curHostName = InetAddress.getLocalHost().getHostName()
+        set.filterNot(_.equalsIgnoreCase(curHostName)).toArray
+      } else {
         set.toArray
-	    }
-	} else {
-	  Seq("localhost").toArray
-	}
-	* */
+      }
+  } else {
+    Seq("localhost").toArray
+  }
+  * */
 
 
   def loadCube(schemaPath: String, encrypted: Boolean, aggTablesGen: Boolean, partitioner: Partitioner)(sqlContext: SQLContext) {
@@ -676,7 +667,7 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
       if (null != cube.getMeasure(cube.getFactTableName(), colName)) sys.error(s"Measure must be provided along with aggregate function :: $colName")
       if (null == cube.getDimensionByLevelName(colName, colName, colName, cube.getFactTableName())) sys.error(s"Invalid column name. Cannot create an aggregate table :: $colName")
       if (dimArray.contains(colName)) {
-         sys.error(s"Duplicate column name. Cannot create an aggregate table :: $colName")
+        sys.error(s"Duplicate column name. Cannot create an aggregate table :: $colName")
       }
       dimArray :+= colName
     }
@@ -765,13 +756,13 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     return newAggregateTableName
   }
 
-  def  updateCube(schema: MolapDef.Schema, aggTablesGen: Boolean)(sqlContext: SQLContext) {
+  def updateCube(schema: MolapDef.Schema, aggTablesGen: Boolean)(sqlContext: SQLContext) {
     val schemaName = schema.name
     val cubeName = schema.cubes(0).name
     val schemaXML: String = schema.toXML
     if (!cubeExists(Seq(schemaName, cubeName))(sqlContext)) {
-       sys.error(s"Cube does not exist with $schemaName and $cubeName to update")
-     }
+      sys.error(s"Cube does not exist with $schemaName and $cubeName to update")
+    }
     val schemaNew = OlapMetastoreCatalog.parseStringToSchema(schemaXML)
     //if(aggTablesGen) schemaNew = GenerateAggTables(schemaNew).apply
     //Remove the cube and load again for aggregates.
@@ -790,7 +781,7 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     {
       oldMetadataFile.delete()
     }*/
-    val fileOperation = new AtomicFileOperationsImpl(metadataFilePath, FileFactory.getFileType(metadataFilePath))
+
     val tempMetadataFilePath = metadataFilePath + MolapCommonConstants.UPDATING_METADATA
 
     if (FileFactory.isFileExist(tempMetadataFilePath, fileType)) {
@@ -804,7 +795,7 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     metadata.cubesMeta.map { c =>
       if (c.schemaName.equalsIgnoreCase(schemaName) && c.cubeName.equalsIgnoreCase(cubeName)) {
         val cubeMeta = CubeMeta(schemaName, cubeName, metadataPath+"/store", schemaNew, cube, updatePartitioner(c.partitioner, cube),c.cubeCreationTime)
-        val out = fileOperation.openForWrite(FileWriteOperation.OVERWRITE)
+        val out = FileFactory.getDataOutputStream(tempMetadataFilePath, fileType)
 
         val schemaNameBytes = c.schemaName.getBytes()
         val cubeNameBytes = c.cubeName.getBytes()
@@ -826,14 +817,13 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
         out.write(dataPathBytes)
         out.writeInt(versionNoBytes.length)
         out.write(versionNoBytes)
-      	out.writeInt(schemaArray.length)
-      	out.write(schemaArray)
-      	out.writeInt(partitionArray.length)
-      	out.write(partitionArray)
+        out.writeInt(schemaArray.length)
+        out.write(schemaArray)
+        out.writeInt(partitionArray.length)
+        out.write(partitionArray)
         out.writeLong(c.cubeCreationTime)
-      	fileOperation.close()
-//      	out.close
-//      	tempMetadataFile.renameForce(oldMetadataFile.getAbsolutePath())
+        out.close
+        tempMetadataFile.renameForce(oldMetadataFile.getAbsolutePath())
       }
 
 
@@ -851,8 +841,8 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
   }
 
   /**
-   * Shows all schemas which has schema name like
-   */
+    * Shows all schemas which has schema name like
+    */
   def showSchemas(schemaLike: Option[String]): Seq[String] = {
     checkSchemasModifiedTimeAndReloadCubes()
     metadata.cubesMeta.map { c =>
@@ -866,9 +856,9 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
   }
 
   /**
-   * Shows all cubes for given schema.
-   */
- def getCubes(databaseName: Option[String])(sqlContext: SQLContext): Seq[(String, Boolean)] = {
+    * Shows all cubes for given schema.
+    */
+  def getCubes(databaseName: Option[String])(sqlContext: SQLContext): Seq[(String, Boolean)] = {
 
     val schemaName = databaseName.getOrElse(sqlContext.asInstanceOf[HiveContext].catalog.client.currentDatabase)
     checkSchemasModifiedTimeAndReloadCubes()
@@ -877,10 +867,10 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     }.map { c => (c.cubeName, false) }
   }
 
- /**
-   * Shows all cubes in all schemas.
-   */
- def getAllCubes()(sqlContext: SQLContext): Seq[(String, String)] = {
+  /**
+    * Shows all cubes in all schemas.
+    */
+  def getAllCubes()(sqlContext: SQLContext): Seq[(String, String)] = {
     checkSchemasModifiedTimeAndReloadCubes()
     metadata.cubesMeta.map { c => (c.schemaName, c.cubeName) }
   }
@@ -894,26 +884,26 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     val cube = MolapMetadata.getInstance().getCube(schemaName + '_' + cubeName)
 
     if (null != cube) {
-    	val metadatFilePath = MolapMetadata.getInstance().getCube(schemaName + '_' + cubeName).getMetaDataFilepath()
-    	val fileType = FileFactory.getFileType(metadatFilePath)
+      val metadatFilePath = MolapMetadata.getInstance().getCube(schemaName + '_' + cubeName).getMetaDataFilepath()
+      val fileType = FileFactory.getFileType(metadatFilePath)
 
       if (FileFactory.isFileExist(metadatFilePath, fileType)) {
-    	    val file = FileFactory.getMolapFile(metadatFilePath, fileType)
-          MolapUtil.renameCubeForDeletion(partitionCount, storePath, schemaName, cubeName)
-    	    MolapUtil.deleteFoldersAndFilesSilent(file)
-    	}
+        val file = FileFactory.getMolapFile(metadatFilePath, fileType)
+        MolapUtil.renameCubeForDeletion(partitionCount, storePath, schemaName, cubeName)
+        MolapUtil.deleteFoldersAndFilesSilent(file)
+      }
 
-    	val partitionLocation = storePath + File.separator + "partition" + File.separator + schemaName + File.separator + cubeName
-    	val partitionFileType = FileFactory.getFileType(partitionLocation)
+      val partitionLocation = storePath + File.separator + "partition" + File.separator + schemaName + File.separator + cubeName
+      val partitionFileType = FileFactory.getFileType(partitionLocation)
       if (FileFactory.isFileExist(partitionLocation, partitionFileType)) {
-    	   MolapUtil.deleteFoldersAndFiles(FileFactory.getMolapFile(partitionLocation, partitionFileType))
-    	}
+        MolapUtil.deleteFoldersAndFiles(FileFactory.getMolapFile(partitionLocation, partitionFileType))
+      }
     }
 
     try {
-          sqlContext.sql(s"DROP TABLE $schemaName.$cubeName").collect()
+      sqlContext.sql(s"DROP TABLE $schemaName.$cubeName").collect()
     } catch {
-        case e: Exception =>
+      case e: Exception =>
         LOGGER.audit(s"Error While deleting the table $schemaName.$cubeName during drop cube" + e.getMessage)
     }
 
@@ -929,14 +919,14 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     var timestampFile =  if(useUniquePath)
     {
        metadataPath + "/" + schemaName + "/" + cubeName + "/schemas/" + MolapCommonConstants.SCHEMAS_MODIFIED_TIME_FILE
-  }
+    }
     else
     {
        metadataPath + "/schemas/" + MolapCommonConstants.SCHEMAS_MODIFIED_TIME_FILE
     }
-  
-      val timestampFileType = FileFactory.getFileType(timestampFile)
-      (timestampFile, timestampFileType)
+    
+    val timestampFileType = FileFactory.getFileType(timestampFile)
+    (timestampFile, timestampFileType)
   }
 
   def updateSchemasUpdatedTime(schemaName : String, cubeName : String) {
@@ -948,21 +938,21 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
     }
 
     touchSchemasTimestampFile(schemaName, cubeName)
-  
+    
     if(useUniquePath)
-  {
+    {
       cubeModifiedTimeStore.put(schemaName + '_' + cubeName, FileFactory.getMolapFile(timestampFile, timestampFileType).getLastModifiedTime())
     }
     else
-	  {
+    {
       cubeModifiedTimeStore.put("default", FileFactory.getMolapFile(timestampFile, timestampFileType).getLastModifiedTime())
-	  }
-	  
+    }
+    
   }
 
   def touchSchemasTimestampFile(schemaName : String, cubeName : String) {
    val (timestampFile, timestampFileType) = getTimestampFileAndType(schemaName, cubeName)
-	  FileFactory.getMolapFile(timestampFile, timestampFileType).setLastModifiedTime(System.currentTimeMillis())
+    FileFactory.getMolapFile(timestampFile, timestampFileType).setLastModifiedTime(System.currentTimeMillis())
   }
 
   def checkSchemasModifiedTimeAndReloadCubes() {
@@ -972,9 +962,9 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
 
         if (FileFactory.isFileExist(timestampFile, timestampFileType)) {
           if (!(FileFactory.getMolapFile(timestampFile, timestampFileType).getLastModifiedTime() == cubeModifiedTimeStore.get(c.schemaName + "_" + c.cubeName))) {
-		    refreshCache
-		  }
-	  }
+            refreshCache
+          }
+        }
       })
     } else {
       val (timestampFile, timestampFileType) = getTimestampFileAndType("", "")
@@ -982,7 +972,7 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
         if (!(FileFactory.getMolapFile(timestampFile, timestampFileType).
           getLastModifiedTime() == cubeModifiedTimeStore.get("default"))) {
           refreshCache
-  }
+        }
       }
     }
   }
@@ -1001,26 +991,26 @@ class OlapMetastoreCatalog(sparkContext: SparkContext, val metadataPath: String)
   }
 
   private def loadCubeFromMetaData(
-    fileType: com.huawei.unibi.molap.datastorage.store.impl.FileFactory.FileType,
-    buffer: scala.collection.mutable.ArrayBuffer[org.apache.spark.sql.CubeMeta],
-    cubeFolder: com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile): Unit = {
-        if (cubeFolder.isDirectory()) {
+                                    fileType: com.huawei.unibi.molap.datastorage.store.impl.FileFactory.FileType,
+                                    buffer: scala.collection.mutable.ArrayBuffer[org.apache.spark.sql.CubeMeta],
+                                    cubeFolder: com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile): Unit = {
+    if (cubeFolder.isDirectory()) {
 
          val (schemaName,cubeName,dataPath,schema,partitioner,cubeCreationTime) = readCubeMetaDataFile(cubeFolder,fileType)
 
-            val mondSchema = OlapMetastoreCatalog.parseStringToSchema(schema)
-            val cubeUniqueName = schemaName + "_" + cubeName
-            MolapMetadata.getInstance().loadSchema(mondSchema)
-            val cube = MolapMetadata.getInstance().getCube(cubeUniqueName)
-            buffer += CubeMeta(
-                schemaName,
-                cubeName,
-                dataPath,
-                mondSchema,
-                cube,
+      val mondSchema = OlapMetastoreCatalog.parseStringToSchema(schema)
+      val cubeUniqueName = schemaName + "_" + cubeName
+      MolapMetadata.getInstance().loadSchema(mondSchema)
+      val cube = MolapMetadata.getInstance().getCube(cubeUniqueName)
+      buffer += CubeMeta(
+        schemaName,
+        cubeName,
+        dataPath,
+        mondSchema,
+        cube,
                 updatePartitioner(partitioner, cube),cubeCreationTime)
-          }
-        }
+    }
+  }
 
   def readCubeMetaDataFile(cubeFolder: com.huawei.unibi.molap.datastorage.store.filesystem.MolapFile, fileType: com.huawei.unibi.molap.datastorage.store.impl.FileFactory.FileType): (String, String, String, String, Partitioner, Long) = {
     val cubeMetadataFile = cubeFolder.getAbsolutePath() + "/metadata"
@@ -1108,10 +1098,8 @@ object OlapMetastoreTypes extends RegexParsers {
       "varchar\\((\\d+)\\)".r ^^^ StringType |
       "timestamp" ^^^ TimestampType
 
-    protected lazy val arrayType: Parser[DataType] =
-      "array" ~> "<" ~> dataType<~ ">" ^^ {
-        case tpe => ArrayType(tpe)
-    }
+  //  protected lazy val arrayType: Parser[DataType] =
+  //    "array" ~> "<" ~> dataType <~ ">" ^^ ArrayType
 
   protected lazy val mapType: Parser[DataType] =
     "map" ~> "<" ~> dataType ~ "," ~ dataType <~ ">" ^^ {
@@ -1123,15 +1111,13 @@ object OlapMetastoreTypes extends RegexParsers {
       case name ~ _ ~ tpe => StructField(name, tpe, nullable = true)
     }
 
-    protected lazy val structType: Parser[DataType] =
-      "struct" ~> "<" ~> repsep(structField,",") <~ ">" ^^ {
-        case fields => StructType(fields)
-    }
+  //  protected lazy val structType: Parser[DataType] =
+  //    "struct" ~> "<" ~> repsep(structField,",") <~ ">" ^^ StructType
 
   protected lazy val dataType: Parser[DataType] =
-      arrayType |
-      mapType |
-      structType |
+  //    arrayType |
+    mapType |
+      //      structType |
       primitiveType
 
   def toDataType(metastoreType: String): DataType = parseAll(dataType, metastoreType) match {
@@ -1140,7 +1126,7 @@ object OlapMetastoreTypes extends RegexParsers {
   }
 
   def toMetastoreType(dt: DataType): String = dt match {
-    case ArrayType(elementType, _) => s"array<${toMetastoreType(elementType)}>"
+    //    case ArrayType(elementType) => s"array<${toMetastoreType(elementType)}>"
     case StructType(fields) =>
       s"struct<${fields.map(f => s"${f.name}:${toMetastoreType(f.dataType)}").mkString(",")}>"
     //    case MapType(keyType, valueType) =>
@@ -1154,9 +1140,7 @@ object OlapMetastoreTypes extends RegexParsers {
     case BinaryType => "binary"
     case BooleanType => "boolean"
     case DecimalType() => "decimal"
-    case TimestampType => "timestamp"
   }
-  
 }
 
 case class OlapMetaData(dims: Seq[String], msrs: Seq[String], cube: Cube)
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapRelation.scala b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapRelation.scala
index 3acab92..9e7cdda 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapRelation.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/OlapRelation.scala
@@ -15,9 +15,6 @@ import scala.collection.JavaConversions.seqAsJavaList
 import scala.language.implicitConversions
 import java.util.LinkedHashSet
 import org.apache.spark.sql.types.StructType
-import java.util.HashMap
-import org.apache.spark.sql.types.DataType
-import org.apache.spark.sql.types.StringType
 
 
 /**
@@ -82,36 +79,6 @@ case class OlapRelation(schemaName: String,
 
   def tableName = cubeName
 
-  def recursiveMethod(dimName: String) : String = {
-	metaData.cube.getChildren(dimName).map(childDim => {
-		childDim.getDataType().toString.toLowerCase match {
-			case "array" => s"array<${getArrayChildren(childDim.getColName)}>"
-			case "struct" => s"struct<${getStructChildren(childDim.getColName)}>"
-			case dType => s"${childDim.getColName()}:${dType}"
-		}
-	}).mkString(",")
-  }
-  
-  def getArrayChildren(dimName: String) : String = {
-	metaData.cube.getChildren(dimName).map(childDim => {
-		childDim.getDataType().toString.toLowerCase match {
-		    case "array" => s"array<${getArrayChildren(childDim.getColName())}>"
-			case "struct" => s"struct<${getStructChildren(childDim.getColName())}>"
-			case dType => dType
-		}
-	}).mkString(",")
-  }
-  
-  def getStructChildren(dimName: String) : String = {
-    metaData.cube.getChildren(dimName).map(childDim => {
-		childDim.getDataType().toString.toLowerCase match {
-		    case "array" => s"${childDim.getColName().substring(childDim.getParentName.length()+1)}:array<${getArrayChildren(childDim.getColName())}>"
-			case "struct" => s"struct<${metaData.cube.getChildren(childDim.getColName).map(f => s"${recursiveMethod(f.getColName)}")}>"
-			case dType => s"${childDim.getColName.substring(childDim.getParentName.length()+1)}:${dType}"
-		}
-	}).mkString(",")
-  }
-  
   //  def getSchemaPath = schemaPath
   override def newInstance() = OlapRelation(schemaName, cubeName, metaData, cubeMeta, alias)(sqlContext).asInstanceOf[this.type]
 
@@ -119,25 +86,11 @@ case class OlapRelation(schemaName: String,
     val filteredDimAttr = cubeMeta.schema.cubes(0).dimensions.filter { aDim => (null == aDim.asInstanceOf[MolapDef.Dimension].hierarchies(0).levels(0).visible) ||
       (aDim.asInstanceOf[MolapDef.Dimension].hierarchies(0).levels(0).visible)
     }
-    
-     
     val sett = new LinkedHashSet(filteredDimAttr.toSeq)
-    sett.toSeq.map(dim => 
-    {
-    	val output: DataType = metaData.cube.getDimension(dim.name).getDataType().toString.toLowerCase match {
-    	  case "array" => OlapMetastoreTypes.toDataType(s"array<${getArrayChildren(dim.name)}>")
-    	  case "struct" => OlapMetastoreTypes.toDataType(s"struct<${getStructChildren(dim.name)}>")
-    	  case dType => OlapMetastoreTypes.toDataType(dType)
-    	}
-    	
-//          println(OlapMetastoreTypes.toMetastoreType(output))
-    	  AttributeReference(
-    		  dim.name,
-//    		  OlapMetastoreTypes.toDataType(metaData.cube.getDimension(dim.name).getDataType().toString.toLowerCase),
-    		  output,
-    		  nullable = true)(qualifiers = tableName +: alias.toSeq)
-      }
-    )
+    sett.toSeq.map(x => AttributeReference(
+      x.name,
+      OlapMetastoreTypes.toDataType(metaData.cube.getDimension(x.name).getDataType().toString.toLowerCase),
+      nullable = true)(qualifiers = tableName +: alias.toSeq))
   }
 
   val measureAttr = {
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/cubemodel/cubeSchema.scala b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/cubemodel/cubeSchema.scala
index 8aad313..c313604 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/cubemodel/cubeSchema.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/cubemodel/cubeSchema.scala
@@ -94,20 +94,12 @@ case class CubeModel(
                       partitioner: Option[Partitioner])
 
 
-case class Field(column: String, dataType: Option[String], name: Option[String], children : Option[List[Field]], parent: String = null)
-
-case class ArrayDataType(dataType: String)
-
-case class StructDataType(dataTypes: List[String])
-
-case class StructField(column: String, dataType: String)
+case class Field(column: String, dataType: Option[String], name: Option[String], storeType: Option[String])
 
 case class FieldMapping(levelName: String, columnName: String)
 
 case class HierarchyMapping(hierName: String, hierType: String, levels: Seq[String])
 
-case class ComplexField(complexType: String, primitiveField: Option[Field], complexField: Option[ComplexField])
-
 case class Cardinality(levelName: String, cardinality: Int)
 
 case class Aggregation(msrName: String, aggType: String)
@@ -120,7 +112,7 @@ case class DimensionRelation(tableName: String, dimSource: Object, relation: Rel
 
 case class Relation(leftColumn: String, rightColumn: String)
 
-case class Level(name: String, val column: String, cardinality: Int, dataType: String, parent: String = null, levelType: String = "Regular")
+case class Level(name: String, val column: String, cardinality: Int, dataType: String, storeType: String = "Columnar", levelType: String = "Regular")
 
 case class Measure(name: String, column: String, dataType: String, aggregator: String = "SUM", visible: Boolean = true)
 
@@ -146,21 +138,6 @@ class CubeProcessor(cm: CubeModel, sqlContext: SQLContext) {
   val timeDims = Seq("TimeYears", "TimeMonths", "TimeDays", "TimeHours", "TimeMinutes")
   val numericTypes = Seq(MolapCommonConstants.INTEGER_TYPE, MolapCommonConstants.DOUBLE_TYPE, MolapCommonConstants.LONG_TYPE, MolapCommonConstants.FLOAT_TYPE)
 
-  def getAllChildren(fieldChildren : Option[List[Field]]) : Seq[Level]  = {
-      var levels: Seq[Level] = Seq[Level]()
-	   fieldChildren.map(fields => {
-	        fields.map(field => {
-	        	  if(field.parent != null)
-		    		 levels ++= Seq(Level(field.name.getOrElse(field.column), field.column, Int.MaxValue, field.dataType.getOrElse(MolapCommonConstants.STRING), field.parent))
-		    	 else
-		    		 levels ++= Seq(Level(field.name.getOrElse(field.column), field.column, Int.MaxValue, field.dataType.getOrElse(MolapCommonConstants.STRING)))
-	        	  if(field.children.get != null)
-	        		  levels ++= getAllChildren(field.children)
-	      	})
-	   })
-	   levels
-  }
-  
   def process(): Cube = {
 
     var levels = Seq[Level]()
@@ -169,16 +146,7 @@ class CubeProcessor(cm: CubeModel, sqlContext: SQLContext) {
     val LOGGER = LogServiceFactory.getLogService(CubeProcessor.getClass().getName())
 
     // Create Cube DDL with Schema defination
-//    levels = 
-      cm.dimCols.map(field =>
-      {
-    	 if(field.parent != null)
-    		 levels ++= Seq(Level(field.name.getOrElse(field.column), field.column, Int.MaxValue, field.dataType.getOrElse(MolapCommonConstants.STRING), field.parent))
-    	 else
-    		 levels ++= Seq(Level(field.name.getOrElse(field.column), field.column, Int.MaxValue, field.dataType.getOrElse(MolapCommonConstants.STRING)))
-    	 if(field.children.get != null)
-    		 levels ++= getAllChildren(field.children)
-      })
+      levels = cm.dimCols.map(field => Level(field.name.getOrElse(field.column), field.column, Int.MaxValue, field.dataType.getOrElse(MolapCommonConstants.STRING),field.storeType.getOrElse("Columnar")))
     measures = cm.msrCols.map(field => Measure(field.name.getOrElse(field.column), field.column, field.dataType.getOrElse(MolapCommonConstants.NUMERIC)))
 
     if (cm.withKeyword.equalsIgnoreCase(MolapCommonConstants.WITH) && cm.simpleDimRelations.size > 0) {
@@ -255,18 +223,8 @@ class CubeProcessor(cm: CubeModel, sqlContext: SQLContext) {
         })
       })
     })
-    
-//    val hierarchies = levels.map(field => Hierarchy(field.name, None, Seq(field), None))
-    
-//    val hierarchies = levels.groupBy(
-//        _.name.split('.')(0)
-//        ).map(
-//        fields => 
-//          Hierarchy(fields._1, None, fields._2, None)
-//        ).toSeq
-    
-    val groupedSeq = levels.groupBy(_.name.split('.')(0))
-    val hierarchies = levels.filter(level => !level.name.contains(".")).map(parentLevel => Hierarchy(parentLevel.name, None, groupedSeq.get(parentLevel.name).get, None))
+
+    val hierarchies = levels.map(field => Hierarchy(field.name, None, Seq(field), None,false))
     var dimensions = hierarchies.map(field => Dimension(field.name, Seq(field), None))
 
     dimensions = dimensions ++ dimSrcDimensions
@@ -437,15 +395,7 @@ private[sql] case class ShowCreateCube(cm: CubeModel, override val output: Seq[A
         specifiedCols = cols.map(_._1)
         cols
       } else {
-        df.dtypes.map(f => 
-          if(f._2.startsWith("ArrayType") || f._2.startsWith("StructType"))
-          {
-        	  val fieldIndex = df.schema.getFieldIndex(f._1).get
-        	  (f._1.trim(), df.schema.fields(fieldIndex).dataType.simpleString)
-          }
-          else
-        	  (f._1.trim(), f._2))
-        
+        df.dtypes.map(f => (f._1.trim(), f._2))
       }
 
       val columns = rawColumns.filter(c => !c._2.equalsIgnoreCase(MolapCommonConstants.BINARY_TYPE))
@@ -525,12 +475,7 @@ private[sql] case class ShowCreateCube(cm: CubeModel, override val output: Seq[A
           levels = levels.dropWhile(p => p.column.equalsIgnoreCase(relationEntry.relation.leftColumn) && !specifiedCols.map(x => x.toLowerCase()).contains(p.column.toLowerCase()))
           measures = measures.dropWhile(p => p.column.equalsIgnoreCase(relationEntry.relation.leftColumn) && !specifiedCols.map(x => x.toLowerCase()).contains(p.column.toLowerCase()))
 
-          var dimFileLevels: Seq[Level] = Seq[Level]() 
-            relColumns.map(field => {
-//            		dimFileLevels ++ = MolapScalaUtil.convertSparkColumnToMolapLevel(field)
-            		Level(field._1, field._1, Int.MaxValue, MolapScalaUtil.convertSparkToMolapSchemaDataType(field._2))
-            	}
-              )
+          val dimFileLevels = relColumns.map(field => Level(field._1, field._1, Int.MaxValue, MolapScalaUtil.convertSparkToMolapSchemaDataType(field._2)))
           val dimFileHierarchies = dimFileLevels.map(field => Hierarchy(relationEntry.tableName, Some(dimFileLevels.find(dl => dl.name.equalsIgnoreCase(relationEntry.relation.rightColumn)).get.column), Seq(field), Some(relationEntry.tableName)))
           dimFileDimensions = dimFileDimensions ++ dimFileHierarchies.map(field => Dimension(field.levels.head.name, Seq(field), Some(relationEntry.relation.leftColumn)))
 
@@ -679,7 +624,7 @@ private[sql] case class ShowCreateCube(cm: CubeModel, override val output: Seq[A
 
       case None =>
     }
-//    println(command.toString)
+
     Seq(Row(command.toString))
   }
 
@@ -1275,7 +1220,7 @@ private[sql] case class CreateCube(cm: CubeModel) extends RunnableCommand with C
     LOGGER.audit(s"Creating cube with Schema name [$s] and cube name [$c]")
 
     if (cm.withKeyword.equalsIgnoreCase(MolapCommonConstants.WITH) && cm.simpleDimRelations.size > 0) {
-      val levels = cm.dimCols.map(field => Level(field.name.getOrElse(field.column), field.column, Int.MaxValue, field.dataType.getOrElse(MolapCommonConstants.STRING)))
+      val levels = cm.dimCols.map(field => Level(field.name.getOrElse(field.column), field.column, Int.MaxValue, field.dataType.getOrElse(MolapCommonConstants.STRING),field.storeType.getOrElse("Columnar")))
       cm.simpleDimRelations.foreach(relationEntry => {
 
         // Split the levels and seperate levels with dimension levels
@@ -1380,8 +1325,11 @@ private[sql] case class CreateCube(cm: CubeModel) extends RunnableCommand with C
             levelXml.name = level.name
             levelXml.column = level.column
             levelXml.levelType = level.levelType
-            if(level.parent != null)
-              levelXml.parentname = level.parent
+          level.storeType match {
+            case "row" =>
+              levelXml.columnar=false
+            case others =>          
+          }
             //TODO: find away to assign type in scala
             //levelXml.type = level.dataType
             setV(levelXml, "type", level.dataType)
@@ -1394,7 +1342,6 @@ private[sql] case class CreateCube(cm: CubeModel) extends RunnableCommand with C
 
       //val schemaWithAggs = GenerateAggTables(schema).apply
       //println(schemaWithAggs.toXML())
-//      println(schema.toXML())
 
       //Add schema to catalog and persist
       val catalog = CarbonEnv.getInstance(sqlContext).carbonCatalog
@@ -1673,24 +1620,10 @@ private[sql] case class LoadCube(
       val fileHeader = partionValues.getOrElse("fileheader", "")
       val escapeChar = partionValues.getOrElse("escapechar", "")
       val multiLine = partionValues.getOrElse("multiline", false)
-      val complex_delimiter_level_1 = partionValues.getOrElse("complex_delimiter_level_1", "\\$")
-      val complex_delimiter_level_2 = partionValues.getOrElse("complex_delimiter_level_2", "\\:")
       var booleanValForMultiLine = false
       if (multiLine.equals("true")) {
         booleanValForMultiLine = true
       }
-      
-      if(delimiter.equalsIgnoreCase(complex_delimiter_level_1) || 
-          complex_delimiter_level_1.equalsIgnoreCase(complex_delimiter_level_2) ||
-          delimiter.equalsIgnoreCase(complex_delimiter_level_2))
-      {
-    	  sys.error(s"Field Delimiter & Complex types delimiter are same")
-      }
-      else
-      {
-    	  molapLoadModel.setComplexDelimiterLevel1(MolapUtil.escapeComplexDelimiterChar(complex_delimiter_level_1))
-    	  molapLoadModel.setComplexDelimiterLevel2(MolapUtil.escapeComplexDelimiterChar(complex_delimiter_level_2))
-      }
 
       var partitionStatus = MolapCommonConstants.STORE_LOADSTATUS_SUCCESS
       try {
diff --git a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/olapOperators.scala b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/olapOperators.scala
index 7f9e7d2..5aaabc4 100644
--- a/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/olapOperators.scala
+++ b/Molap/Molap-Spark-Interface/src/main/scala/org/apache/spark/sql/olapOperators.scala
@@ -68,6 +68,7 @@ import com.huawei.unibi.molap.engine.querystats.QueryDetail
 import com.huawei.unibi.molap.engine.querystats.QueryStatsCollector
 import com.huawei.unibi.molap.engine.expression.ColumnExpression
 import com.huawei.datasight.spark.agg.AverageMolap
+import com.huawei.datasight.spark.agg.CommonMolapParAggExpr
 import com.huawei.datasight.spark.agg.CountMolap
 import com.huawei.datasight.spark.agg.SumMolap
 import com.huawei.datasight.spark.agg.CountDistinctMolap
diff --git a/Molap/dummy-encryption-util/.classpath b/Molap/dummy-encryption-util/.classpath
index fceb480..6cf7e9d 100644
--- a/Molap/dummy-encryption-util/.classpath
+++ b/Molap/dummy-encryption-util/.classpath
@@ -1,6 +1,7 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <classpath>
 	<classpathentry kind="src" path="src"/>
-	<classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/JavaSE-1.8"/>
+	<classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
+	<classpathentry kind="lib" path="/libraries/Unibi_Prebuild/kettle-core-4.2.1-GA.jar"/>
 	<classpathentry kind="output" path="bin"/>
 </classpath>
