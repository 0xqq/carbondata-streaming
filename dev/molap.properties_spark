molap.schema.maxFileSize=50
dataload.taskstatus.retention=2
molap.numberOfCubesToLoadConcurrent=5
max.memory.threshold=60
min.memory.threshold=50
#1 means every day
molap.retention.schedule=1
molap.dataload.queuesize=100
molap.dataload.concurrent.execution.size=1
molap.result.limit=100000000
mysql.null.value=\\N
mssql.null.value=
oracle.null.value=NULL
molap.sort.size=1000000
molap.queryexecutor.concurrent.execution.size=3
#################### EXECUTION THREADS ##################
molap.number.of.cores=4
molap.smartJump.avoid.percent=70
molap.agg.enableXXHash=true
molap.spark.resultlimit=20000
molap.cache.used=false

mysql.resultset.cursor.moveonly.forward=false

molap.level.write.bufferinkb=12238
molap.graph.rowset.size=100000
molap.sort.file.write.buffer.size=10485760
molap.sort.intermediate.files.limit=50
molap.sort.file.buffer.size=20
molap.sort.intermedaite.number.of.therads=5
molap.csv.read.buffersize.byte=1048576
molap.csv.read.copies=6
molap.datawriter.write.all.node=true
molap.data.load.log.counter=500000
molap.number.of.cores.while.loading=6
molap.prefetch.in.merge=true
molap.prefetch.bufferSize=20000
molap.inmemory.cache.use=true
molap.dataload.log.enabled=true


## Spark MOLAP related Properties
#spark.dataset.location=../datasets_test/
#spark.dp.location=../datapipelines_test/
#spark.sqlconnections.location=../unibi-solutions/system/dbconnection/sqlconnections_test.xml
#spark.url=local

#molap.storelocation=hdfs://master:54310/opt/ravi/store
#molap.storelocation=/opt/ravi/store1day
molap.storelocation=hdfs://master:54310/opt/ravi/perfstore
#molap.storelocation=/opt/ravi/store1day
#molap.storelocation=/opt/ravi/storebasemolap
#molap.storelocation=/opt/ravi/storesinglenode




spark.dataset.location=hdfs://master:54310/opt/ravi/sparkmolap/datasets/
spark.dp.location=hdfs://master:54310/opt/ravi/sparkmolap/datapipelines/
spark.sqlconnections.location=hdfs://master:54310/opt/ravi/sparkmolap/sqlconnections/sqlconnections_test.xml
spark.url=spark://master:7077
spark.home=/opt/spark-1.0.0-rc3
#spark.schema.path=/opt/ravi/steelwheels.molap.xml
spark.schema.path=/opt/ravi/PCC_Java.xml
spark.schema.name=PCC
spark.cube.name=ODM

spark.executor.memory=200g
spark.cores.max=76
spark.usekryo.serializer=true
spark.eventLog.enabled=true
spark.sql.shuffle.partitions=200

##### New properties for columnar ####################################################################
# Enbale Columnar
molap.is.columnar.storage=true	
#Int or Short based indexes. use Int now (TODO  Short is not working) 
is.int.based.indexer=true			
#Store Unique Values for a column if not high cardinality dimension 
aggregate.columnar.keyblock=true
#Threshold for a dimension be considered High Cardinality 
high.cardinality.value=100000
#Numbers of tuples in Leaf  ( this can be 15x for columar store comared to row based store since each column is sperately read/decompressed) 
molap.leaf.node.size=120000
#Use multiple of 8 bits for a colmn value
molap.is.fullyfilled.bits=true
#To use NumberCompressor.java for compression . Since no benefit was found, keep it false
is.compressed.keyblock=false
#How many levels will be combined into one column .TODO only one supported
molap.dimension.split.value.in.columnar=1
